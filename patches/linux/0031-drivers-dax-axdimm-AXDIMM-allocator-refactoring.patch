From 51b3c595c5cafa2093b8023edd9894c832b5cfa1 Mon Sep 17 00:00:00 2001
From: Petr Bred <p.bred@samsung.com>
Date: Mon, 1 Aug 2022 16:08:12 +0300
Subject: [PATCH 031/225] [drivers/dax/axdimm] AXDIMM allocator refactoring

* add AXDIMM log, AXDIMM_COPY_*_USER macros

Signed-off-by: Petr Bred <p.bred@samsung.com>
---
 drivers/dax/axdimm-private.h   |  14 ++
 drivers/dax/axdimm.c           |  57 ++---
 drivers/dax/axdimm_allocator.c | 421 +++++++++++++++++----------------
 drivers/dax/axdimm_allocator.h |   6 +-
 drivers/dax/axdimm_log.h       |  18 ++
 5 files changed, 275 insertions(+), 241 deletions(-)
 create mode 100644 drivers/dax/axdimm_log.h

diff --git a/drivers/dax/axdimm-private.h b/drivers/dax/axdimm-private.h
index df704cc1d..c8da88c6f 100644
--- a/drivers/dax/axdimm-private.h
+++ b/drivers/dax/axdimm-private.h
@@ -8,11 +8,25 @@
 /* Put the header here not to change origin dax-private.h */
 #include <linux/pgtable.h>
 #include "dax-private.h"
+#include "axdimm_log.h"
 
 #include <linux/fs.h>
 #include <linux/libaxdimm.h>
 #include <linux/types.h>
 
+#define AXDIMM_COPY_FROM_TO_USER(func, error, dst, src, size)                  \
+	do {                                                                   \
+		error = func(dst, src, size) ? -EFAULT : 0;                    \
+		if (unlikely(error)) {                                         \
+			AXDIMM_ERR("Can't copy '" #src "' to '" #dst           \
+				   "' in '" #func "'\n");                      \
+		}                                                              \
+	} while (0)
+#define AXDIMM_COPY_FROM_USER(error, dst, src, size)                           \
+	AXDIMM_COPY_FROM_TO_USER(copy_from_user, error, dst, src, size)
+#define AXDIMM_COPY_TO_USER(error, dst, src, size)                             \
+	AXDIMM_COPY_FROM_TO_USER(copy_to_user, error, dst, src, size)
+
 /* A scale of AXDIMM memory range */
 #define AXDIMM_MEMORY_SCALE ((uint64_t)CONFIG_AXDIMM_MEMORY_SCALE)
 
diff --git a/drivers/dax/axdimm.c b/drivers/dax/axdimm.c
index 7b6b4f9fe..0504b5f1f 100644
--- a/drivers/dax/axdimm.c
+++ b/drivers/dax/axdimm.c
@@ -3,6 +3,7 @@
 
 #include "axdimm_allocator.h"
 #include "axdimm-private.h"
+#include "axdimm_log.h"
 
 #include <linux/memremap.h>
 #include <linux/pagemap.h>
@@ -44,27 +45,23 @@ ssize_t axdimm_meminfo_read(struct file *filp, char __user *buf, size_t count,
 	ssize_t retval = 0;
 
 	if (*f_pos != 0) {
-		printk(KERN_WARNING
-		       "[DAX_AXDIMM_DD] Wrong file offset. Operation aborted\n");
+		AXDIMM_WRN("Wrong file offset. Operation aborted\n");
 		return -EINVAL;
 	}
 
 	if (count != sizeof(axdmem_info)) {
-		printk(KERN_WARNING
-		       "[DAX_AXDIMM_DD] Truncating axdimm read meminfo parameters: "
-		       "requested: %zu, read: %zu.\n",
-		       count, sizeof(axdmem_info));
+		AXDIMM_WRN(
+			"Truncating axdimm read meminfo parameters: requested: %zu, read: %zu.\n",
+			count, sizeof(axdmem_info));
 	}
 
-	if (copy_to_user(buf, (void *)(&axdimm_device.mem_info),
-			 sizeof(axdmem_info))) {
-		printk(KERN_WARNING
-		       "[DAX_AXDIMM_DD] can't use copy_to_user.\n");
-		retval = -EPERM;
-	} else {
-		printk(KERN_WARNING "[DAX_AXDIMM_DD] Read axdimm mem_info.\n");
+	AXDIMM_COPY_TO_USER(retval, buf, &axdimm_device.mem_info,
+			    sizeof(axdmem_info));
+	if (likely(!retval)) {
+		AXDIMM_INF("Read axdimm mem_info.\n");
 		retval = sizeof(axdmem_info);
 	}
+
 	return retval;
 }
 
@@ -271,9 +268,9 @@ static int setup_axdimm_ranges(struct dev_dax *dev_dax)
 			},
 		};
 		pgoff += PHYS_PFN(range_len(&ranges[i].range));
-		printk(KERN_INFO
-		       "[DAX_AXDIMM_DD] Filling dev_dax range %d via addresses 0x%llx - 0x%llx\n",
-		       i, ranges[i].range.start, ranges[i].range.end);
+		AXDIMM_INF(
+			"Filling dev_dax range %d via addresses 0x%llx - 0x%llx\n",
+			i, ranges[i].range.start, ranges[i].range.end);
 	}
 
 	return rc;
@@ -311,17 +308,16 @@ int axdimm_mmap(struct file *filep, struct vm_area_struct *vma)
 
 	vma->vm_page_prot = get_page_prot(vma);
 
-	printk(KERN_INFO
-	       "[DAX_AXDIMM_DD] Device mmap Offset 0x%lx, Size 0x%lx, page prot 0x%lx\n",
-	       vma->vm_pgoff, (vma->vm_end - vma->vm_start),
-	       vma->vm_page_prot.pgprot);
+	AXDIMM_INF("Device mmap Offset 0x%lx, Size 0x%lx, page prot 0x%lx\n",
+		   vma->vm_pgoff, (vma->vm_end - vma->vm_start),
+		   vma->vm_page_prot.pgprot);
 
 	if (remap_pfn_range(vma, vma->vm_start, page_addr,
 			    vma->vm_end - vma->vm_start, vma->vm_page_prot)) {
-		printk(KERN_INFO "[DAX_AXDIMM_DD] Device mmap failed\n");
+		AXDIMM_ERR("Device mmap failed\n");
 		return -EAGAIN;
 	}
-	printk(KERN_INFO "[DAX_AXDIMM_DD] Device mmap okay\n");
+	AXDIMM_INF("Device mmap okay\n");
 
 	return 0;
 }
@@ -336,15 +332,15 @@ long axdimm_ioctl(struct file *filp, unsigned int cmd, unsigned long __user arg)
 	 * wrong cmds: return ENOTTY (inappropriate ioctl) before access_ok()
 	 */
 	if (_IOC_TYPE(cmd) != AXDIMM_IOC_MAGIC) {
-		printk(KERN_INFO " _IOC_TYPE(cmd) :	 %u\n", _IOC_TYPE(cmd));
-		printk(KERN_INFO " AXDIMM_IOC_MAGIC:   %u\n", AXDIMM_IOC_MAGIC);
-		printk(KERN_WARNING
-		       "[SAIT] axdimm: _IOC_TYPE(cmd) != AXDIMM_IOC_MAGIC => false. Aborting ioctl\n");
+		AXDIMM_ERR(" _IOC_TYPE(cmd) :	 %u\n", _IOC_TYPE(cmd));
+		AXDIMM_ERR(" AXDIMM_IOC_MAGIC:   %u\n", AXDIMM_IOC_MAGIC);
+		AXDIMM_ERR(
+			" _IOC_TYPE(cmd) != AXDIMM_IOC_MAGIC => false. Aborting ioctl\n");
 		return -ENOTTY;
 	}
 	if (_IOC_NR(cmd) > AXDIMM_IOC_MAXNR) {
-		printk(KERN_WARNING
-		       "[SAIT] axdimm: _IOC_NR(cmd) > AXDIMM_IOC_MAXNR => false. Aborting ioctl\n");
+		AXDIMM_ERR(
+			" _IOC_NR(cmd) > AXDIMM_IOC_MAXNR => false. Aborting ioctl\n");
 		return -ENOTTY;
 	}
 
@@ -374,8 +370,7 @@ long axdimm_ioctl(struct file *filp, unsigned int cmd, unsigned long __user arg)
 		break;
 	case SET_SC_LOCK:
 		if (down_interruptible(&axdimm_device.sem_axdimm)) {
-			printk(KERN_WARNING
-			       "[SAIT] axdimm: Device was busy. Operation aborted\n");
+			AXDIMM_ERR("Device was busy. Operation aborted\n");
 			return -ERESTARTSYS;
 		}
 		break;
@@ -386,7 +381,7 @@ long axdimm_ioctl(struct file *filp, unsigned int cmd, unsigned long __user arg)
 	case GET_MEMORY_OBJECTS_NUM:
 	case GET_MEMORY_ALLOCATION:
 	case DEALLOCATE_MEMORY:
-		retval = do_allocation_logic(&axdimm_allocator, cmd, arg);
+		retval = mem_process_ioctl(cmd, &axdimm_allocator, arg);
 		break;
 	default:
 		return retval;
diff --git a/drivers/dax/axdimm_allocator.c b/drivers/dax/axdimm_allocator.c
index 42fc01504..4c2bb3661 100644
--- a/drivers/dax/axdimm_allocator.c
+++ b/drivers/dax/axdimm_allocator.c
@@ -1,7 +1,9 @@
 // SPDX-License-Identifier: GPL-2.0
 /* Copyright(c) 2022 Samsung LTD. All rights reserved. */
 
+#include "axdimm-private.h"
 #include "axdimm_allocator.h"
+#include "axdimm_log.h"
 
 #include <linux/math.h>
 #include <linux/slab.h>
@@ -14,7 +16,6 @@ void init_axdimm_allocator(struct axdimm_allocator *alloc,
 
 	/* Offset in allocation decisions storage */
 	alloc->available_allocation_idx = 0;
-
 	alloc->allocation_counter = 0;
 
 	/* Ranks sizes and offsets */
@@ -38,8 +39,8 @@ void reset_axdimm_allocator(struct axdimm_allocator *alloc)
 	uint8_t allocation;
 	uint8_t rank;
 
-	if (mutex_is_locked(&alloc->memory_mutex)) {
-		printk(KERN_WARNING "[DAX_AXDIMM_DD] Mutex unlock forced.\n");
+	if (unlikely(mutex_is_locked(&alloc->memory_mutex))) {
+		AXDIMM_WRN("Mutex unlock forced.\n");
 		mutex_unlock(&alloc->memory_mutex);
 	}
 
@@ -48,9 +49,7 @@ void reset_axdimm_allocator(struct axdimm_allocator *alloc)
 		kfree(alloc->allocations[allocation].objects);
 
 	memset(alloc->allocations, 0, sizeof(alloc->allocations));
-
 	alloc->available_allocation_idx = 0;
-
 	alloc->allocation_counter = 0;
 
 	/* Reset memory tracker's offset */
@@ -61,13 +60,12 @@ void reset_axdimm_allocator(struct axdimm_allocator *alloc)
 void cleanup_axdimm_allocator(struct axdimm_allocator *alloc)
 {
 	reset_axdimm_allocator(alloc);
-
 	mutex_destroy(&alloc->memory_mutex);
 }
 
-static void save_new_allocation(struct axdimm_allocator *alloc,
-			 struct axd_memory_object *objects,
-			 uint64_t num_objects)
+static inline void save_new_allocation(struct axdimm_allocator *alloc,
+				       struct axd_memory_object *objects,
+				       uint64_t num_obj)
 {
 	/* Save new allocation to allocation storage */
 	alloc->allocations[alloc->available_allocation_idx].objects = objects;
@@ -75,94 +73,131 @@ static void save_new_allocation(struct axdimm_allocator *alloc,
 	alloc->allocations[alloc->available_allocation_idx].descriptor =
 		++alloc->allocation_counter;
 	/* Set objects count for this allocation */
-	alloc->allocations[alloc->available_allocation_idx].num_objects =
-		num_objects;
+	alloc->allocations[alloc->available_allocation_idx].num_obj = num_obj;
 }
 
-static inline uint64_t get_num_objects(uint64_t num_user_objects,
-				       axd_user_preferences pref)
+/* Get total number of allocated objects depends on user memory policy. */
+static inline uint64_t gen_num_obj(uint64_t num_user_obj,
+				   axd_user_preferences pref)
 {
-	if (likely(pref != AXDIMM_ALLOC_DISTRIBUTE_ALL))
-		return num_user_objects * NUM_OF_RANK;
+	switch (pref) {
+	case AXDIMM_ALLOC_AUTO:
+	case AXDIMM_ALLOC_REPLICATE_ALL:
+		return num_user_obj * NUM_OF_RANK;
+	case AXDIMM_ALLOC_DISTRIBUTE_ALL:
+		return num_user_obj;
+	}
 
-	return num_user_objects;
+	AXDIMM_ERR("Unknown memory policy [%d]\n", pref);
+	return 0;
 }
 
-static inline uint64_t get_rank_num_objects(uint64_t num_user_objects,
-					    axd_user_preferences pref)
+/* Get total number of allocated objects per rank
+ * depends on user memory policy.
+ */
+static inline uint64_t gen_rank_num_obj(uint64_t num_user_obj,
+					axd_user_preferences pref)
 {
-	if (likely(pref != AXDIMM_ALLOC_DISTRIBUTE_ALL))
-		return num_user_objects;
+	switch (pref) {
+	case AXDIMM_ALLOC_AUTO:
+	case AXDIMM_ALLOC_REPLICATE_ALL:
+		return num_user_obj;
+	case AXDIMM_ALLOC_DISTRIBUTE_ALL:
+		/* [TODO: @p.bred] Not perfectly even distribution for a small number of objects */
+		return DIV_ROUND_UP(num_user_obj, NUM_OF_RANK);
+	}
 
-	/* [TODO: @p.bred] Not perfectly even distribution for a small number of objects */
-	return DIV_ROUND_UP(num_user_objects, NUM_OF_RANK);
+	AXDIMM_ERR("Unknown memory policy [%d]\n", pref);
+	return 0;
 }
 
-static inline uint64_t get_user_object_idx(uint64_t global_idx, uint8_t rank,
-					   uint64_t rank_num_objects,
-					   axd_user_preferences pref)
+/* Get original user object index from user request
+ * depends on user memory policy.
+ */
+static inline uint64_t get_user_obj_idx(uint64_t obj_idx, uint8_t rank,
+					uint64_t rank_num_obj,
+					axd_user_preferences pref)
 {
-	if (likely(pref != AXDIMM_ALLOC_DISTRIBUTE_ALL))
-		return global_idx - rank * rank_num_objects;
+	switch (pref) {
+	case AXDIMM_ALLOC_AUTO:
+	case AXDIMM_ALLOC_REPLICATE_ALL:
+		return obj_idx - rank * rank_num_obj;
+	case AXDIMM_ALLOC_DISTRIBUTE_ALL:
+		return obj_idx;
+	}
 
-	return global_idx;
+	AXDIMM_ERR("Unknown memory policy [%d]\n", pref);
+	return 0;
 }
 
-static int rank_insert_mem_obj(uint64_t global_idx, uint64_t rank,
-			       uint64_t rank_num_objects,
+/* Fill allocated object by the corresponding user object inside rank */
+static int rank_insert_mem_obj(uint64_t obj_idx, uint8_t rank,
+			       uint64_t rank_num_obj,
 			       struct axd_memory_object *objects,
 			       struct axd_memory_alloc_request *request,
 			       uint64_t *free_size, uint64_t *offset)
 {
 	int err_code = 0;
-	const uint64_t user_object_idx = get_user_object_idx(
-		global_idx, rank, rank_num_objects, request->preference);
-	const uint64_t user_object_length =
-		request->user_objects_sizes[user_object_idx];
+	uint64_t user_obj_size;
+	const uint64_t user_obj_idx = get_user_obj_idx(
+		obj_idx, rank, rank_num_obj, request->preference);
+
+	if (user_obj_idx >= request->num_user_objects) {
+		AXDIMM_ERR(
+			"user_obj_idx >= num_user_objects, user_obj_idx = [%llu], num_user_objects = [%llu]\n",
+			user_obj_idx, request->num_user_objects);
+		err_code = -EINVAL;
+		goto insert_out;
+	}
 
-	if (user_object_length > *free_size) {
+	user_obj_size = request->user_objects_sizes[user_obj_idx];
+	if (unlikely(!user_obj_size)) {
+		err_code = -EINVAL;
+		AXDIMM_ERR(
+			"Memory object size is zero, user_obj_idx = [%llu]\n",
+			user_obj_idx);
+		goto insert_out;
+	}
+	if (unlikely(user_obj_size > *free_size)) {
 		err_code = -ENOSPC;
-		printk(KERN_ERR
-		       "[DAX_AXDIMM_DD] No free space at rank %d, user_object_length = %llu, user_object_id = %llu\n",
-		       (int)rank, user_object_length, user_object_idx);
+		AXDIMM_ERR(
+			"No free space at rank %hhu, user_obj_size = [%llu], user_object_id = [%llu], free rank size = [%llu]\n",
+			rank, user_obj_size, user_obj_idx, *free_size);
 		goto insert_out;
 	}
 
-	objects[global_idx].rank = rank;
-	objects[global_idx].user_object_id = user_object_idx;
-	objects[global_idx].offset = *offset;
-	objects[global_idx].length = user_object_length;
+	objects[obj_idx].rank = rank;
+	objects[obj_idx].user_object_id = user_obj_idx;
+	objects[obj_idx].offset = *offset;
+	objects[obj_idx].length = user_obj_size;
 
-	*offset += user_object_length;
-	*free_size -= user_object_length;
+	*offset += user_obj_size;
+	*free_size -= user_obj_size;
 
 insert_out:
 	return err_code;
 }
 
-static int allocate_in_ranks(uint64_t num_objects,
-			     struct axdimm_allocator *alloc,
+static int allocate_in_ranks(uint64_t num_obj, struct axdimm_allocator *alloc,
 			     struct axd_memory_object *objects,
 			     struct axd_memory_alloc_request *request)
 {
 	uint8_t rank;
 	int err_code = 0;
-	uint64_t idx, next_rank_idx, offset, free_size,
+	uint64_t idx, max_idx_in_rank, offset, free_size,
 		new_ranks_offsets[NUM_OF_RANK] = {};
-	const uint64_t rank_num_objects = get_rank_num_objects(
+	const uint64_t rank_num_obj = gen_rank_num_obj(
 		request->num_user_objects, request->preference);
 
-	for (rank = 0, idx = 0; rank < NUM_OF_RANK && idx < num_objects;
-	     ++rank) {
+	for (rank = 0, idx = 0; rank < NUM_OF_RANK && idx < num_obj; ++rank) {
 		offset = alloc->ranks_mem_tracker[rank].offset;
 		free_size = alloc->ranks_mem_tracker[rank].length - offset;
-		next_rank_idx = idx + rank_num_objects;
-		for (; idx < next_rank_idx && idx < num_objects; ++idx) {
-			err_code =
-				rank_insert_mem_obj(idx, rank, rank_num_objects,
-						    objects, request,
-						    &free_size, &offset);
-			if (err_code)
+		max_idx_in_rank = idx + rank_num_obj;
+		for (; idx < max_idx_in_rank && idx < num_obj; ++idx) {
+			err_code = rank_insert_mem_obj(idx, rank, rank_num_obj,
+						       objects, request,
+						       &free_size, &offset);
+			if (unlikely(err_code))
 				goto alloc_ranks_out;
 		}
 
@@ -183,30 +218,33 @@ static int allocate_memory(struct axdimm_allocator *alloc,
 {
 	uint64_t idx;
 	int err_code = 0;
+	/* Array with allocated memory objects depends on user memory policy,
+	 * if no issues with allocation and filling by original user objects,
+	 * it's placed into allocation storage.
+	 */
 	struct axd_memory_object *objects = NULL;
-	const uint64_t num_objects =
-		get_num_objects(request->num_user_objects, request->preference);
-
-	mutex_lock(&alloc->memory_mutex);
+	/* Total number of allocated objects given the user memory policy */
+	const uint64_t num_obj =
+		gen_num_obj(request->num_user_objects, request->preference);
+	/* [TODO: s-koval] check for num_obj param sanity */
 
-	/* [TODO: s-koval] check for num_objects param sanity */
-	objects = kmalloc_array(num_objects, sizeof(struct axd_memory_object),
+	objects = kmalloc_array(num_obj, sizeof(struct axd_memory_object),
 				GFP_KERNEL);
-	if (!objects) {
-		printk(KERN_ERR
-		       "[DAX_AXDIMM_DD] No free space for memory objects, num_objects = %llu\n",
-		       num_objects);
+	if (unlikely(!objects)) {
+		AXDIMM_ERR("No free space for memory objects, num_obj = %llu\n",
+			   num_obj);
 		err_code = -ENOMEM;
 		goto alloc_out;
 	}
 
-	err_code = allocate_in_ranks(num_objects, alloc, objects, request);
-	if (err_code) {
+	mutex_lock(&alloc->memory_mutex);
+	err_code = allocate_in_ranks(num_obj, alloc, objects, request);
+	if (unlikely(err_code)) {
 		kfree(objects);
-		goto alloc_out;
+		goto alloc_unlock_out;
 	}
 
-	save_new_allocation(alloc, objects, num_objects);
+	save_new_allocation(alloc, objects, num_obj);
 
 	/* Return new descriptor to user space */
 	*descriptor = alloc->allocation_counter;
@@ -215,7 +253,7 @@ static int allocate_memory(struct axdimm_allocator *alloc,
 	for (idx = 0; idx < AXDIMM_ALLOCATION_MAX; ++idx) {
 		if (alloc->allocations[idx].descriptor == 0) {
 			alloc->available_allocation_idx = idx;
-			goto alloc_out;
+			goto alloc_unlock_out;
 		}
 	}
 
@@ -223,61 +261,54 @@ static int allocate_memory(struct axdimm_allocator *alloc,
 	 * [TODO: @s.koval] Change storage for allocations
 	 * to more appropriate one, e.g. hash table
 	 */
-	printk(KERN_ERR
-	       "[DAX_AXDIMM_DD] Next allocation won't be performed because of allocation storage capacity. Need to reset device.\n");
+	AXDIMM_ERR(
+		"Next allocation won't be performed because of allocation storage capacity. Need to reset device.\n");
 	err_code = -EBUSY;
 
-alloc_out:
+alloc_unlock_out:
 	mutex_unlock(&alloc->memory_mutex);
+alloc_out:
 	return err_code;
 }
 
-static int do_allocate_memory(struct axdimm_allocator *alloc, unsigned long __user arg)
+static int allocate_memory_ioctl(struct axdimm_allocator *alloc,
+				 unsigned long __user arg)
 {
-	int err_code = 0;
+	int err_code;
 	uint32_t array_size;
 	uint64_t descriptor;
-	struct axd_memory_alloc_request *usr_req = NULL;
 	struct axd_memory_alloc_request kernel_req;
+	struct axd_memory_alloc_request __user *usr_req =
+		(struct axd_memory_alloc_request __user *)arg;
 	uint64_t *sizes_ptr = NULL;
 
-	usr_req = (struct axd_memory_alloc_request __user *)arg;
-	if (copy_from_user(&kernel_req, usr_req,
-			   sizeof(struct axd_memory_alloc_request))) {
-		printk(KERN_ERR
-		       "[DAX_AXDIMM_DD] Can't copy allocation request from user.\n");
-		err_code = -EPERM;
+	AXDIMM_COPY_FROM_USER(err_code, &kernel_req, usr_req,
+			      sizeof(struct axd_memory_alloc_request));
+	if (unlikely(err_code))
 		goto out;
-	}
 
 	array_size = sizeof(uint64_t) * kernel_req.num_user_objects;
 	sizes_ptr = kernel_req.user_objects_sizes;
 	kernel_req.user_objects_sizes = kmalloc(array_size, GFP_KERNEL);
-	if (!kernel_req.user_objects_sizes) {
+	if (unlikely(!kernel_req.user_objects_sizes)) {
+		AXDIMM_ERR("kmalloc failed for array_size [%u]\n", array_size);
 		err_code = -ENOMEM;
 		goto out;
 	}
 
-	if (copy_from_user(kernel_req.user_objects_sizes,
-			   sizes_ptr,
-			   array_size)) {
-		printk(KERN_ERR
-		       "[DAX_AXDIMM_DD] Can't copy user objects sizes from user.\n");
-		err_code = -EPERM;
+	AXDIMM_COPY_FROM_USER(err_code, kernel_req.user_objects_sizes,
+			      sizes_ptr, array_size);
+	if (unlikely(err_code))
 		goto free_user_objects_sizes;
-	}
 	err_code = allocate_memory(alloc, &kernel_req, &descriptor);
-	if (err_code) {
-		printk(KERN_ERR "[DAX_AXDIMM_DD] Failed to allocate memory.\n");
+	if (unlikely(err_code)) {
+		AXDIMM_ERR("Failed to allocate memory.\n");
 		goto free_user_objects_sizes;
 	}
 
 	err_code = put_user(descriptor, &usr_req->descriptor);
-	if (err_code) {
-		printk(KERN_ERR
-		       "[DAX_AXDIMM_DD] Can't copy allocation descriptor to user.\n");
-		goto free_user_objects_sizes;
-	}
+	if (unlikely(err_code))
+		AXDIMM_ERR("Can't copy allocation descriptor to user.\n");
 
 free_user_objects_sizes:
 	kfree(kernel_req.user_objects_sizes);
@@ -285,94 +316,80 @@ static int do_allocate_memory(struct axdimm_allocator *alloc, unsigned long __us
 	return err_code;
 }
 
-static int get_objects_num(struct axdimm_allocator *alloc,
-						uint64_t descriptor, uint64_t *objects_num)
+static int get_num_obj(struct axdimm_allocator *alloc, uint64_t descriptor,
+		       uint64_t *num_obj)
 {
 	uint8_t allocation;
 	int err_code;
 
 	err_code = -EINVAL;
-	if (descriptor == 0)
-		goto out;
+	if (unlikely(descriptor == 0))
+		goto out_num_obj;
 
 	mutex_lock(&alloc->memory_mutex);
 	for (allocation = 0; allocation < AXDIMM_ALLOCATION_MAX; ++allocation) {
 		if (alloc->allocations[allocation].descriptor == descriptor) {
-			*objects_num = alloc->allocations[allocation].num_objects;
+			*num_obj = alloc->allocations[allocation].num_obj;
 			err_code = 0;
-			goto unlock;
+			goto unlock_num_obj;
 		}
 	}
 
-unlock:
+unlock_num_obj:
 	mutex_unlock(&alloc->memory_mutex);
-out:
+out_num_obj:
 	return err_code;
 }
 
-static int do_get_objects_num(struct axdimm_allocator *alloc, unsigned long __user arg)
+static int get_num_obj_ioctl(struct axdimm_allocator *alloc,
+			     unsigned long __user arg)
 {
-	int err_code = 0;
-	struct axd_num_objects_request *usr_get_obj_num_req = NULL;
-	struct axd_num_objects_request *kernel_get_obj_num_req = NULL;
-	uint64_t num_objects;
-
-	kernel_get_obj_num_req = kmalloc(sizeof(struct axd_num_objects_request), GFP_KERNEL);
-	usr_get_obj_num_req = (struct axd_num_objects_request __user *)arg;
-
-	if (copy_from_user(kernel_get_obj_num_req, usr_get_obj_num_req,
-						sizeof(struct axd_num_objects_request))) {
-		printk(KERN_ERR
-		       "[DAX_AXDIMM_DD] Can't copy get objects num request from user.\n");
-		err_code = -EPERM;
-		goto free_num_objects_request;
-	}
-	err_code = get_objects_num(alloc, kernel_get_obj_num_req->descriptor, &num_objects);
-	if (err_code) {
-		printk(KERN_ERR
-		       "[DAX_AXDIMM_DD] Can't get objects number by allocation descriptor [%llu]\n",
-		       kernel_get_obj_num_req->descriptor);
-		goto free_num_objects_request;
-	}
-
-	kernel_get_obj_num_req->num_objects = num_objects;
-	if (copy_to_user(usr_get_obj_num_req, kernel_get_obj_num_req,
-					 sizeof(struct axd_num_objects_request))) {
-		printk(KERN_ERR
-			   "[DAX_AXDIMM_DD] can't copy objects number request to user.\n");
-		err_code = -EPERM;
-		goto free_num_objects_request;
+	int err_code;
+	uint64_t num_obj;
+	struct axd_num_objects_request __user *usr_get_num_obj_req =
+		(struct axd_num_objects_request __user *)arg;
+	struct axd_num_objects_request kernel_get_num_obj_req = {};
+
+	AXDIMM_COPY_FROM_USER(err_code, &kernel_get_num_obj_req,
+			      usr_get_num_obj_req,
+			      sizeof(struct axd_num_objects_request));
+	if (unlikely(err_code))
+		goto out_num_obj_ioctl;
+
+	err_code =
+		get_num_obj(alloc, kernel_get_num_obj_req.descriptor, &num_obj);
+	if (unlikely(err_code)) {
+		AXDIMM_ERR(
+			"Can't get number of objects by allocation descriptor [%llu]\n",
+			kernel_get_num_obj_req.descriptor);
+		goto out_num_obj_ioctl;
 	}
-free_num_objects_request:
-	kfree(kernel_get_obj_num_req);
 
+	kernel_get_num_obj_req.num_objects = num_obj;
+	AXDIMM_COPY_TO_USER(err_code, usr_get_num_obj_req,
+			    &kernel_get_num_obj_req,
+			    sizeof(struct axd_num_objects_request));
+out_num_obj_ioctl:
 	return err_code;
 }
 
-static int get_memory_allocation(struct axdimm_allocator *alloc, struct axd_memory_alloc *request)
+static int get_allocation(struct axdimm_allocator *alloc,
+			  struct axd_memory_alloc *request)
 {
 	uint8_t allocation;
-	int err_code;
+	int err_code = -EINVAL;
 
-	err_code = -EINVAL;
-	if (request->descriptor == 0)
+	if (unlikely(request->descriptor == 0))
 		goto out;
 
 	mutex_lock(&alloc->memory_mutex);
 	for (allocation = 0; allocation < AXDIMM_ALLOCATION_MAX; ++allocation) {
 		if (alloc->allocations[allocation].descriptor == request->descriptor) {
-			if (copy_to_user(
-				    request->objects,
-				    alloc->allocations[allocation].objects,
-				    alloc->allocations[allocation].num_objects *
-					    sizeof(struct axd_memory_object)
-						)) {
-				printk(KERN_WARNING
-				       "[DAX_AXDIMM_DD] can't copy allocation choice to user.\n");
-				err_code = -EPERM;
-				goto unlock;
-			}
-			err_code = 0;
+			AXDIMM_COPY_TO_USER(
+				err_code, request->objects,
+				alloc->allocations[allocation].objects,
+				alloc->allocations[allocation].num_obj *
+					sizeof(struct axd_memory_object));
 			goto unlock;
 		}
 	}
@@ -383,42 +400,35 @@ static int get_memory_allocation(struct axdimm_allocator *alloc, struct axd_memo
 	return err_code;
 }
 
-static int do_get_allocation(struct axdimm_allocator *alloc, unsigned long __user arg)
+static int get_allocation_ioctl(struct axdimm_allocator *alloc,
+				unsigned long __user arg)
 {
-	int err_code = 0;
-	struct axd_memory_alloc *usr_get_alloc_req = NULL;
-	struct axd_memory_alloc *kernel_get_alloc_req = NULL;
-
-	usr_get_alloc_req = (struct axd_memory_alloc __user *)arg;
-	kernel_get_alloc_req = kmalloc(sizeof(struct axd_memory_alloc), GFP_KERNEL);
-	if (copy_from_user(kernel_get_alloc_req, usr_get_alloc_req,
-						sizeof(struct axd_memory_alloc))) {
-		printk(KERN_ERR
-		       "[DAX_AXDIMM_DD] Can't copy get allocation request from user.\n");
-		err_code = -EPERM;
-		goto free_memory_alloc_request;
-	}
-	err_code = get_memory_allocation(alloc, kernel_get_alloc_req);
-	if (err_code) {
-		printk(KERN_ERR
-		       "[DAX_AXDIMM_DD] Can't get allocation by allocation descriptor [%llu]\n",
-		       kernel_get_alloc_req->descriptor);
-		goto free_memory_alloc_request;
-	}
-
-free_memory_alloc_request:
-	kfree(kernel_get_alloc_req);
-
+	int err_code;
+	struct axd_memory_alloc __user *usr_get_alloc_req =
+		(struct axd_memory_alloc __user *)arg;
+	struct axd_memory_alloc kernel_get_alloc_req = {};
+
+	AXDIMM_COPY_FROM_USER(err_code, &kernel_get_alloc_req,
+			      usr_get_alloc_req,
+			      sizeof(struct axd_memory_alloc));
+	if (unlikely(err_code))
+		goto out_get_alloc;
+	err_code = get_allocation(alloc, &kernel_get_alloc_req);
+	if (unlikely(err_code))
+		AXDIMM_ERR(
+			"Can't get allocation by allocation descriptor [%llu]\n",
+			kernel_get_alloc_req.descriptor);
+
+out_get_alloc:
 	return err_code;
 }
 
 static int deallocate_memory(struct axdimm_allocator *alloc, uint64_t descriptor)
 {
 	uint8_t allocation;
-	int err_code;
+	int err_code = -EINVAL;
 
-	err_code = -EINVAL;
-	if (descriptor == 0)
+	if (unlikely(descriptor == 0))
 		goto out;
 
 	mutex_lock(&alloc->memory_mutex);
@@ -426,10 +436,9 @@ static int deallocate_memory(struct axdimm_allocator *alloc, uint64_t descriptor
 		if (alloc->allocations[allocation].descriptor != descriptor)
 			continue;
 
-		alloc->allocations[allocation].descriptor = 0;
-		alloc->allocations[allocation].num_objects = 0;
 		kfree(alloc->allocations[allocation].objects);
-		alloc->allocations[allocation].objects = NULL;
+		memset(&alloc->allocations[allocation], 0,
+		       sizeof(alloc->allocations[allocation]));
 		err_code = 0;
 		goto unlock;
 	}
@@ -440,36 +449,34 @@ static int deallocate_memory(struct axdimm_allocator *alloc, uint64_t descriptor
 	return err_code;
 }
 
-static int do_deallocate_memory(struct axdimm_allocator *alloc, unsigned long __user arg)
+static int deallocate_memory_ioctl(struct axdimm_allocator *alloc,
+				   unsigned long __user arg)
 {
-	int err_code = 0;
+	/* [TODO: @p.bred] we assume descriptor is uint64_t,
+	 * however in this method it's truncated to unsigned long.
+	 */
 	uint64_t in_descriptor = (uint64_t)arg;
 
-	err_code = deallocate_memory(alloc, in_descriptor);
-	if (err_code) {
-		printk(KERN_ERR
-		       "[DAX_AXDIMM_DD] Can't deallocate memory by allocation descriptor [%llu]\n",
-		       in_descriptor);
-		goto out;
-	}
-out:
-	return err_code;
+	return deallocate_memory(alloc, in_descriptor);
 }
 
-int do_allocation_logic(struct axdimm_allocator *alloc, unsigned int cmd,
-			unsigned long __user arg)
+int mem_process_ioctl(unsigned int cmd, struct axdimm_allocator *alloc,
+		      unsigned long __user arg)
 {
 	switch (cmd) {
 	case ALLOCATE_MEMORY:
-		return do_allocate_memory(alloc, arg);
+		return allocate_memory_ioctl(alloc, arg);
 	case GET_MEMORY_OBJECTS_NUM:
-		return do_get_objects_num(alloc, arg);
+		return get_num_obj_ioctl(alloc, arg);
 	case GET_MEMORY_ALLOCATION:
-		return do_get_allocation(alloc, arg);
+		return get_allocation_ioctl(alloc, arg);
 	case DEALLOCATE_MEMORY:
-		return do_deallocate_memory(alloc, arg);
+		return deallocate_memory_ioctl(alloc, arg);
 	default:
-		printk(KERN_ERR "[DAX_AXDIMM_DD] Unknown allocation command [%u]\n", cmd);
-		return -EINVAL;
+		AXDIMM_ERR(
+			"Unknown memory operation [%u], with argument [%lu]\n",
+			cmd, arg);
 	}
+
+	return -EINVAL;
 }
diff --git a/drivers/dax/axdimm_allocator.h b/drivers/dax/axdimm_allocator.h
index 2753a158e..4bf80f2f1 100644
--- a/drivers/dax/axdimm_allocator.h
+++ b/drivers/dax/axdimm_allocator.h
@@ -18,7 +18,7 @@ struct axdimm_allocator {
 	/* Simple storage for memory allocations */
 	struct {
 		uint64_t descriptor;
-		uint64_t num_objects;
+		uint64_t num_obj;
 		struct axd_memory_object *objects;
 	} allocations[AXDIMM_ALLOCATION_MAX];
 	/* Index shows where to store allocation info in "allocations" array */
@@ -33,8 +33,8 @@ void init_axdimm_allocator(struct axdimm_allocator *alloc,
 /* Not proccess(thread)-safe */
 void reset_axdimm_allocator(struct axdimm_allocator *alloc);
 void cleanup_axdimm_allocator(struct axdimm_allocator *alloc);
-int do_allocation_logic(struct axdimm_allocator *alloc, unsigned int cmd,
-			unsigned long arg);
+int mem_process_ioctl(unsigned int cmd, struct axdimm_allocator *alloc,
+		      unsigned long __user arg);
 
 #endif
 
diff --git a/drivers/dax/axdimm_log.h b/drivers/dax/axdimm_log.h
new file mode 100644
index 000000000..b120a5c16
--- /dev/null
+++ b/drivers/dax/axdimm_log.h
@@ -0,0 +1,18 @@
+/* SPDX-License-Identifier: GPL-2.0 */
+/* Copyright(c) 2022 Samsung LTD. All rights reserved. */
+
+#ifndef __AXDIMM_LOG_H__
+#define __AXDIMM_LOG_H__
+
+#include <linux/kernel.h>
+
+#define AXDIMM_DD_MARK "[DAX_AXDIMM_DD]"
+
+#define AXDIMM_PRINT(level, fmt, ...)                                          \
+	printk(level AXDIMM_DD_MARK "[%s:%d] " fmt, __FILE__, __LINE__,        \
+	       ##__VA_ARGS__)
+#define AXDIMM_ERR(fmt, ...) AXDIMM_PRINT(KERN_ERR, fmt, ##__VA_ARGS__)
+#define AXDIMM_WRN(fmt, ...) AXDIMM_PRINT(KERN_WARNING, fmt, ##__VA_ARGS__)
+#define AXDIMM_INF(fmt, ...) AXDIMM_PRINT(KERN_INFO, fmt, ##__VA_ARGS__)
+
+#endif /* __AXDIMM_LOG_H__ */
-- 
2.34.1

