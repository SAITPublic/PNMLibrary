From 265f6d8e4147338d792b16f42e6249c60cfb20e8 Mon Sep 17 00:00:00 2001
From: Aleksandr Korzun <a.korzun@partner.samsung.com>
Date: Wed, 28 Sep 2022 17:28:48 +0300
Subject: [PATCH 051/161] [drivers/dax/axdimm] Add more debug logs.

Add `AXDIMM_DBG` logs to various places (allocator,
rank scheduler, init/cleanup functions, ioctl handler).
Also, add a few other log messages and turn `AXDIMM_INF`
to `AXDIMM_DBG` where appropriate.

References: AXDIMM-372

Signed-off-by: Aleksandr Korzun <a.korzun@partner.samsung.com>
---
 drivers/dax/axdimm.c                | 13 +++++++++++--
 drivers/dax/axdimm_allocator.c      | 26 ++++++++++++++++++++++++++
 drivers/dax/axdimm_rank_scheduler.c | 25 ++++++++++++++++++++++++-
 drivers/dax/axdimm_sysfs.c          | 18 ++++++++++++++++++
 4 files changed, 79 insertions(+), 3 deletions(-)

diff --git a/drivers/dax/axdimm.c b/drivers/dax/axdimm.c
index e99adc5b9..0df6cb850 100644
--- a/drivers/dax/axdimm.c
+++ b/drivers/dax/axdimm.c
@@ -275,6 +275,8 @@ long axdimm_ioctl(struct file *filp, unsigned int cmd, unsigned long __user arg)
 	int err = 0;
 	int retval = 0;
 
+	AXDIMM_DBG("Handling ioctl(cmd = 0x%x, arg = 0x%lx)\n", cmd, arg);
+
 	/*
 	 * extract the type and number bitfields, and don't decode
 	 * wrong cmds: return ENOTTY (inappropriate ioctl) before access_ok()
@@ -303,8 +305,10 @@ long axdimm_ioctl(struct file *filp, unsigned int cmd, unsigned long __user arg)
 	} else if (_IOC_DIR(cmd) & _IOC_WRITE) {
 		err = !access_ok((void __user *)arg, _IOC_SIZE(cmd));
 	}
-	if (err)
+	if (err) {
+		AXDIMM_ERR("Cannot access user memory at 0x%lx\n", arg);
 		return -EFAULT;
+	}
 
 	switch (cmd) {
 	case DEVICE_IOCRESET:
@@ -342,9 +346,10 @@ long axdimm_ioctl(struct file *filp, unsigned int cmd, unsigned long __user arg)
 		retval = release_axdimm_rank(&axdimm_rank_sched, cmd, arg);
 		break;
 	default:
-		return retval;
+		AXDIMM_ERR("Unknown ioctl command 0x%x\n", cmd);
 	}
 
+	AXDIMM_DBG("Returning %d from ioctl\n", retval);
 	return retval;
 }
 
@@ -352,6 +357,8 @@ int init_axdimm_device(struct dev_dax *dev_dax)
 {
 	int err;
 
+	AXDIMM_DBG("Initializing AXDIMM device\n");
+
 	/* Mark DAX device as AXDIMM, this is used in mmap implementation */
 	dev_dax->is_axdimm_device = 1;
 
@@ -384,6 +391,8 @@ int init_axdimm_device(struct dev_dax *dev_dax)
 
 void cleanup_axdimm_device()
 {
+	AXDIMM_DBG("Cleaning up AXDIMM device\n");
+
 	/* Free allocated memory */
 	cleanup_axdimm_allocator(&axdimm_allocator);
 
diff --git a/drivers/dax/axdimm_allocator.c b/drivers/dax/axdimm_allocator.c
index 269d689b6..2ff8a3114 100644
--- a/drivers/dax/axdimm_allocator.c
+++ b/drivers/dax/axdimm_allocator.c
@@ -36,6 +36,10 @@ static int init_memory_trees_and_size(struct axdimm_allocator *alloc,
 				goto init_mem_trees_out;
 			}
 			/* Initialize tree size */
+			AXDIMM_DBG(
+				"Initialized allocator tree for rank %x with size 0x%llx\n",
+				cs_rank_idx,
+				length);
 			alloc->ranks_free_sizes[cs_rank_idx] = length;
 		}
 	}
@@ -50,6 +54,8 @@ int init_axdimm_allocator(struct axdimm_allocator *alloc,
 {
 	int err_code;
 
+	AXDIMM_DBG("Initializing AXDIMM allocator\n");
+
 	alloc->descriptor_counter = 0;
 
 	err_code = init_memory_trees_and_size(alloc, mem_info);
@@ -73,6 +79,8 @@ int reset_axdimm_allocator(struct axdimm_allocator *alloc,
 	struct list_head *cur, *n;
 	struct axdimm_allocation *entry;
 
+	AXDIMM_DBG("Resetting AXDIMM allocator\n");
+
 	if (unlikely(mutex_is_locked(&alloc->memory_mutex))) {
 		AXDIMM_WRN("Mutex unlock forced.\n");
 		mutex_unlock(&alloc->memory_mutex);
@@ -99,6 +107,7 @@ int reset_axdimm_allocator(struct axdimm_allocator *alloc,
 
 void cleanup_axdimm_allocator(struct axdimm_allocator *alloc)
 {
+	AXDIMM_DBG("Cleaning up AXDIMM allocator\n");
 	reset_axdimm_allocator(alloc, NULL);
 	mutex_destroy(&alloc->memory_mutex);
 }
@@ -223,6 +232,12 @@ static int rank_insert_mem_obj(struct axdimm_allocator *alloc, uint64_t obj_idx,
 	}
 
 	alloc->ranks_free_sizes[rank] -= user_obj_size;
+	AXDIMM_DBG(
+		"Allocated chunk: rank %x, user object index %llu, offset 0x%llx, length %llu\n",
+		rank,
+		user_obj_idx,
+		offset,
+		user_obj_size);
 
 	objects[obj_idx].rank = rank;
 	objects[obj_idx].user_object_id = user_obj_idx;
@@ -307,6 +322,8 @@ static int allocate_memory(struct axdimm_allocator *alloc,
 		gen_num_obj(request->num_user_objects, request->preference);
 	/* [TODO: s-koval] check for num_obj param sanity */
 
+	AXDIMM_DBG("Allocating memory for %llu objects\n", num_obj);
+
 	objects = kmalloc_array(num_obj, sizeof(struct axd_memory_object),
 				GFP_KERNEL);
 	if (unlikely(!objects)) {
@@ -324,6 +341,8 @@ static int allocate_memory(struct axdimm_allocator *alloc,
 			AXDIMM_ERR("Failed partial deallocate\n");
 
 		kfree(objects);
+		AXDIMM_DBG("Partial allocation freed for %llu objects\n",
+			   actual_num);
 		goto alloc_unlock_out;
 	}
 
@@ -336,6 +355,9 @@ static int allocate_memory(struct axdimm_allocator *alloc,
 	/* Return new descriptor to user space */
 	*descriptor = alloc->descriptor_counter;
 
+	AXDIMM_DBG("Allocation succeeded, returning descriptor [%llu]\n",
+		   *descriptor);
+
 alloc_unlock_out:
 	mutex_unlock(&alloc->memory_mutex);
 alloc_out:
@@ -407,6 +429,7 @@ static int get_num_obj(struct axdimm_allocator *alloc, uint64_t descriptor,
 		allocation = list_entry(ptr, struct axdimm_allocation, list);
 		if (allocation->descriptor == descriptor) {
 			*num_obj = allocation->num_obj;
+			AXDIMM_DBG("Number of objects: %llu\n", *num_obj);
 			err_code = 0;
 			goto unlock_num_obj;
 		}
@@ -457,6 +480,7 @@ static int get_allocation(struct axdimm_allocator *alloc,
 	struct list_head *ptr;
 	struct axdimm_allocation *allocation;
 
+	AXDIMM_DBG("Getting allocation for descriptor %llu\n", request->descriptor);
 	if (unlikely(request->descriptor == 0))
 		goto out;
 
@@ -513,6 +537,8 @@ int deallocate_memory(struct axdimm_allocator *alloc, uint64_t descriptor)
 	struct list_head *cur, *n;
 	struct axdimm_allocation *allocation;
 
+	AXDIMM_DBG("Deallocating memory (descriptor [%llu])\n", descriptor);
+
 	if (unlikely(descriptor == 0))
 		goto out;
 
diff --git a/drivers/dax/axdimm_rank_scheduler.c b/drivers/dax/axdimm_rank_scheduler.c
index 0d8f46705..70aef44e3 100644
--- a/drivers/dax/axdimm_rank_scheduler.c
+++ b/drivers/dax/axdimm_rank_scheduler.c
@@ -53,12 +53,17 @@ static void find_free_ranks(struct axdimm_rank_scheduler *rank_sched,
 			}
 		}
 	}
+
+	AXDIMM_DBG("Find free ranks: rw = 0x%x, wo = 0x%x for mask = 0x%x",
+		   *rw_msk, *wo_msk, msk);
 }
 
 void reset_axdimm_rank_scheduler(struct axdimm_rank_scheduler *rank_sched)
 {
 	size_t rank;
 
+	AXDIMM_DBG("Resetting AXDIMM rank scheduler\n");
+
 	/* set all ranks as idle */
 	for (rank = 0; rank < NUM_OF_RANK; rank++) {
 		rank_sched->axd_rank_stats[rank].wr_stat = IDLE_STATE;
@@ -85,8 +90,10 @@ static int get_rank_write(struct axdimm_rank_scheduler *rank_sched,
 	unsigned int rw_mask = 0;
 	unsigned int wo_mask = 0;
 
+	AXDIMM_DBG("Acquiring rank for write (mask 0x%x)\n", msk);
+
 	if (msk > MAX_MSK_VAL) {
-		AXDIMM_ERR("Invalid mask value: %x\n", msk);
+		AXDIMM_ERR("Invalid mask value: 0x%x\n", msk);
 		return ret;
 	}
 
@@ -100,6 +107,11 @@ static int get_rank_write(struct axdimm_rank_scheduler *rank_sched,
 
 	mutex_unlock(&rank_sched->rank_stat_lock);
 
+	if (ret < 0)
+		AXDIMM_DBG("No free rank for write\n");
+	else
+		AXDIMM_DBG("Acquired rank %x for write\n", (unsigned int)ret);
+
 	return ret;
 }
 
@@ -109,6 +121,8 @@ static int get_rank_read(struct axdimm_rank_scheduler *rank_sched,
 	int ret = -1;
 	struct axdimm_rank_stat_t *axd_rs = rank_sched->axd_rank_stats;
 
+	AXDIMM_DBG("Acquiring rank %x for read\n", rank_id);
+
 	if (rank_id > (NUM_OF_RANK - 1)) {
 		AXDIMM_ERR("Invalid rank value: %x\n", rank_id);
 		return ret;
@@ -123,6 +137,11 @@ static int get_rank_read(struct axdimm_rank_scheduler *rank_sched,
 
 	mutex_unlock(&rank_sched->rank_stat_lock);
 
+	if (ret < 0)
+		AXDIMM_DBG("Could not acquire rank %x for read\n", rank_id);
+	else
+		AXDIMM_DBG("Acquired rank %x for read\n", rank_id);
+
 	return ret;
 }
 
@@ -132,6 +151,8 @@ int release_rank_write(struct axdimm_rank_scheduler *rank_sched,
 	int ret = rank_id;
 	struct axdimm_rank_stat_t *axd_rs = rank_sched->axd_rank_stats;
 
+	AXDIMM_DBG("Releasing rank %x for write\n", rank_id);
+
 	if (rank_id > (NUM_OF_RANK - 1)) {
 		AXDIMM_ERR("Invalid rank value: %x\n", rank_id);
 		return -1;
@@ -150,6 +171,8 @@ int release_rank_read(struct axdimm_rank_scheduler *rank_sched,
 	int ret = rank_id;
 	struct axdimm_rank_stat_t *axd_rs = rank_sched->axd_rank_stats;
 
+	AXDIMM_DBG("Releasing rank %x for read\n", rank_id);
+
 	if (rank_id > (NUM_OF_RANK - 1)) {
 		AXDIMM_ERR("Invalid rank value: %x\n", rank_id);
 		return -1;
diff --git a/drivers/dax/axdimm_sysfs.c b/drivers/dax/axdimm_sysfs.c
index bafd59bee..f053b84ed 100644
--- a/drivers/dax/axdimm_sysfs.c
+++ b/drivers/dax/axdimm_sysfs.c
@@ -43,6 +43,7 @@ static ssize_t acq_timeout_store(struct device *device,
 			buf);
 		return -EINVAL;
 	}
+	AXDIMM_DBG("Setting acq_timeout to %llu ns via sysfs\n", acq_timeout);
 	atomic64_set(&axdimm_rank_sched.retry_timeout_ns, acq_timeout);
 	return count;
 }
@@ -52,8 +53,15 @@ static ssize_t reset_store(struct device *device, struct device_attribute *attr,
 			   const char *buf, size_t count)
 {
 	if (sysfs_streq(buf, "1")) {
+		AXDIMM_DBG("Resetting AXDIMM device via sysfs\n");
 		if (axdimm_ioctl(NULL, DEVICE_IOCRESET, 0))
 			AXDIMM_ERR("Failed to reset device via sysfs.\n");
+	} else {
+		// Usual behavior is to silently ignore this, so there is no reason
+		// to make it an AXDIMM_WRN.
+		AXDIMM_DBG(
+			"Ignoring invalid value ('%s') written into sysfs 'reset' file\n",
+			buf);
 	}
 
 	return count;
@@ -309,6 +317,8 @@ static int build_rank_sysfs(struct kobject *kobj, uint8_t rank)
 	char buf[4];
 	int err;
 
+	AXDIMM_DBG("Building AXDIMM sysfs for rank %u\n", rank);
+
 	kobject_init(&ranks_fs[rank].rank_idx_kobj, &rank_type);
 	sprintf(buf, "%u", rank);
 	err = kobject_add(&ranks_fs[rank].rank_idx_kobj, kobj, buf);
@@ -339,6 +349,8 @@ int build_axdimm_sysfs(struct kobject *kobj)
 	int rank;
 	int err = 0;
 
+	AXDIMM_DBG("Building AXDIMM sysfs\n");
+
 	ranks_kobj = kobject_create_and_add("ranks", kobj);
 	if (sysfs_create_groups(ranks_kobj, dev_attr_groups)) {
 		err = -ENOMEM;
@@ -354,6 +366,8 @@ int build_axdimm_sysfs(struct kobject *kobj)
 		}
 	}
 
+	AXDIMM_DBG("Built AXDIMM sysfs\n");
+
 axdimm_sysfs_out:
 	return err;
 }
@@ -362,6 +376,8 @@ void destroy_axdimm_sysfs(void)
 {
 	int rank;
 
+	AXDIMM_DBG("Destroying AXDIMM sysfs\n");
+
 	for (rank = 0; rank < NUM_OF_RANK; ++rank) {
 		sysfs_remove_groups(&ranks_fs[rank].regions_fs.regions_kobj,
 				    ranks_fs[rank].regions_fs.groups);
@@ -372,4 +388,6 @@ void destroy_axdimm_sysfs(void)
 
 	sysfs_remove_groups(ranks_kobj, dev_attr_groups);
 	kobject_del(ranks_kobj);
+
+	AXDIMM_DBG("Destroyed AXDIMM sysfs\n");
 }
-- 
2.34.1

