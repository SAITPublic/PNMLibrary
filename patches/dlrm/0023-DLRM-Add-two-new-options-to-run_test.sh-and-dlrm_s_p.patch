From 7e00eeecbb1cb35deec1b0bae88582fb08cea2b6 Mon Sep 17 00:00:00 2001
From: Maxim Ostapenko <maxim.o@samsung.com>
Date: Fri, 11 Aug 2023 04:06:17 +0000
Subject: [PATCH 23/24] [DLRM] Add two new options to run_test.sh and
 dlrm_s_pytorch.py

* "--num_batches": to contol number of inferences from run_test.sh.
* "--user-triggers-inference": allow dlrm_s_pytorch.py to wait for
  user's trigger action before starting inferences. This is useful for
  PNM performance simulator to filter out tables loading traffic.

Signed-off-by: Maxim Ostapenko <maxim.o@samsung.com>
---
 dlrm_s_pytorch.py |  5 +++++
 run_test.sh       | 10 +++++++++-
 2 files changed, 14 insertions(+), 1 deletion(-)

diff --git a/dlrm_s_pytorch.py b/dlrm_s_pytorch.py
index acaaa89..cc4e67c 100644
--- a/dlrm_s_pytorch.py
+++ b/dlrm_s_pytorch.py
@@ -886,6 +886,10 @@ def inference(
         test_loads.append(testBatch)
 
     print("Make {} runs to warmup".format(args.warmup_runs))
+
+    if args.user_triggers_inference:
+        input("Waiting for users trigger, please press Enter to start inference...")
+
     for i in range(args.warmup_runs):
         process_batch(device, use_gpu, test_loads[0])
 
@@ -1121,6 +1125,7 @@ def run():
     sls_dev_interfaces = {"AXDIMM" : PnmDeviceInterface.AXDIMM, "CXL" : PnmDeviceInterface.CXL}
     parser.add_argument("--sls_device_interface", action="store", type=str, choices=sls_dev_interfaces.keys(), 
                         default="AXDIMM", help="The device type for SLS operation.")
+    parser.add_argument("--user-triggers-inference", action="store_true", default=False)
 
     global args
     global nbatches
diff --git a/run_test.sh b/run_test.sh
index 1802629..c5cf92d 100755
--- a/run_test.sh
+++ b/run_test.sh
@@ -18,6 +18,7 @@ script_run_command="python3"
 script_dir=$(dirname "$0")
 warmup_runs=1
 sls_device_interface='AXDIMM'
+user_triggers_inference_opt=""
 
 while [ "$#" -ne 0 ]
 do
@@ -42,6 +43,13 @@ do
         shift
         sls_device_interface=$1
         ;;
+    "--num_batches")
+        shift
+        num_batches=$1
+        ;;
+    "--user-triggers-inference")
+        user_triggers_inference_opt="--user-triggers-inference"
+        ;;
 esac
     shift
 done
@@ -59,4 +67,4 @@ $script_run_command $script_dir/dlrm_s_pytorch.py --arch-embedding-size="$embedd
                             --arch-sparse-feature-size="$sparse_feature_size" --mini-batch-size="$mini_batch_size" --num-indices-per-lookup-fixed="$num_indices_per_lookup_fixed" \
                             --num-indices-per-lookup="$num_indices_per_lookup" --arch-interaction-op="$interaction_op" --num-batches="$num_batches" \
                             --use-pnm "$pnm_tensor_type" --weights-path "$weights_path" --warmup_runs=$warmup_runs --inference-only \
-                            --sls_device_interface "$sls_device_interface"
+                            --sls_device_interface "$sls_device_interface" $user_triggers_inference_opt
-- 
2.34.1

