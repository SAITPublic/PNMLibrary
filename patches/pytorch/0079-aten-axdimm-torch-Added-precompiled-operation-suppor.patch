From af7a1ea2807254f8312506746a09250b0dd73fa8 Mon Sep 17 00:00:00 2001
From: Nikita Enin <n.enin@samsung.com>
Date: Mon, 24 Oct 2022 23:28:24 +0300
Subject: [PATCH 079/135] [aten,axdimm,torch] Added precompiled operation
 support for embedding bag axdimm operator

Resolves: AXDIMM-452

Signed-off-by: Nikita Enin <n.enin@samsung.com>
---
 .../native/axdimm/AxdimmPrecompiledOp.cpp     | 78 +++++++++++++++++++
 .../ATen/native/axdimm/AxdimmPrecompiledOp.h  | 47 +++++++++++
 .../ATen/native/axdimm/ops/EmbeddingBag.cpp   | 39 ++++++----
 torch/nn/modules/sparse.py                    | 12 ++-
 4 files changed, 159 insertions(+), 17 deletions(-)
 create mode 100644 aten/src/ATen/native/axdimm/AxdimmPrecompiledOp.cpp
 create mode 100644 aten/src/ATen/native/axdimm/AxdimmPrecompiledOp.h

diff --git a/aten/src/ATen/native/axdimm/AxdimmPrecompiledOp.cpp b/aten/src/ATen/native/axdimm/AxdimmPrecompiledOp.cpp
new file mode 100644
index 00000000..d24fbbc7
--- /dev/null
+++ b/aten/src/ATen/native/axdimm/AxdimmPrecompiledOp.cpp
@@ -0,0 +1,78 @@
+#include <ATen/native/axdimm/AxdimmPrecompiledOp.h>
+
+#include <algorithm>
+
+namespace at {
+namespace native {
+namespace axdimm {
+
+std::unordered_map<intptr_t, OpPtr> AxdimmPrecompiledOp::g_precompiled_ops_;
+
+AxdimmPrecompiledOp::AxdimmPrecompiledOp(
+    const at::Tensor& weights,
+    const at::Tensor& offsets) {
+  const auto num_tables = offsets.sizes()[0];
+  const auto minibatch_size = offsets.sizes()[1] - 1;
+  const AxdimmTensor& ten = convert(weights);
+  lookups_.reserve(num_tables);
+
+  auto batch = static_cast<const uint32_t*>(offsets.data_ptr());
+  for (size_t table_idx = 0; table_idx < num_tables; ++table_idx) {
+    lookups_.push_back(batch[1]);
+    batch += minibatch_size + 1;
+  }
+
+  TORCH_INTERNAL_ASSERT_DEBUG_ONLY(
+      std::adjacent_find(
+          std::begin(lookups_), std::end(lookups_), std::not_equal_to<>()) ==
+      std::end(lookups_));
+
+  op_id_ = create_precompiled_op(
+      minibatch_size,
+      ten.get_sparse_feature_size(),
+      ten.get_num_tables(),
+      const_cast<uint32_t*>(ten.get_tables_rows_num().data()),
+      lookups_.data(),
+      ten.get_tables_layout(),
+      ten.get_sls_type());
+}
+
+AxdimmPrecompiledOp::~AxdimmPrecompiledOp() {
+  g_precompiled_ops_.erase(op_id_);
+}
+
+intptr_t AxdimmPrecompiledOp::get_precompiled_op_id() const {
+  return op_id_;
+}
+
+AxdimmOperation* AxdimmPrecompiledOp::get_precompiled_op_by_id(
+    intptr_t id) {
+  auto op_it = g_precompiled_ops_.find(id);
+  TORCH_INTERNAL_ASSERT(
+      op_it != std::end(g_precompiled_ops_),
+      "Precompiled operation should exist");
+  return op_it->second.get();
+}
+
+template <typename... Args>
+intptr_t AxdimmPrecompiledOp::create_precompiled_op(Args&&... args) {
+  auto op_ptr = OpPtr(
+      axdimm_create_sls_op(std::forward<Args>(args)...),
+      [](AxdimmOperation* op) { axdimm_destroy_op(op); });
+  TORCH_CHECK(op_ptr, "Failed to create AxdimmOperation");
+  auto op_id = reinterpret_cast<intptr_t>(op_ptr.get());
+  g_precompiled_ops_.emplace(op_id, std::move(op_ptr));
+  return op_id;
+}
+
+TORCH_LIBRARY(axdimm_helpers, m) {
+  m.class_<AxdimmPrecompiledOp>("AxdimmPrecompiledOp")
+      .def(torch::init<const at::Tensor&, const at::Tensor&>())
+      .def(
+          "get_precompiled_op_id",
+          &AxdimmPrecompiledOp::get_precompiled_op_id);
+}
+
+} // namespace axdimm
+} // namespace native
+} // namespace at
diff --git a/aten/src/ATen/native/axdimm/AxdimmPrecompiledOp.h b/aten/src/ATen/native/axdimm/AxdimmPrecompiledOp.h
new file mode 100644
index 00000000..9265ab44
--- /dev/null
+++ b/aten/src/ATen/native/axdimm/AxdimmPrecompiledOp.h
@@ -0,0 +1,47 @@
+#ifndef __AXDIMM_OPERATIONS_STORAGE__
+#define __AXDIMM_OPERATIONS_STORAGE__
+
+#include "ai/api/axdimm.h"
+
+#include <ATen/native/axdimm/AxdimmTensor.h>
+
+#include <functional>
+#include <memory>
+#include <unordered_map>
+
+namespace at {
+namespace native {
+namespace axdimm {
+
+using OpPtr =
+    std::unique_ptr<AxdimmOperation, std::function<void(AxdimmOperation*)>>;
+
+/*!
+ * Class for precompiled axdimm operations management.
+ * Available in python via: torch.classes.axdimm_helpers.AxdimmPrecompiledOp
+ */
+class AxdimmPrecompiledOp : public torch::CustomClassHolder {
+ public:
+  AxdimmPrecompiledOp(const at::Tensor& weights, const at::Tensor& offsets);
+  ~AxdimmPrecompiledOp() override;
+
+  intptr_t get_precompiled_op_id() const;
+  static AxdimmOperation* get_precompiled_op_by_id(intptr_t id);
+
+ private:
+  template <typename... Args>
+  static intptr_t create_precompiled_op(Args&&... args);
+
+  std::vector<uint32_t> lookups_;
+  intptr_t op_id_{-1};
+
+  // Global state is required to store precompiled operations,
+  // since there's no simple way to pass operation object to aten operator
+  static std::unordered_map<intptr_t, OpPtr> g_precompiled_ops_;
+};
+
+} // namespace axdimm
+} // namespace native
+} // namespace at
+
+#endif
diff --git a/aten/src/ATen/native/axdimm/ops/EmbeddingBag.cpp b/aten/src/ATen/native/axdimm/ops/EmbeddingBag.cpp
index 6d0c85d9..8f5d0c07 100644
--- a/aten/src/ATen/native/axdimm/ops/EmbeddingBag.cpp
+++ b/aten/src/ATen/native/axdimm/ops/EmbeddingBag.cpp
@@ -1,4 +1,5 @@
 #include <ATen/native/axdimm/AxdimmOpaqueTensor.h>
+#include <ATen/native/axdimm/AxdimmPrecompiledOp.h>
 #include <ATen/native/axdimm/AxdimmTensor.h>
 
 #include <torch/autograd.h>
@@ -15,9 +16,7 @@ void transform_offsets(
   auto batch = static_cast<const uint32_t*>(offsets.data_ptr());
   for (size_t table_idx = 0; table_idx < num_tables; ++table_idx) {
     for (size_t batch_idx = 0; batch_idx < minibatch_size; ++batch_idx) {
-      axdimm_lengths_out.push_back(
-          batch[batch_idx + 1] -
-          batch[batch_idx]);
+      axdimm_lengths_out.push_back(batch[batch_idx + 1] - batch[batch_idx]);
     }
     batch += minibatch_size + 1;
   }
@@ -32,7 +31,8 @@ namespace axdimm {
 at::Tensor embedding_bag_forward_only_axdimm(
     const at::Tensor& weights,
     const at::Tensor& indices,
-    const at::Tensor& offsets) {
+    const at::Tensor& offsets,
+    c10::optional<int64_t> precompiled_op_id) {
   TORCH_INTERNAL_ASSERT(weights.is_axdimm());
   TORCH_CHECK(indices.is_cpu(), "Indices must be CPU tensor");
   TORCH_CHECK(offsets.is_cpu(), "Offsets must be CPU tensor");
@@ -59,20 +59,27 @@ at::Tensor embedding_bag_forward_only_axdimm(
       [ten.get_num_tables() * minibatch_size * ten.get_sparse_feature_size() *
        weights.dtype().itemsize()];
   const auto& tables_rows_num = ten.get_tables_rows_num();
-  auto sls_op_ = axdimm_create_sls_op(
-      minibatch_size,
-      ten.get_sparse_feature_size(),
-      ten.get_num_tables(),
-      const_cast<uint32_t*>(tables_rows_num.data()),
-      nullptr,
-      ten.get_tables_layout(),
-      ten.get_sls_type());
+  AxdimmOperation* sls_op{};
+  if (precompiled_op_id) {
+    sls_op =
+        AxdimmPrecompiledOp::get_precompiled_op_by_id(*precompiled_op_id);
+    axdimm_precompile_op(sls_op, ten.get_device());
+  } else {
+    sls_op = axdimm_create_sls_op(
+        minibatch_size,
+        ten.get_sparse_feature_size(),
+        ten.get_num_tables(),
+        const_cast<uint32_t*>(tables_rows_num.data()),
+        nullptr,
+        ten.get_tables_layout(),
+        ten.get_sls_type());
+  }
 
   std::vector<uint32_t> axdimm_lengths;
   transform_offsets(offsets, axdimm_lengths);
 
   auto status = axdimm_run_sls(
-      sls_op_,
+      sls_op,
       ten.get_device(),
       axdimm_lengths.data(),
       static_cast<uint32_t*>(indices.data_ptr()),
@@ -83,7 +90,9 @@ at::Tensor embedding_bag_forward_only_axdimm(
   return torch::from_blob(
       psum_buf,
       {ten.get_num_tables(), minibatch_size, ten.get_sparse_feature_size()},
-      {minibatch_size * ten.get_sparse_feature_size(), ten.get_sparse_feature_size(), 1},
+      {minibatch_size * ten.get_sparse_feature_size(),
+       ten.get_sparse_feature_size(),
+       1},
       [](void* data) { delete[] static_cast<uint8_t*>(data); },
       torch::TensorOptions().dtype(weights.dtype()).device(torch::kCPU));
 }
@@ -92,7 +101,7 @@ at::Tensor embedding_bag_forward_only_axdimm(
 // (aten)
 TORCH_LIBRARY_FRAGMENT(aten, m) {
   m.def(
-      "aten::embedding_bag_forward_only_axdimm(Tensor weights, Tensor indices, Tensor offsets) -> Tensor");
+      "aten::embedding_bag_forward_only_axdimm(Tensor weights, Tensor indices, Tensor offsets, int? precompiled_op_id=None) -> Tensor");
 }
 
 TORCH_LIBRARY_IMPL(aten, AXDIMM, m) {
diff --git a/torch/nn/modules/sparse.py b/torch/nn/modules/sparse.py
index d5655d04..2c4cddd0 100644
--- a/torch/nn/modules/sparse.py
+++ b/torch/nn/modules/sparse.py
@@ -225,12 +225,20 @@ class Embedding(Module):
 
 class EmbeddingBagAxdimm(Module):
     weight: Tensor
-    def __init__(self, weight):
+    op_id: int
+    precompile: bool
+    def __init__(self, weight, precompile = False):
         super(EmbeddingBagAxdimm, self).__init__()
         self.weight = weight
+        self.op_context = None
+        self.precompile = precompile
+        self.op_id = None
 
     def forward(self, indices: Tensor, offsets: Tensor) -> Tensor:
-        return torch.ops.aten.embedding_bag_forward_only_axdimm(self.weight, indices, offsets)
+        if self.precompile and self.op_context is None:
+            self.op_context = torch.classes.axdimm_helpers.AxdimmOperationsStorage(self.weight, offsets)
+            self.op_id = self.op_context.get_precompiled_op_id()
+        return torch.ops.aten.embedding_bag_forward_only_axdimm(self.weight, indices, offsets, self.op_id)
 
 
 class EmbeddingBag(Module):
-- 
2.34.1

