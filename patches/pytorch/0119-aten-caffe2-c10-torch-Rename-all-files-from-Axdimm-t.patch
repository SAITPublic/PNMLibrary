From 003106d655c4c05b3389fd2f64f7c6fd391dec05 Mon Sep 17 00:00:00 2001
From: Maxim Ostapenko <maxim.o@samsung.com>
Date: Tue, 9 May 2023 08:51:02 +0000
Subject: [PATCH 119/128] [aten, caffe2, c10, torch] Rename all files from
 *Axdimm* to *PNM*

Do massive renaming for all PNM-related entities except those which
depend on axdimm_driver and axdimm_linux enums.

This is done as a preparation for OneMCC release.

Signed-off-by: Maxim Ostapenko <maxim.o@samsung.com>
---
 CMakeLists.txt                                |  2 +-
 aten/CMakeLists.txt                           | 12 +--
 aten/src/ATen/CMakeLists.txt                  | 26 +++---
 aten/src/ATen/core/TensorBase.h               |  6 +-
 aten/src/ATen/native/Copy.cpp                 |  2 +-
 .../native/axdimm/AxdimmDeviceContext.cpp     | 21 -----
 .../ATen/native/axdimm/AxdimmTensorConvert.h  | 33 --------
 aten/src/ATen/native/axdimm/ops/Copy.cpp      | 28 -------
 aten/src/ATen/native/native_functions.yaml    |  2 +-
 .../PNMBaseTensor.h}                          | 53 ++++++------
 aten/src/ATen/native/pnm/PNMDeviceContext.cpp | 21 +++++
 .../PNMDeviceContext.h}                       | 14 ++--
 .../AxdimmGuard.cpp => pnm/PNMGuard.cpp}      |  4 +-
 .../PNMOpaqueTensor.h}                        | 14 ++--
 .../PNMSecureTensor.cpp}                      | 53 ++++++------
 .../PNMSecureTensor.h}                        | 26 +++---
 .../AxdimmTensor.cpp => pnm/PNMTensor.cpp}    | 37 ++++-----
 .../AxdimmTensor.h => pnm/PNMTensor.h}        | 34 ++++----
 aten/src/ATen/native/pnm/PNMTensorConvert.h   | 33 ++++++++
 .../PNMTypeHelpers.h}                         |  8 +-
 aten/src/ATen/native/pnm/ops/Copy.cpp         | 28 +++++++
 .../{axdimm => pnm}/ops/EmbeddingBag.cpp      | 49 ++++++-----
 .../native/{axdimm => pnm}/ops/Factory.cpp    | 83 +++++++++----------
 .../is_pnm_available.cpp}                     |  8 +-
 c10/core/Backend.h                            | 18 ++--
 c10/core/CPUAllocator.cpp                     |  2 +-
 c10/core/Device.cpp                           |  2 +-
 c10/core/DeviceType.cpp                       |  6 +-
 c10/core/DeviceType.h                         |  4 +-
 c10/core/DispatchKey.cpp                      |  6 +-
 c10/core/DispatchKey.h                        |  2 +-
 c10/core/DispatchKeySet.h                     |  3 +-
 c10/core/TensorImpl.h                         |  6 +-
 c10/core/TensorOptions.h                      | 12 +--
 caffe2/CMakeLists.txt                         | 72 ++++++++--------
 .../core/{context_axdimm.h => context_pnm.h}  | 39 +++++----
 caffe2/core/{event_axdimm.cc => event_pnm.cc} | 80 +++++++++---------
 caffe2/core/operator.cc                       |  4 +-
 caffe2/core/operator.h                        | 20 ++---
 caffe2/operators/CMakeLists.txt               | 12 +--
 caffe2/operators/lengths_reducer_ops.h        |  2 +-
 ...s_axdimm.cc => lengths_reducer_ops_pnm.cc} | 36 ++++----
 ...dimm.cc => lengths_reducer_ops_sec_pnm.cc} | 12 +--
 ...axdimm.h => lengths_reducer_ops_sec_pnm.h} | 66 +++++++--------
 ...lback_axdimm.h => operator_fallback_pnm.h} | 44 +++++-----
 caffe2/proto/caffe2.proto                     |  2 +-
 caffe2/proto/caffe2_pb.h                      | 14 ++--
 caffe2/python/CMakeLists.txt                  | 10 +--
 caffe2/python/__init__.py                     |  2 +-
 caffe2/python/_import_c_extension.py          | 12 +--
 caffe2/python/_import_c_extension.pyi         |  2 +-
 ...nd_state_axdimm.cc => pybind_state_pnm.cc} | 26 +++---
 caffe2/python/workspace.py                    | 16 ++--
 caffe2/utils/proto_utils.cc                   |  8 +-
 caffe2/utils/proto_utils.h                    |  2 +-
 cmake/Codegen.cmake                           |  4 +-
 cmake/Dependencies.cmake                      | 12 +--
 setup.py                                      |  4 +-
 torch/csrc/autograd/python_variable.cpp       |  8 +-
 torch/csrc/jit/frontend/sugared_value.cpp     |  2 +-
 torch/csrc/jit/runtime/register_prim_ops.cpp  |  4 +-
 torch/csrc/utils/tensor_types.cpp             |  4 +-
 torch/nn/modules/__init__.py                  |  4 +-
 torch/nn/modules/sparse.py                    |  6 +-
 torchgen/model.py                             |  2 +-
 65 files changed, 587 insertions(+), 602 deletions(-)
 delete mode 100644 aten/src/ATen/native/axdimm/AxdimmDeviceContext.cpp
 delete mode 100644 aten/src/ATen/native/axdimm/AxdimmTensorConvert.h
 delete mode 100644 aten/src/ATen/native/axdimm/ops/Copy.cpp
 rename aten/src/ATen/native/{axdimm/AxdimmBaseTensor.h => pnm/PNMBaseTensor.h} (82%)
 create mode 100644 aten/src/ATen/native/pnm/PNMDeviceContext.cpp
 rename aten/src/ATen/native/{axdimm/AxdimmDeviceContext.h => pnm/PNMDeviceContext.h} (60%)
 rename aten/src/ATen/native/{axdimm/AxdimmGuard.cpp => pnm/PNMGuard.cpp} (76%)
 rename aten/src/ATen/native/{axdimm/AxdimmOpaqueTensor.h => pnm/PNMOpaqueTensor.h} (75%)
 rename aten/src/ATen/native/{axdimm/AxdimmSecureTensor.cpp => pnm/PNMSecureTensor.cpp} (66%)
 rename aten/src/ATen/native/{axdimm/AxdimmSecureTensor.h => pnm/PNMSecureTensor.h} (80%)
 rename aten/src/ATen/native/{axdimm/AxdimmTensor.cpp => pnm/PNMTensor.cpp} (69%)
 rename aten/src/ATen/native/{axdimm/AxdimmTensor.h => pnm/PNMTensor.h} (70%)
 create mode 100644 aten/src/ATen/native/pnm/PNMTensorConvert.h
 rename aten/src/ATen/native/{axdimm/AxdimmTypeHelpers.h => pnm/PNMTypeHelpers.h} (93%)
 create mode 100644 aten/src/ATen/native/pnm/ops/Copy.cpp
 rename aten/src/ATen/native/{axdimm => pnm}/ops/EmbeddingBag.cpp (77%)
 rename aten/src/ATen/native/{axdimm => pnm}/ops/Factory.cpp (61%)
 rename aten/src/ATen/{axdimm/is_axdimm_available.cpp => pnm/is_pnm_available.cpp} (62%)
 rename caffe2/core/{context_axdimm.h => context_pnm.h} (71%)
 rename caffe2/core/{event_axdimm.cc => event_pnm.cc} (57%)
 rename caffe2/operators/{lengths_reducer_ops_axdimm.cc => lengths_reducer_ops_pnm.cc} (93%)
 rename caffe2/operators/{lengths_reducer_ops_sec_axdimm.cc => lengths_reducer_ops_sec_pnm.cc} (88%)
 rename caffe2/operators/{lengths_reducer_ops_sec_axdimm.h => lengths_reducer_ops_sec_pnm.h} (83%)
 rename caffe2/operators/{operator_fallback_axdimm.h => operator_fallback_pnm.h} (70%)
 rename caffe2/python/{pybind_state_axdimm.cc => pybind_state_pnm.cc} (81%)

diff --git a/CMakeLists.txt b/CMakeLists.txt
index cadf3ea8..88b327ac 100644
--- a/CMakeLists.txt
+++ b/CMakeLists.txt
@@ -191,7 +191,7 @@ option(USE_CPP_CODE_COVERAGE "Compile C/C++ with code coverage flags" OFF)
 option(USE_COLORIZE_OUTPUT "Colorize output during compilation" ON)
 option(USE_ASAN "Use Address+Undefined Sanitizers" OFF)
 option(USE_TSAN "Use Thread Sanitizer" OFF)
-option(USE_PNM "Use AXDIMM" OFF)
+option(USE_PNM "Use PNM" OFF)
 option(PNM_INSTALL_DIR "A path to PNM library installation directory" "")
 option(USE_CUDA "Use CUDA" ON)
 cmake_dependent_option(
diff --git a/aten/CMakeLists.txt b/aten/CMakeLists.txt
index d037312f..2f8bf158 100644
--- a/aten/CMakeLists.txt
+++ b/aten/CMakeLists.txt
@@ -17,8 +17,8 @@ cmake_policy(SET CMP0012 NEW)
 
 #############################################
 
-set(ATen_AXDIMM_INCLUDE)
-set(ATen_AXDIMM_SRCS)
+set(ATen_PNM_INCLUDE)
+set(ATen_PNM_SRCS)
 set(ATen_CPU_SRCS)
 set(ATen_CPU_TEST_SRCS)
 set(ATen_CPU_INCLUDE)
@@ -37,7 +37,7 @@ set(ATen_HIP_INCLUDE)
 set(ATen_MPS_SRCS)
 set(ATen_MPS_TEST_SRCS)
 set(ATen_VULKAN_TEST_SRCS)
-set(ATen_AXDIMM_DEPENDENCY_LIBS)
+set(ATen_PNM_DEPENDENCY_LIBS)
 set(ATen_CPU_DEPENDENCY_LIBS)
 set(ATen_CUDA_DEPENDENCY_LIBS)
 set(ATen_HIP_DEPENDENCY_LIBS)
@@ -102,7 +102,7 @@ list(APPEND ATen_CPU_INCLUDE
 add_subdirectory(src/ATen)
 
 # Pass source, includes, and libs to parent
-set(ATen_AXDIMM_SRCS ${ATen_AXDIMM_SRCS} PARENT_SCOPE)
+set(ATen_PNM_SRCS ${ATen_PNM_SRCS} PARENT_SCOPE)
 set(ATen_CPU_SRCS ${ATen_CPU_SRCS} PARENT_SCOPE)
 set(ATen_CORE_SRCS ${ATen_CORE_SRCS} PARENT_SCOPE)
 set(ATen_CUDA_CU_SRCS ${ATen_CUDA_CU_SRCS} PARENT_SCOPE)
@@ -122,12 +122,12 @@ set(ATen_VULKAN_TEST_SRCS ${ATen_VULKAN_TEST_SRCS} PARENT_SCOPE)
 set(ATen_MOBILE_BENCHMARK_SRCS ${ATen_MOBILE_BENCHMARK_SRCS} PARENT_SCOPE)
 set(ATen_MOBILE_TEST_SRCS ${ATen_MOBILE_TEST_SRCS} PARENT_SCOPE)
 set(ATen_VEC_TEST_SRCS ${ATen_VEC_TEST_SRCS} PARENT_SCOPE)
-set(ATen_AXDIMM_INCLUDE ${ATen_CPU_INCLUDE} PARENT_SCOPE)
+set(ATen_PNM_INCLUDE ${ATen_CPU_INCLUDE} PARENT_SCOPE)
 set(ATen_CPU_INCLUDE ${ATen_CPU_INCLUDE} PARENT_SCOPE)
 set(ATen_CUDA_INCLUDE ${ATen_CUDA_INCLUDE} PARENT_SCOPE)
 set(ATen_HIP_INCLUDE ${ATen_HIP_INCLUDE} PARENT_SCOPE)
 set(ATen_THIRD_PARTY_INCLUDE ${ATen_THIRD_PARTY_INCLUDE} PARENT_SCOPE)
-set(ATen_AXDIMM_DEPENDENCY_LIBS ${ATen_AXDIMM_DEPENDENCY_LIBS} PARENT_SCOPE)
+set(ATen_PNM_DEPENDENCY_LIBS ${ATen_PNM_DEPENDENCY_LIBS} PARENT_SCOPE)
 set(ATen_CPU_DEPENDENCY_LIBS ${ATen_CPU_DEPENDENCY_LIBS} PARENT_SCOPE)
 set(ATen_CUDA_DEPENDENCY_LIBS ${ATen_CUDA_DEPENDENCY_LIBS} PARENT_SCOPE)
 set(ATen_HIP_DEPENDENCY_LIBS ${ATen_HIP_DEPENDENCY_LIBS} PARENT_SCOPE)
diff --git a/aten/src/ATen/CMakeLists.txt b/aten/src/ATen/CMakeLists.txt
index d4d238a0..baa26184 100644
--- a/aten/src/ATen/CMakeLists.txt
+++ b/aten/src/ATen/CMakeLists.txt
@@ -85,8 +85,8 @@ file(GLOB native_mkl_cpp "native/mkl/*.cpp")
 file(GLOB native_mkldnn_cpp "native/mkldnn/*.cpp")
 file(GLOB vulkan_cpp "vulkan/*.cpp")
 file(GLOB native_vulkan_cpp "native/vulkan/*.cpp" "native/vulkan/api/*.cpp" "native/vulkan/impl/*.cpp" "native/vulkan/ops/*.cpp")
-file(GLOB axdimm_cpp "axdimm/*.cpp")
-file(GLOB native_axdimm_cpp "native/axdimm/*.cpp" "native/axdimm/ops/*.cpp")
+file(GLOB pnm_cpp "pnm/*.cpp")
+file(GLOB native_pnm_cpp "native/pnm/*.cpp" "native/pnm/ops/*.cpp")
 
 # Metal
 file(GLOB metal_h "metal/*.h")
@@ -208,7 +208,7 @@ if(USE_LIGHTWEIGHT_DISPATCH)
   set(all_cpu_cpp ${all_cpu_cpp} ${generated_unboxing_sources})
 endif()
 
-set(all_axdimm_cpp ${core_generated_cpp})
+set(all_pnm_cpp ${core_generated_cpp})
 
 if(AT_MKL_ENABLED)
   set(all_cpu_cpp ${all_cpu_cpp} ${mkl_cpp})
@@ -223,9 +223,9 @@ else()
 endif()
 
 if(USE_PNM)
-  set(all_cpu_cpp ${all_cpu_cpp} ${axdimm_cpp} ${native_axdimm_cpp})
+  set(all_cpu_cpp ${all_cpu_cpp} ${pnm_cpp} ${native_pnm_cpp})
 else()
-  set(all_cpu_cpp ${all_cpu_cpp} ${axdimm_cpp})
+  set(all_cpu_cpp ${all_cpu_cpp} ${pnm_cpp})
 endif()
 
 # Metal
@@ -293,7 +293,7 @@ if(USE_ROCM)
 endif()
 
 if(USE_PNM)
-  list(APPEND ATen_AXDIMM_INCLUDE ${CMAKE_CURRENT_SOURCE_DIR}/axdimm)
+  list(APPEND ATen_PNM_INCLUDE ${CMAKE_CURRENT_SOURCE_DIR}/pnm)
 endif()
 
 list(APPEND ATen_CPU_INCLUDE ${CMAKE_CURRENT_SOURCE_DIR}/..)
@@ -509,8 +509,8 @@ endif()
 # dependency is nontrivial.  So better not to copy-paste.
 # Look for Note [rocblas cmake bug]
 
-# Include CPU paths for CUDA/HIP/AXDIMM as well
-list(APPEND ATen_AXDIMM_INCLUDE ${ATen_CPU_INCLUDE})
+# Include CPU paths for CUDA/HIP/PNM as well
+list(APPEND ATen_PNM_INCLUDE ${ATen_CPU_INCLUDE})
 list(APPEND ATen_CUDA_INCLUDE ${ATen_CPU_INCLUDE})
 list(APPEND ATen_HIP_INCLUDE ${ATen_CPU_INCLUDE})
 list(APPEND ATen_VULKAN_INCLUDE ${ATen_CPU_INCLUDE})
@@ -544,8 +544,8 @@ if(USE_ROCM)
 endif()
 
 if(USE_PNM)
-  set(ATen_AXDIMM_SRCS ${all_axdimm_cpp})
-  list(APPEND ATen_AXDIMM_DEPENDENCY_LIBS ATEN_AXDIMM_FILES_GEN_LIB)
+  set(ATen_PNM_SRCS ${all_pnm_cpp})
+  list(APPEND ATen_PNM_DEPENDENCY_LIBS ATEN_PNM_FILES_GEN_LIB)
 endif()
 
 set(ATEN_INCLUDE_DIR "${CMAKE_INSTALL_PREFIX}/${AT_INSTALL_INCLUDE_DIR}")
@@ -616,7 +616,7 @@ list(APPEND ATen_MOBILE_BENCHMARK_SRCS
 
 # Pass source, includes, and libs to parent
 set(ATen_CORE_SRCS ${ATen_CORE_SRCS} PARENT_SCOPE)
-set(ATen_AXDIMM_SRCS ${ATen_AXDIMM_SRCS} PARENT_SCOPE)
+set(ATen_PNM_SRCS ${ATen_PNM_SRCS} PARENT_SCOPE)
 set(ATen_CPU_SRCS ${ATen_CPU_SRCS} PARENT_SCOPE)
 set(ATen_CUDA_CU_SRCS ${ATen_CUDA_CU_SRCS} PARENT_SCOPE)
 set(ATen_CUDA_CPP_SRCS ${ATen_CUDA_CPP_SRCS} PARENT_SCOPE)
@@ -639,11 +639,11 @@ set(ATen_QUANTIZED_TEST_SRCS ${ATen_QUANTIZED_TEST_SRCS} PARENT_SCOPE)
 set(ATen_MPS_TEST_SRCS ${ATen_MPS_TEST_SRCS} PARENT_SCOPE)
 set(ATen_CPU_INCLUDE ${ATen_CPU_INCLUDE} PARENT_SCOPE)
 set(ATen_THIRD_PARTY_INCLUDE ${ATen_THIRD_PARTY_INCLUDE} PARENT_SCOPE)
-set(ATen_AXDIMM_INCLUDE ${ATen_AXDIMM_INCLUDE} PARENT_SCOPE)
+set(ATen_PNM_INCLUDE ${ATen_PNM_INCLUDE} PARENT_SCOPE)
 set(ATen_CUDA_INCLUDE ${ATen_CUDA_INCLUDE} PARENT_SCOPE)
 set(ATen_HIP_INCLUDE ${ATen_HIP_INCLUDE} PARENT_SCOPE)
 set(ATen_VULKAN_INCLUDE ${ATen_VULKAN_INCLUDE} PARENT_SCOPE)
-set(ATen_AXDIMM_DEPENDENCY_LIBS ${ATen_AXDIMM_DEPENDENCY_LIBS} PARENT_SCOPE)
+set(ATen_PNM_DEPENDENCY_LIBS ${ATen_PNM_DEPENDENCY_LIBS} PARENT_SCOPE)
 set(ATen_CPU_DEPENDENCY_LIBS ${ATen_CPU_DEPENDENCY_LIBS} PARENT_SCOPE)
 set(ATen_CUDA_DEPENDENCY_LIBS ${ATen_CUDA_DEPENDENCY_LIBS} PARENT_SCOPE)
 set(ATen_HIP_DEPENDENCY_LIBS ${ATen_HIP_DEPENDENCY_LIBS} PARENT_SCOPE)
diff --git a/aten/src/ATen/core/TensorBase.h b/aten/src/ATen/core/TensorBase.h
index 056796f7..ddceba1e 100644
--- a/aten/src/ATen/core/TensorBase.h
+++ b/aten/src/ATen/core/TensorBase.h
@@ -481,10 +481,10 @@ class TORCH_API TensorBase {
     return impl_->is_vulkan();
   }
 
-  /// Returns if a `Tensor` is axdimm tensor.
-  bool is_axdimm() const {
+  /// Returns if a `Tensor` is pnm tensor.
+  bool is_pnm() const {
     // NB: this is not a native function to avoid dispatching overhead.
-    return impl_->is_axdimm();
+    return impl_->is_pnm();
   }
 
   /// Returns if a `Tensor` is metal tensor.
diff --git a/aten/src/ATen/native/Copy.cpp b/aten/src/ATen/native/Copy.cpp
index bf65614a..a01ca566 100644
--- a/aten/src/ATen/native/Copy.cpp
+++ b/aten/src/ATen/native/Copy.cpp
@@ -108,7 +108,7 @@ void copy_same_type_transpose_(Tensor& self, const Tensor& src) {
 // (e.g. XLA) may be supported by overriding copy_ and _copy_from.
 bool is_supported_device(Device device) {
   DeviceType device_type = device.type();
-  return device_type == kCPU || device_type == kCUDA || device_type == kHIP || device_type == kVulkan || device_type == kMetal || device_type == kMPS || device_type == kAXDIMM;
+  return device_type == kCPU || device_type == kCUDA || device_type == kHIP || device_type == kVulkan || device_type == kMetal || device_type == kMPS || device_type == kPNM;
 }
 
 } // namespace
diff --git a/aten/src/ATen/native/axdimm/AxdimmDeviceContext.cpp b/aten/src/ATen/native/axdimm/AxdimmDeviceContext.cpp
deleted file mode 100644
index 2b358c10..00000000
--- a/aten/src/ATen/native/axdimm/AxdimmDeviceContext.cpp
+++ /dev/null
@@ -1,21 +0,0 @@
-#include <pnmlib/ai/sls.h>
-
-#include <ATen/native/axdimm/AxdimmDeviceContext.h>
-
-namespace at {
-namespace native {
-namespace axdimm {
-
-Device& AxdimmDeviceContext::device() {
-  static auto static_device = SlsDevice::make();
-  return static_device;
-}
-
-pnm::ContextHandler& AxdimmDeviceContext::context() {
-  static auto context = pnm::make_context(pnm::ContextType::AXDIMM);
-  return context;
-}
-
-} // namespace axdimm
-} // namespace native
-} // namespace at
diff --git a/aten/src/ATen/native/axdimm/AxdimmTensorConvert.h b/aten/src/ATen/native/axdimm/AxdimmTensorConvert.h
deleted file mode 100644
index ce540833..00000000
--- a/aten/src/ATen/native/axdimm/AxdimmTensorConvert.h
+++ /dev/null
@@ -1,33 +0,0 @@
-#ifndef __AXDIMM_TENSOR_CONVERT__
-#define __AXDIMM_TENSOR_CONVERT__
-
-#include <ATen/native/axdimm/AxdimmSecureTensor.h>
-#include <ATen/native/axdimm/AxdimmTensor.h>
-
-namespace at {
-namespace native {
-namespace axdimm {
-
-template <typename T>
-const T& convert(const at::Tensor& tensor) {
-  TORCH_INTERNAL_ASSERT(tensor.is_axdimm());
-  AxdimmTensorImpl* impl =
-      static_cast<AxdimmTensorImpl*>(tensor.unsafeGetTensorImpl());
-  const AxdimmBaseTensor* tensor_ptr = impl->unsafe_opaque_handle().get();
-  const auto tensor_type = tensor_ptr->get_tensor_type();
-  TORCH_INTERNAL_ASSERT(
-      tensor_type == AxdimmTensorType::AXDIMM_SIMPLE ||
-          tensor_type == AxdimmTensorType::AXDIMM_SECURE,
-      "Unsuported tensor type");
-
-  const T* res = dynamic_cast<const T*>(tensor_ptr);
-  TORCH_INTERNAL_ASSERT(res, "Failed to convert tensor");
-
-  return *res;
-}
-
-} // namespace axdimm
-} // namespace native
-} // namespace at
-
-#endif
diff --git a/aten/src/ATen/native/axdimm/ops/Copy.cpp b/aten/src/ATen/native/axdimm/ops/Copy.cpp
deleted file mode 100644
index 850ea075..00000000
--- a/aten/src/ATen/native/axdimm/ops/Copy.cpp
+++ /dev/null
@@ -1,28 +0,0 @@
-#include <ATen/native/axdimm/AxdimmOpaqueTensor.h>
-#include <ATen/native/axdimm/AxdimmTensor.h>
-
-#include <torch/library.h>
-
-namespace at {
-namespace native {
-namespace axdimm {
-
-// implementation is required for dispatched tensor creation
-at::Tensor& copy_axdimm_(
-    at::Tensor& self,
-    const at::Tensor& src,
-    bool non_blocking) {
-  TORCH_INTERNAL_ASSERT(self.is_axdimm());
-  TORCH_CHECK(src.is_cpu(), "Only CPU tensors can be copied to AXDIMM device");
-  auto impl = static_cast<AxdimmTensorImpl*>(self.unsafeGetTensorImpl());
-  impl->unsafe_opaque_handle() = std::make_shared<AxdimmTensor>(src);
-  return self;
-}
-
-TORCH_LIBRARY_IMPL(aten, AXDIMM, m) {
-  m.impl(TORCH_SELECTIVE_NAME("aten::copy_"), TORCH_FN(copy_axdimm_));
-}
-
-} // namespace axdimm
-} // namespace native
-} // namespace at
diff --git a/aten/src/ATen/native/native_functions.yaml b/aten/src/ATen/native/native_functions.yaml
index 7a86b266..741c9210 100644
--- a/aten/src/ATen/native/native_functions.yaml
+++ b/aten/src/ATen/native/native_functions.yaml
@@ -4068,7 +4068,7 @@
 
 - func: is_vulkan_available() -> bool
 
-- func: is_axdimm_available() -> bool
+- func: is_pnm_available() -> bool
 
 - func: _nnpack_available() -> bool
 
diff --git a/aten/src/ATen/native/axdimm/AxdimmBaseTensor.h b/aten/src/ATen/native/pnm/PNMBaseTensor.h
similarity index 82%
rename from aten/src/ATen/native/axdimm/AxdimmBaseTensor.h
rename to aten/src/ATen/native/pnm/PNMBaseTensor.h
index 2b3bcb39..25e2ea9f 100644
--- a/aten/src/ATen/native/axdimm/AxdimmBaseTensor.h
+++ b/aten/src/ATen/native/pnm/PNMBaseTensor.h
@@ -1,9 +1,9 @@
-#ifndef __AXDIMM_BASE_TENSOR__
-#define __AXDIMM_BASE_TENSOR__
+#ifndef __PNM_BASE_TENSOR__
+#define __PNM_BASE_TENSOR__
 
 #include <ATen/ATen.h>
-#include <ATen/native/axdimm/AxdimmDeviceContext.h>
-#include <ATen/native/axdimm/AxdimmOpaqueTensor.h>
+#include <ATen/native/pnm/PNMDeviceContext.h>
+#include <ATen/native/pnm/PNMOpaqueTensor.h>
 
 #include <torch/library.h>
 #include <torch/types.h>
@@ -15,36 +15,36 @@
 
 namespace at {
 namespace native {
-namespace axdimm {
+namespace pnm {
 
 inline void verify(const at::TensorOptions& options) {
   TORCH_CHECK(
       !options.has_requires_grad() || !options.requires_grad(),
-      "'requires_grad' tensor option is not yet supported under Axdimm!");
+      "'requires_grad' tensor option is not yet supported under Pnm!");
 
   TORCH_CHECK(
       !options.has_pinned_memory() || !options.pinned_memory(),
-      "'pinned_memory' tensor option is not yet supported under Axdimm!");
+      "'pinned_memory' tensor option is not yet supported under Pnm!");
 
   TORCH_CHECK(
       !options.has_layout() || (c10::kStrided == options.layout()),
-      "'layout' tensor option is not yet supported under Axdimm!");
+      "'layout' tensor option is not yet supported under Pnm!");
 
   TORCH_CHECK(
       !options.has_memory_format() ||
           (c10::MemoryFormat::Contiguous == options.memory_format_opt()),
-      "'memory_format' tensor option is not yet supported under Axdimm!");
+      "'memory_format' tensor option is not yet supported under Pnm!");
 }
 
-enum class AxdimmTensorType { AXDIMM_SIMPLE, AXDIMM_SECURE };
+enum class PnmTensorType { PNM_SIMPLE, PNM_SECURE };
 
-class AxdimmBaseTensor {
+class PnmBaseTensor {
  public:
-  AxdimmBaseTensor(
+  PnmBaseTensor(
       const std::string& weights_path,
       const c10::ScalarType& scalar_type,
       const at::Tensor& tables_rows_num,
-      AxdimmTensorType tensor_type,
+      PnmTensorType tensor_type,
       uint32_t num_tables,
       uint32_t sparse_feature_size,
       axd_user_preferences preference = AXDIMM_ALLOC_DISTRIBUTE_ALL)
@@ -79,9 +79,9 @@ class AxdimmBaseTensor {
         });
   }
 
-  AxdimmBaseTensor(
+  PnmBaseTensor(
       const at::Tensor& weights,
-      AxdimmTensorType tensor_type,
+      PnmTensorType tensor_type,
       uint32_t num_tables,
       uint32_t features_per_table,
       uint32_t sparse_feature_size,
@@ -102,11 +102,11 @@ class AxdimmBaseTensor {
     tables_size_ = num_tables_ * features_per_table * sparse_feature_size_;
   }
 
-  AxdimmBaseTensor(AxdimmBaseTensor&&) = default;
+  PnmBaseTensor(PnmBaseTensor&&) = default;
 
-  virtual ~AxdimmBaseTensor() = default;
+  virtual ~PnmBaseTensor() = default;
 
-  AxdimmTensorType get_tensor_type() const {
+  PnmTensorType get_tensor_type() const {
     return type_;
   }
 
@@ -123,18 +123,18 @@ class AxdimmBaseTensor {
   }
 
   Device& get_device() const {
-    return AxdimmDeviceContext::device();
+    return PnmDeviceContext::device();
   }
 
-  pnm::ContextHandler& get_pnm_context() const {
-    return AxdimmDeviceContext::context();
+  ::pnm::ContextHandler& get_pnm_context() const {
+    return PnmDeviceContext::context();
   }
 
  private:
   void check_params() const {
     TORCH_CHECK(
         scalar_type_ == torch::kFloat32 || scalar_type_ == torch::kInt32,
-        "Invalid tensor data type. AXDIMM tensor only float32 and int32 tensors as weights");
+        "Invalid tensor data type. PNM tensor only float32 and int32 tensors as weights");
     TORCH_CHECK(num_tables_ > 0, "Number of tables must be > 0");
     TORCH_CHECK(sparse_feature_size_ > 0, "Sparse feature size must be > 0");
   }
@@ -164,10 +164,10 @@ class AxdimmBaseTensor {
   uint32_t num_tables_{};
   uint32_t sparse_feature_size_{};
   axd_user_preferences preference_{};
-  AxdimmTensorType type_{};
+  PnmTensorType type_{};
 };
 
-/* We need `AxdimmOpaqueTensorImpl` handle to:
+/* We need `PnmOpaqueTensorImpl` handle to:
 
    1) Be copyable (opaque handle objects requirement).
    2) Preserve polymorphic behavior.
@@ -177,10 +177,9 @@ class AxdimmBaseTensor {
    performance impact and wrapper with copy constructor would require to move or
    transfer ownership of data, which is not intuitive for copy operations to do
 */
-using AxdimmTensorImpl =
-    AxdimmOpaqueTensorImpl<std::shared_ptr<AxdimmBaseTensor>>;
+using PnmTensorImpl = PnmOpaqueTensorImpl<std::shared_ptr<PnmBaseTensor>>;
 
-} // namespace axdimm
+} // namespace pnm
 } // namespace native
 } // namespace at
 
diff --git a/aten/src/ATen/native/pnm/PNMDeviceContext.cpp b/aten/src/ATen/native/pnm/PNMDeviceContext.cpp
new file mode 100644
index 00000000..24794660
--- /dev/null
+++ b/aten/src/ATen/native/pnm/PNMDeviceContext.cpp
@@ -0,0 +1,21 @@
+#include <pnmlib/ai/sls.h>
+
+#include <ATen/native/pnm/PNMDeviceContext.h>
+
+namespace at {
+namespace native {
+namespace pnm {
+
+Device& PnmDeviceContext::device() {
+  static auto static_device = SlsDevice::make();
+  return static_device;
+}
+
+::pnm::ContextHandler& PnmDeviceContext::context() {
+  static auto context = ::pnm::make_context(::pnm::ContextType::AXDIMM);
+  return context;
+}
+
+} // namespace pnm
+} // namespace native
+} // namespace at
diff --git a/aten/src/ATen/native/axdimm/AxdimmDeviceContext.h b/aten/src/ATen/native/pnm/PNMDeviceContext.h
similarity index 60%
rename from aten/src/ATen/native/axdimm/AxdimmDeviceContext.h
rename to aten/src/ATen/native/pnm/PNMDeviceContext.h
index 0840cd77..9efcfbe5 100644
--- a/aten/src/ATen/native/axdimm/AxdimmDeviceContext.h
+++ b/aten/src/ATen/native/pnm/PNMDeviceContext.h
@@ -1,8 +1,8 @@
-#ifndef __AXDIMM_DEVICE_CONTEXT__
-#define __AXDIMM_DEVICE_CONTEXT__
+#ifndef __PNM_DEVICE_CONTEXT__
+#define __PNM_DEVICE_CONTEXT__
 
-#include <pnmlib/core/sls_device.h>
 #include <pnmlib/core/context.h>
+#include <pnmlib/core/sls_device.h>
 
 #include <c10/util/Exception.h>
 
@@ -10,18 +10,18 @@
 
 namespace at {
 namespace native {
-namespace axdimm {
+namespace pnm {
 
 using Device = SlsDevice;
 
-class AxdimmDeviceContext {
+class PnmDeviceContext {
  public:
   static Device& device();
 
-  static pnm::ContextHandler& context();
+  static ::pnm::ContextHandler& context();
 };
 
-} // namespace axdimm
+} // namespace pnm
 } // namespace native
 } // namespace at
 
diff --git a/aten/src/ATen/native/axdimm/AxdimmGuard.cpp b/aten/src/ATen/native/pnm/PNMGuard.cpp
similarity index 76%
rename from aten/src/ATen/native/axdimm/AxdimmGuard.cpp
rename to aten/src/ATen/native/pnm/PNMGuard.cpp
index f54b8b89..399210a3 100644
--- a/aten/src/ATen/native/axdimm/AxdimmGuard.cpp
+++ b/aten/src/ATen/native/pnm/PNMGuard.cpp
@@ -4,5 +4,5 @@
 // This registers device in the global map of supported devices
 // Since for now no specific actions required it's left empty
 C10_REGISTER_GUARD_IMPL(
-    AXDIMM,
-    c10::impl::NoOpDeviceGuardImpl<at::DeviceType::AXDIMM>);
+    PNM,
+    c10::impl::NoOpDeviceGuardImpl<at::DeviceType::PNM>);
diff --git a/aten/src/ATen/native/axdimm/AxdimmOpaqueTensor.h b/aten/src/ATen/native/pnm/PNMOpaqueTensor.h
similarity index 75%
rename from aten/src/ATen/native/axdimm/AxdimmOpaqueTensor.h
rename to aten/src/ATen/native/pnm/PNMOpaqueTensor.h
index 626d2584..93c164ff 100644
--- a/aten/src/ATen/native/axdimm/AxdimmOpaqueTensor.h
+++ b/aten/src/ATen/native/pnm/PNMOpaqueTensor.h
@@ -1,5 +1,5 @@
-#ifndef __AXDIMM_OPAQUE_TENSOR__
-#define __AXDIMM_OPAQUE_TENSOR__
+#ifndef __PNM_OPAQUE_TENSOR__
+#define __PNM_OPAQUE_TENSOR__
 
 #include <ATen/OpaqueTensorImpl.h>
 
@@ -11,13 +11,13 @@ namespace at {
  * type, that encapsulates device specific data and operations. OpaqueHandle has
  * no interface requirements Reference to handle can be aquired from at::Tensor
  * object using: auto impl =
- * static_cast<at::AxdimmOpaqueTensorImpl<at::native::axdimm::AxdimmTensor>*>(tensor.unsafeGetTensorImpl());
- * impl->unsafe_opaque_handle() <- returns at::native::axdimm::AxdimmTensor
+ * static_cast<at::PnmOpaqueTensorImpl<at::native::pnm::PnmTensor>*>(tensor.unsafeGetTensorImpl());
+ * impl->unsafe_opaque_handle() <- returns at::native::pnm::PnmTensor
  * reference
  */
 template <typename OpaqueHandle>
-struct AxdimmOpaqueTensorImpl : public OpaqueTensorImpl<OpaqueHandle> {
-  AxdimmOpaqueTensorImpl(
+struct PnmOpaqueTensorImpl : public OpaqueTensorImpl<OpaqueHandle> {
+  PnmOpaqueTensorImpl(
       at::DispatchKeySet key_set,
       const caffe2::TypeMeta data_type,
       c10::Device device,
@@ -43,7 +43,7 @@ struct AxdimmOpaqueTensorImpl : public OpaqueTensorImpl<OpaqueHandle> {
 
  private:
   const char* tensorimpl_type_name() const override {
-    return "AxdimmOpaqueTensorImpl";
+    return "PnmOpaqueTensorImpl";
   }
 
   SmallVector<int64_t, 5> strides_;
diff --git a/aten/src/ATen/native/axdimm/AxdimmSecureTensor.cpp b/aten/src/ATen/native/pnm/PNMSecureTensor.cpp
similarity index 66%
rename from aten/src/ATen/native/axdimm/AxdimmSecureTensor.cpp
rename to aten/src/ATen/native/pnm/PNMSecureTensor.cpp
index 13b74ccd..e8b7f105 100644
--- a/aten/src/ATen/native/axdimm/AxdimmSecureTensor.cpp
+++ b/aten/src/ATen/native/pnm/PNMSecureTensor.cpp
@@ -1,8 +1,8 @@
-#include <pnmlib/secure/sls_runner_factory.h>
 #include <pnmlib/secure/base_device.h>
+#include <pnmlib/secure/sls_runner_factory.h>
 #include <pnmlib/secure/untrusted_sls_params.h>
 
-#include <ATen/native/axdimm/AxdimmSecureTensor.h>
+#include <ATen/native/pnm/PNMSecureTensor.h>
 
 #include <torch/library.h>
 #include <torch/types.h>
@@ -11,18 +11,18 @@
 
 namespace at {
 namespace native {
-namespace axdimm {
+namespace pnm {
 
-AxdimmSecureTensor::AxdimmSecureTensor(
+PnmSecureTensor::PnmSecureTensor(
     const std::string& weights_path,
     const c10::ScalarType& scalar_type,
     const at::Tensor& tables_rows_num,
-    AxdimmTensorType tensor_type,
+    PnmTensorType tensor_type,
     uint32_t num_tables,
     uint32_t sparse_feature_size,
     axd_user_preferences preference,
     bool with_tag)
-    : AxdimmBaseTensor(
+    : PnmBaseTensor(
           weights_path,
           scalar_type,
           tables_rows_num,
@@ -34,15 +34,15 @@ AxdimmSecureTensor::AxdimmSecureTensor(
   load(mmap_weights_file());
 }
 
-AxdimmSecureTensor::AxdimmSecureTensor(
+PnmSecureTensor::PnmSecureTensor(
     const at::Tensor& weights,
-    AxdimmTensorType type,
+    PnmTensorType type,
     uint32_t num_tables,
     uint32_t features_per_table,
     uint32_t sparse_feature_size,
     axd_user_preferences preference,
     bool with_tag)
-    : AxdimmBaseTensor(
+    : PnmBaseTensor(
           weights,
           type,
           num_tables,
@@ -54,12 +54,12 @@ AxdimmSecureTensor::AxdimmSecureTensor(
   load(weights.data_ptr());
 }
 
-AxdimmSecureTensor::AxdimmSecureTensor(
+PnmSecureTensor::PnmSecureTensor(
     const at::Tensor& weights,
-    AxdimmTensorType type,
+    PnmTensorType type,
     axd_user_preferences preference,
     bool with_tag)
-    : AxdimmBaseTensor(
+    : PnmBaseTensor(
           weights,
           type,
           weights.sizes()[0],
@@ -71,32 +71,29 @@ AxdimmSecureTensor::AxdimmSecureTensor(
   load(weights.data_ptr());
 }
 
-void AxdimmSecureTensor::check_params(const at::Tensor& weights) const {
+void PnmSecureTensor::check_params(const at::Tensor& weights) const {
   TORCH_CHECK(
-      type_ == AxdimmTensorType::AXDIMM_SECURE,
-      "Secure tensor type must be AXDIMM_SECURE");
+      type_ == PnmTensorType::PNM_SECURE,
+      "Secure tensor type must be PNM_SECURE");
 }
 
-void AxdimmSecureTensor::load(const void* weights_data) {
+void PnmSecureTensor::load(const void* weights_data) {
   TORCH_INTERNAL_ASSERT(weights_data, "Weights data can't be null");
-  if (type_ == AxdimmTensorType::AXDIMM_SECURE) {
+  if (type_ == PnmTensorType::PNM_SECURE) {
     if (scalar_type_ == torch::kFloat32) {
-      runner_ = ::sls::secure::make_runner(
-          ::sls::secure::RunnerType::FLOAT);
+      runner_ = ::sls::secure::make_runner(::sls::secure::RunnerType::FLOAT);
     } else {
-      runner_ = ::sls::secure::make_runner(
-          ::sls::secure::RunnerType::INT);
+      runner_ = ::sls::secure::make_runner(::sls::secure::RunnerType::INT);
     }
   }
 
   const auto& rows_view = ::pnm::make_view(std::cref(tables_rows_num_).get());
 
-  ::sls::secure::DeviceArguments args(
-      ::sls::secure::UntrustedDeviceParams{
-          .rows = rows_view,
-          .sparse_feature_size = sparse_feature_size_,
-          .with_tag = with_tag_,
-          .preference = static_cast<axd_user_preferences>(preference_)});
+  ::sls::secure::DeviceArguments args(::sls::secure::UntrustedDeviceParams{
+      .rows = rows_view,
+      .sparse_feature_size = sparse_feature_size_,
+      .with_tag = with_tag_,
+      .preference = static_cast<axd_user_preferences>(preference_)});
   runner_->init(&args);
 
   if (scalar_type_ == torch::kFloat32) {
@@ -112,6 +109,6 @@ void AxdimmSecureTensor::load(const void* weights_data) {
   }
 }
 
-} // namespace axdimm
+} // namespace pnm
 } // namespace native
 } // namespace at
diff --git a/aten/src/ATen/native/axdimm/AxdimmSecureTensor.h b/aten/src/ATen/native/pnm/PNMSecureTensor.h
similarity index 80%
rename from aten/src/ATen/native/axdimm/AxdimmSecureTensor.h
rename to aten/src/ATen/native/pnm/PNMSecureTensor.h
index a7c893f7..7ee40851 100644
--- a/aten/src/ATen/native/axdimm/AxdimmSecureTensor.h
+++ b/aten/src/ATen/native/pnm/PNMSecureTensor.h
@@ -1,44 +1,44 @@
-#ifndef __AXDIMM_SECURE_TENSOR__
-#define __AXDIMM_SECURE_TENSOR__
+#ifndef __PNM_SECURE_TENSOR__
+#define __PNM_SECURE_TENSOR__
 
 #include <pnmlib/ai/sls.h>
 #include <pnmlib/secure/base_runner.h>
 
 #include <ATen/ATen.h>
-#include <ATen/native/axdimm/AxdimmBaseTensor.h>
-#include <ATen/native/axdimm/AxdimmTypeHelpers.h>
+#include <ATen/native/pnm/PNMBaseTensor.h>
+#include <ATen/native/pnm/PNMTypeHelpers.h>
 
 #include <algorithm>
 
 namespace at {
 namespace native {
-namespace axdimm {
+namespace pnm {
 
 //! This class represents internal at::Tensor handle, for device specific logic
 //! implementation
-class AxdimmSecureTensor : public AxdimmBaseTensor {
+class PnmSecureTensor : public PnmBaseTensor {
  public:
-  AxdimmSecureTensor(
+  PnmSecureTensor(
       const std::string& weights_path,
       const c10::ScalarType& scalar_type,
       const at::Tensor& tables_rows_num,
-      AxdimmTensorType tensor_type,
+      PnmTensorType tensor_type,
       uint32_t num_tables,
       uint32_t sparse_feature_size,
       axd_user_preferences preference = AXDIMM_ALLOC_DISTRIBUTE_ALL,
       bool with_tag = false);
-  AxdimmSecureTensor(
+  PnmSecureTensor(
       const at::Tensor& tables,
-      AxdimmTensorType type,
+      PnmTensorType type,
       uint32_t num_tables,
       uint32_t features_per_table,
       uint32_t sparse_feature_size,
       axd_user_preferences preference = AXDIMM_ALLOC_DISTRIBUTE_ALL,
       bool with_tag = false);
 
-  AxdimmSecureTensor(
+  PnmSecureTensor(
       const at::Tensor& weights,
-      AxdimmTensorType type,
+      PnmTensorType type,
       axd_user_preferences preference = AXDIMM_ALLOC_DISTRIBUTE_ALL,
       bool with_tag = false);
 
@@ -71,7 +71,7 @@ class AxdimmSecureTensor : public AxdimmBaseTensor {
   bool with_tag_;
 };
 
-} // namespace axdimm
+} // namespace pnm
 } // namespace native
 } // namespace at
 
diff --git a/aten/src/ATen/native/axdimm/AxdimmTensor.cpp b/aten/src/ATen/native/pnm/PNMTensor.cpp
similarity index 69%
rename from aten/src/ATen/native/axdimm/AxdimmTensor.cpp
rename to aten/src/ATen/native/pnm/PNMTensor.cpp
index 6d50fe6b..ad6f81ca 100644
--- a/aten/src/ATen/native/axdimm/AxdimmTensor.cpp
+++ b/aten/src/ATen/native/pnm/PNMTensor.cpp
@@ -2,7 +2,7 @@
 
 #include <c10/util/Logging.h>
 
-#include <ATen/native/axdimm/AxdimmTensor.h>
+#include <ATen/native/pnm/PNMTensor.h>
 
 namespace {
 
@@ -20,32 +20,29 @@ namespace {
 
 namespace at {
 namespace native {
-namespace axdimm {
+namespace pnm {
 
-AxdimmTensor::AxdimmTensor(
-    const at::Tensor& weights,
-    axd_user_preferences preference)
-    : AxdimmBaseTensor(
+PnmTensor::PnmTensor(const at::Tensor& weights, axd_user_preferences preference)
+    : PnmBaseTensor(
           weights,
-          AxdimmTensorType::AXDIMM_SIMPLE,
+          PnmTensorType::PNM_SIMPLE,
           weights.sizes()[0],
           weights.sizes()[1],
           weights.sizes()[2],
           preference) {
-  TORCH_CHECK(
-      weights.dim() == 3, "Axdimm tensor dimensions must be equal to 3");
+  TORCH_CHECK(weights.dim() == 3, "Pnm tensor dimensions must be equal to 3");
   load(weights.data_ptr());
 }
 
-AxdimmTensor::AxdimmTensor(
+PnmTensor::PnmTensor(
     const at::Tensor& weights,
     uint32_t num_tables,
     uint32_t features_per_table,
     uint32_t sparse_feature_size,
     axd_user_preferences preference)
-    : AxdimmBaseTensor(
+    : PnmBaseTensor(
           weights,
-          AxdimmTensorType::AXDIMM_SIMPLE,
+          PnmTensorType::PNM_SIMPLE,
           num_tables,
           features_per_table,
           sparse_feature_size,
@@ -53,41 +50,41 @@ AxdimmTensor::AxdimmTensor(
   load(weights.data_ptr());
 }
 
-AxdimmTensor::AxdimmTensor(
+PnmTensor::PnmTensor(
     const std::string& weights_path,
     const c10::ScalarType& scalar_type,
     const at::Tensor& tables_rows_num,
     uint32_t num_tables,
     uint32_t sparse_feature_size,
     axd_user_preferences preference)
-    : AxdimmBaseTensor(
+    : PnmBaseTensor(
           weights_path,
           scalar_type,
           tables_rows_num,
-          AxdimmTensorType::AXDIMM_SIMPLE,
+          PnmTensorType::PNM_SIMPLE,
           num_tables,
           sparse_feature_size,
           preference) {
   load(mmap_weights_file());
 }
 
-void AxdimmTensor::load(const void* weights_data) {
+void PnmTensor::load(const void* weights_data) {
   sls_type_ = ::get_sls_type(scalar_type_);
-  runner_ = pnm::Runner(get_pnm_context());
+  runner_ = ::pnm::Runner(get_pnm_context());
 
   auto tables_size =
       std::accumulate(tables_rows_num_.begin(), tables_rows_num_.end(), 0ULL);
   tables_size *=
       sparse_feature_size_ * c10::scalarTypeToTypeMeta(scalar_type_).itemsize();
 
-  tables_ = pnm::memory::EmbeddedTables::create(
-      pnm::make_view(static_cast<const uint8_t*>(weights_data), tables_size),
+  tables_ = ::pnm::memory::EmbeddedTables::create(
+      ::pnm::make_view(static_cast<const uint8_t*>(weights_data), tables_size),
       tables_rows_num_,
       sparse_feature_size_ * c10::scalarTypeToTypeMeta(scalar_type_).itemsize(),
       get_pnm_context(),
       preference_);
 }
 
-} // namespace axdimm
+} // namespace pnm
 } // namespace native
 } // namespace at
diff --git a/aten/src/ATen/native/axdimm/AxdimmTensor.h b/aten/src/ATen/native/pnm/PNMTensor.h
similarity index 70%
rename from aten/src/ATen/native/axdimm/AxdimmTensor.h
rename to aten/src/ATen/native/pnm/PNMTensor.h
index 6a0f11a1..707ccfb6 100644
--- a/aten/src/ATen/native/axdimm/AxdimmTensor.h
+++ b/aten/src/ATen/native/pnm/PNMTensor.h
@@ -1,43 +1,43 @@
-#ifndef __AXDIMM_TENSOR__
-#define __AXDIMM_TENSOR__
+#ifndef __PNM_TENSOR__
+#define __PNM_TENSOR__
 
-#include <pnmlib/ai/sls.h>
 #include <pnmlib/ai/embedded_tables.h>
+#include <pnmlib/ai/sls.h>
 #include <pnmlib/ai/sls_type.h>
 
-#include <pnmlib/core/sls_device.h>
 #include <pnmlib/core/runner.h>
+#include <pnmlib/core/sls_device.h>
 
 #include <ATen/ATen.h>
-#include <ATen/native/axdimm/AxdimmBaseTensor.h>
-#include <ATen/native/axdimm/AxdimmDeviceContext.h>
-#include <ATen/native/axdimm/AxdimmOpaqueTensor.h>
+#include <ATen/native/pnm/PNMBaseTensor.h>
+#include <ATen/native/pnm/PNMDeviceContext.h>
+#include <ATen/native/pnm/PNMOpaqueTensor.h>
 
 #include <torch/library.h>
 #include <torch/types.h>
 
 namespace at {
 namespace native {
-namespace axdimm {
+namespace pnm {
 
 void verify(const at::TensorOptions& options);
 
 //! This class represents internal at::Tensor handle, for device specific logic
 //! implementation
-class AxdimmTensor : public AxdimmBaseTensor {
+class PnmTensor : public PnmBaseTensor {
  public:
-  AxdimmTensor(
+  PnmTensor(
       const at::Tensor& weights,
       ::axd_user_preferences preference = AXDIMM_ALLOC_DISTRIBUTE_ALL);
 
-  AxdimmTensor(
+  PnmTensor(
       const at::Tensor& weights,
       uint32_t num_tables,
       uint32_t features_per_table,
       uint32_t sparse_feature_size,
       axd_user_preferences preference);
 
-  AxdimmTensor(
+  PnmTensor(
       const std::string& weights_path,
       const c10::ScalarType& scalar_type,
       const at::Tensor& tables_rows_num,
@@ -45,7 +45,7 @@ class AxdimmTensor : public AxdimmBaseTensor {
       uint32_t sparse_feature_size,
       axd_user_preferences preference = AXDIMM_ALLOC_DISTRIBUTE_ALL);
 
-  const pnm::memory::EmbeddedTables* get_tables_layout() const {
+  const ::pnm::memory::EmbeddedTables* get_tables_layout() const {
     return tables_.get();
   }
 
@@ -53,19 +53,19 @@ class AxdimmTensor : public AxdimmBaseTensor {
     return sls_type_;
   }
 
-  const pnm::Runner& get_runner() const {
+  const ::pnm::Runner& get_runner() const {
     return runner_;
   }
 
  private:
   void load(const void* weights_data);
 
-  pnm::memory::EmbeddedTablesHandler tables_;
+  ::pnm::memory::EmbeddedTablesHandler tables_;
   SLSType sls_type_{};
-  pnm::Runner runner_;
+  ::pnm::Runner runner_;
 };
 
-} // namespace axdimm
+} // namespace pnm
 } // namespace native
 } // namespace at
 
diff --git a/aten/src/ATen/native/pnm/PNMTensorConvert.h b/aten/src/ATen/native/pnm/PNMTensorConvert.h
new file mode 100644
index 00000000..a932bfb3
--- /dev/null
+++ b/aten/src/ATen/native/pnm/PNMTensorConvert.h
@@ -0,0 +1,33 @@
+#ifndef __PNM_TENSOR_CONVERT__
+#define __PNM_TENSOR_CONVERT__
+
+#include <ATen/native/pnm/PNMSecureTensor.h>
+#include <ATen/native/pnm/PNMTensor.h>
+
+namespace at {
+namespace native {
+namespace pnm {
+
+template <typename T>
+const T& convert(const at::Tensor& tensor) {
+  TORCH_INTERNAL_ASSERT(tensor.is_pnm());
+  PnmTensorImpl* impl =
+      static_cast<PnmTensorImpl*>(tensor.unsafeGetTensorImpl());
+  const PnmBaseTensor* tensor_ptr = impl->unsafe_opaque_handle().get();
+  const auto tensor_type = tensor_ptr->get_tensor_type();
+  TORCH_INTERNAL_ASSERT(
+      tensor_type == PnmTensorType::PNM_SIMPLE ||
+          tensor_type == PnmTensorType::PNM_SECURE,
+      "Unsuported tensor type");
+
+  const T* res = dynamic_cast<const T*>(tensor_ptr);
+  TORCH_INTERNAL_ASSERT(res, "Failed to convert tensor");
+
+  return *res;
+}
+
+} // namespace pnm
+} // namespace native
+} // namespace at
+
+#endif
diff --git a/aten/src/ATen/native/axdimm/AxdimmTypeHelpers.h b/aten/src/ATen/native/pnm/PNMTypeHelpers.h
similarity index 93%
rename from aten/src/ATen/native/axdimm/AxdimmTypeHelpers.h
rename to aten/src/ATen/native/pnm/PNMTypeHelpers.h
index 7a0fb213..bbf0939e 100644
--- a/aten/src/ATen/native/axdimm/AxdimmTypeHelpers.h
+++ b/aten/src/ATen/native/pnm/PNMTypeHelpers.h
@@ -1,5 +1,5 @@
-#ifndef __AXDIMM_TYPE_HELPERS__
-#define __AXDIMM_TYPE_HELPERS__
+#ifndef __PNM_TYPE_HELPERS__
+#define __PNM_TYPE_HELPERS__
 
 #include <pnmlib/common/views.h>
 
@@ -8,7 +8,7 @@
 
 namespace at {
 namespace native {
-namespace axdimm {
+namespace pnm {
 
 // Compile type helper to resolve types for sls operator
 template <typename T>
@@ -59,7 +59,7 @@ struct SecureScale {
   }
 };
 
-} // namespace axdimm
+} // namespace pnm
 } // namespace native
 } // namespace at
 
diff --git a/aten/src/ATen/native/pnm/ops/Copy.cpp b/aten/src/ATen/native/pnm/ops/Copy.cpp
new file mode 100644
index 00000000..355fa8f8
--- /dev/null
+++ b/aten/src/ATen/native/pnm/ops/Copy.cpp
@@ -0,0 +1,28 @@
+#include <ATen/native/pnm/PNMOpaqueTensor.h>
+#include <ATen/native/pnm/PNMTensor.h>
+
+#include <torch/library.h>
+
+namespace at {
+namespace native {
+namespace pnm {
+
+// implementation is required for dispatched tensor creation
+at::Tensor& copy_pnm_(
+    at::Tensor& self,
+    const at::Tensor& src,
+    bool non_blocking) {
+  TORCH_INTERNAL_ASSERT(self.is_pnm());
+  TORCH_CHECK(src.is_cpu(), "Only CPU tensors can be copied to PNM device");
+  auto impl = static_cast<PnmTensorImpl*>(self.unsafeGetTensorImpl());
+  impl->unsafe_opaque_handle() = std::make_shared<PnmTensor>(src);
+  return self;
+}
+
+TORCH_LIBRARY_IMPL(aten, PNM, m) {
+  m.impl(TORCH_SELECTIVE_NAME("aten::copy_"), TORCH_FN(copy_pnm_));
+}
+
+} // namespace pnm
+} // namespace native
+} // namespace at
diff --git a/aten/src/ATen/native/axdimm/ops/EmbeddingBag.cpp b/aten/src/ATen/native/pnm/ops/EmbeddingBag.cpp
similarity index 77%
rename from aten/src/ATen/native/axdimm/ops/EmbeddingBag.cpp
rename to aten/src/ATen/native/pnm/ops/EmbeddingBag.cpp
index 625a5531..223c64ca 100644
--- a/aten/src/ATen/native/axdimm/ops/EmbeddingBag.cpp
+++ b/aten/src/ATen/native/pnm/ops/EmbeddingBag.cpp
@@ -1,7 +1,7 @@
 #include <pnmlib/ai/sls.h>
 #include <pnmlib/ai/sls_operation.h>
 
-#include <ATen/native/axdimm/AxdimmTensorConvert.h>
+#include <ATen/native/pnm/PNMTensorConvert.h>
 
 #include <torch/autograd.h>
 #include <torch/library.h>
@@ -10,14 +10,14 @@ namespace {
 
 void transform_offsets(
     const at::Tensor& offsets,
-    std::vector<uint32_t>& axdimm_lengths_out) {
+    std::vector<uint32_t>& pnm_lengths_out) {
   const auto num_tables = offsets.sizes()[0];
   const auto minibatch_size = offsets.sizes()[1] - 1;
-  axdimm_lengths_out.reserve(num_tables * minibatch_size);
+  pnm_lengths_out.reserve(num_tables * minibatch_size);
   auto batch = static_cast<const uint32_t*>(offsets.data_ptr());
   for (size_t table_idx = 0; table_idx < num_tables; ++table_idx) {
     for (size_t batch_idx = 0; batch_idx < minibatch_size; ++batch_idx) {
-      axdimm_lengths_out.push_back(batch[batch_idx + 1] - batch[batch_idx]);
+      pnm_lengths_out.push_back(batch[batch_idx + 1] - batch[batch_idx]);
     }
     batch += minibatch_size + 1;
   }
@@ -27,7 +27,7 @@ void transform_offsets(
 
 namespace at {
 namespace native {
-namespace axdimm {
+namespace pnm {
 
 at::Tensor embedding_bag_forward_simple_impl(
     const at::Tensor& weights,
@@ -35,16 +35,16 @@ at::Tensor embedding_bag_forward_simple_impl(
     ::pnm::common_view<const uint32_t> lengths_view,
     ::pnm::common_view<uint8_t> output_view,
     uint32_t minibatch_size) {
-  const AxdimmTensor& ten = convert<AxdimmTensor>(weights);
+  const PnmTensor& ten = convert<PnmTensor>(weights);
   const auto& tables_rows_num = ten.get_tables_rows_num();
 
   PNMSLSOperation sls_op{
       ten.get_sparse_feature_size(),
-      pnm::make_view(tables_rows_num),
+      ::pnm::make_view(tables_rows_num),
       ten.get_tables_layout(),
       ten.get_sls_type()};
 
-  auto indices_view = pnm::view_cast<const uint32_t>(pnm::make_view(
+  auto indices_view = ::pnm::view_cast<const uint32_t>(::pnm::make_view(
       static_cast<const uint8_t*>(indices.data_ptr()), indices.nbytes()));
 
   sls_op.set_run_params(
@@ -69,7 +69,7 @@ at::Tensor embedding_bag_forward_secure_impl(
     ::pnm::common_view<const uint32_t> lengths_view,
     ::pnm::common_view<uint8_t> output_view,
     uint32_t minibatch_size) {
-  const AxdimmSecureTensor& sec_ten = convert<AxdimmSecureTensor>(weights);
+  const PnmSecureTensor& sec_ten = convert<PnmSecureTensor>(weights);
 
   ::pnm::common_view<uint8_t> checks{};
   std::vector<uint8_t> tag_checks_;
@@ -88,7 +88,7 @@ at::Tensor embedding_bag_forward_secure_impl(
       output_view,
       checks);
 
-  TORCH_CHECK(status, "Axdimm secure embeddings calculation failed");
+  TORCH_CHECK(status, "Pnm secure embeddings calculation failed");
 
   auto output_int_v = ::pnm::view_cast<const uint32_t>(output_view);
 
@@ -109,11 +109,11 @@ at::Tensor embedding_bag_forward_secure_impl(
       torch::TensorOptions().dtype(weights.dtype()).device(torch::kCPU));
 }
 
-at::Tensor embedding_bag_forward_only_axdimm(
+at::Tensor embedding_bag_forward_only_pnm(
     const at::Tensor& weights,
     const at::Tensor& indices,
     const at::Tensor& offsets) {
-  TORCH_INTERNAL_ASSERT(weights.is_axdimm());
+  TORCH_INTERNAL_ASSERT(weights.is_pnm());
   TORCH_CHECK(indices.is_cpu(), "Indices must be CPU tensor");
   TORCH_CHECK(offsets.is_cpu(), "Offsets must be CPU tensor");
   TORCH_CHECK(
@@ -129,7 +129,7 @@ at::Tensor embedding_bag_forward_only_axdimm(
 
   const uint32_t minibatch_size = offsets.sizes()[1] - 1;
 
-  const AxdimmBaseTensor& base_ten = convert<AxdimmBaseTensor>(weights);
+  const PnmBaseTensor& base_ten = convert<PnmBaseTensor>(weights);
 
   TORCH_CHECK(
       offsets.sizes()[0] == base_ten.get_num_tables(),
@@ -140,18 +140,18 @@ at::Tensor embedding_bag_forward_only_axdimm(
   uint8_t* psum_buf = new uint8_t[psum_buf_size_bytes];
   auto output_view = ::pnm::make_view(psum_buf, psum_buf + psum_buf_size_bytes);
 
-  std::vector<uint32_t> axdimm_lengths;
-  transform_offsets(offsets, axdimm_lengths);
-  auto lengths_view = ::pnm::make_view(std::cref(axdimm_lengths).get());
+  std::vector<uint32_t> pnm_lengths;
+  transform_offsets(offsets, pnm_lengths);
+  auto lengths_view = ::pnm::make_view(std::cref(pnm_lengths).get());
 
-  if (base_ten.get_tensor_type() == AxdimmTensorType::AXDIMM_SECURE) {
+  if (base_ten.get_tensor_type() == PnmTensorType::PNM_SECURE) {
     return embedding_bag_forward_secure_impl(
         weights, indices, lengths_view, output_view, minibatch_size);
-  } else if (base_ten.get_tensor_type() == AxdimmTensorType::AXDIMM_SIMPLE) {
+  } else if (base_ten.get_tensor_type() == PnmTensorType::PNM_SIMPLE) {
     return embedding_bag_forward_simple_impl(
         weights, indices, lengths_view, output_view, minibatch_size);
   } else {
-    TORCH_CHECK(false, "Unsupported Axdimm tensor type");
+    TORCH_CHECK(false, "Unsupported Pnm tensor type");
   }
 }
 
@@ -159,22 +159,21 @@ at::Tensor embedding_bag_forward_only_axdimm(
 // (aten)
 TORCH_LIBRARY_FRAGMENT(aten, m) {
   m.def(
-      "aten::embedding_bag_forward_only_axdimm(Tensor weights, Tensor indices, Tensor offsets) -> Tensor");
+      "aten::embedding_bag_forward_only_pnm(Tensor weights, Tensor indices, Tensor offsets) -> Tensor");
 }
 
-TORCH_LIBRARY_IMPL(aten, AXDIMM, m) {
+TORCH_LIBRARY_IMPL(aten, PNM, m) {
   m.impl(
-      "aten::embedding_bag_forward_only_axdimm",
-      embedding_bag_forward_only_axdimm);
+      "aten::embedding_bag_forward_only_pnm", embedding_bag_forward_only_pnm);
 }
 
 // Disable autograd for operator since it supports only inference
 TORCH_LIBRARY_IMPL(aten, Autograd, m) {
   m.impl(
-      "aten::embedding_bag_forward_only_axdimm",
+      "aten::embedding_bag_forward_only_pnm",
       torch::autograd::autogradNotImplementedFallback());
 }
 
-} // namespace axdimm
+} // namespace pnm
 } // namespace native
 } // namespace at
diff --git a/aten/src/ATen/native/axdimm/ops/Factory.cpp b/aten/src/ATen/native/pnm/ops/Factory.cpp
similarity index 61%
rename from aten/src/ATen/native/axdimm/ops/Factory.cpp
rename to aten/src/ATen/native/pnm/ops/Factory.cpp
index 64426dff..dd0de3a0 100644
--- a/aten/src/ATen/native/axdimm/ops/Factory.cpp
+++ b/aten/src/ATen/native/pnm/ops/Factory.cpp
@@ -1,6 +1,6 @@
-#include <ATen/native/axdimm/AxdimmOpaqueTensor.h>
-#include <ATen/native/axdimm/AxdimmSecureTensor.h>
-#include <ATen/native/axdimm/AxdimmTensor.h>
+#include <ATen/native/pnm/PNMOpaqueTensor.h>
+#include <ATen/native/pnm/PNMSecureTensor.h>
+#include <ATen/native/pnm/PNMTensor.h>
 #include <c10/core/ScalarTypeToTypeMeta.h>
 
 #include <fmt/format.h>
@@ -10,10 +10,10 @@
 
 namespace at {
 namespace native {
-namespace axdimm {
+namespace pnm {
 
 // Implementation is required for dispatched tensor creation
-at::Tensor empty_strided_axdimm(
+at::Tensor empty_strided_pnm(
     at::IntArrayRef size,
     at::IntArrayRef stride,
     c10::optional<at::ScalarType> dtype = {},
@@ -27,52 +27,51 @@ at::Tensor empty_strided_axdimm(
                   .pinned_memory(pin_memory)
                   .memory_format(c10::MemoryFormat::Contiguous);
   verify(opts);
-  return at::detail::make_tensor<at::native::axdimm::AxdimmTensorImpl>(
-      at::DispatchKeySet(at::DispatchKey::AXDIMM),
+  return at::detail::make_tensor<at::native::pnm::PnmTensorImpl>(
+      at::DispatchKeySet(at::DispatchKey::PNM),
       opts.dtype(),
-      at::Device(at::kAXDIMM),
+      at::Device(at::kPNM),
       nullptr,
       size,
       stride);
 }
 
-TORCH_LIBRARY_IMPL(aten, AXDIMM, m) {
+TORCH_LIBRARY_IMPL(aten, PNM, m) {
   m.impl(
-      TORCH_SELECTIVE_NAME("aten::empty_strided"),
-      TORCH_FN(empty_strided_axdimm));
+      TORCH_SELECTIVE_NAME("aten::empty_strided"), TORCH_FN(empty_strided_pnm));
 }
 
 const std::string gkSimpleTensor = "simple";
 const std::string gkSecureTensor = "secure";
 
-std::unordered_map<std::string, AxdimmTensorType> gkAxdimmTensorTypeMap{
-    {gkSimpleTensor, AxdimmTensorType::AXDIMM_SIMPLE},
-    {gkSecureTensor, AxdimmTensorType::AXDIMM_SECURE}};
+std::unordered_map<std::string, PnmTensorType> gkPnmTensorTypeMap{
+    {gkSimpleTensor, PnmTensorType::PNM_SIMPLE},
+    {gkSecureTensor, PnmTensorType::PNM_SECURE}};
 
 at::Tensor create_tensor_helper(
-    std::shared_ptr<AxdimmBaseTensor>&& tensor,
+    std::shared_ptr<PnmBaseTensor>&& tensor,
     const caffe2::TypeMeta& dtype,
     at::IntArrayRef sizes,
     at::IntArrayRef strides) {
-  return at::detail::make_tensor<AxdimmTensorImpl>(
-      at::DispatchKeySet(at::DispatchKey::AXDIMM),
+  return at::detail::make_tensor<PnmTensorImpl>(
+      at::DispatchKeySet(at::DispatchKey::PNM),
       dtype,
-      at::Device(at::kAXDIMM),
+      at::Device(at::kPNM),
       std::move(tensor),
       sizes,
       strides);
 }
 
-AxdimmTensorType get_tensor_type(const c10::string_view& tensor_type_name) {
-  const auto& it = gkAxdimmTensorTypeMap.find(tensor_type_name.data());
+PnmTensorType get_tensor_type(const c10::string_view& tensor_type_name) {
+  const auto& it = gkPnmTensorTypeMap.find(tensor_type_name.data());
   TORCH_CHECK(
-      it != std::end(gkAxdimmTensorTypeMap),
+      it != std::end(gkPnmTensorTypeMap),
       fmt::format("Wrong tensor type: {}", tensor_type_name.data()));
   return it->second;
 }
 
-/*! Factory function for axdimm tensor creation from cpu tensor.
- *  Available in python using: torch.ops.axdimm.create_tensor
+/*! Factory function for pnm tensor creation from cpu tensor.
+ *  Available in python using: torch.ops.pnm.create_tensor
  */
 at::Tensor create_tensor_from_weights(
     c10::string_view tensor_type_name,
@@ -82,19 +81,19 @@ at::Tensor create_tensor_from_weights(
     int64_t sparse_feature_size,
     int64_t allocation_preference,
     c10::optional<bool> with_tag = {}) {
-  std::shared_ptr<AxdimmBaseTensor> tensor;
+  std::shared_ptr<PnmBaseTensor> tensor;
   const auto tensor_type = get_tensor_type(tensor_type_name);
   switch (tensor_type) {
-    case AxdimmTensorType::AXDIMM_SIMPLE:
-      tensor = std::make_shared<AxdimmTensor>(
+    case PnmTensorType::PNM_SIMPLE:
+      tensor = std::make_shared<PnmTensor>(
           weights,
           num_tables,
           features_per_table,
           sparse_feature_size,
           static_cast<axd_user_preferences>(allocation_preference));
       break;
-    case AxdimmTensorType::AXDIMM_SECURE:
-      tensor = std::make_shared<AxdimmSecureTensor>(
+    case PnmTensorType::PNM_SECURE:
+      tensor = std::make_shared<PnmSecureTensor>(
           weights,
           tensor_type,
           num_tables,
@@ -109,8 +108,8 @@ at::Tensor create_tensor_from_weights(
       std::move(tensor), weights.dtype(), weights.sizes(), weights.strides());
 }
 
-/*! Factory function for axdimm tensor creation from cpu tensor.
- *  Available in python using: torch.ops.axdimm.create_tensor
+/*! Factory function for pnm tensor creation from cpu tensor.
+ *  Available in python using: torch.ops.pnm.create_tensor
  */
 at::Tensor create_tensor_from_file(
     c10::string_view tensor_type_name,
@@ -121,11 +120,11 @@ at::Tensor create_tensor_from_file(
     int64_t sparse_feature_size,
     int64_t allocation_preference,
     c10::optional<bool> with_tag = {}) {
-  std::shared_ptr<AxdimmBaseTensor> tensor;
+  std::shared_ptr<PnmBaseTensor> tensor;
   const auto tensor_type = get_tensor_type(tensor_type_name);
   switch (tensor_type) {
-    case AxdimmTensorType::AXDIMM_SIMPLE:
-      tensor = std::make_shared<AxdimmTensor>(
+    case PnmTensorType::PNM_SIMPLE:
+      tensor = std::make_shared<PnmTensor>(
           weights_file_path.data(),
           scalar_type,
           tables_rows_num,
@@ -133,8 +132,8 @@ at::Tensor create_tensor_from_file(
           sparse_feature_size,
           static_cast<axd_user_preferences>(allocation_preference));
       break;
-    case AxdimmTensorType::AXDIMM_SECURE:
-      tensor = std::make_shared<AxdimmSecureTensor>(
+    case PnmTensorType::PNM_SECURE:
+      tensor = std::make_shared<PnmSecureTensor>(
           weights_file_path.data(),
           scalar_type,
           tables_rows_num,
@@ -150,25 +149,25 @@ at::Tensor create_tensor_from_file(
       std::move(tensor), c10::scalarTypeToTypeMeta(scalar_type), {}, {});
 }
 
-TORCH_LIBRARY(axdimm, m) {
+TORCH_LIBRARY(pnm, m) {
   m.def(TORCH_SELECTIVE_SCHEMA(
-      "axdimm::create_tensor.from_weights(str tensor_type_name, Tensor weights, int num_tables, int features_per_table,"
+      "pnm::create_tensor.from_weights(str tensor_type_name, Tensor weights, int num_tables, int features_per_table,"
       "int sparse_feature_size, int allocation_preference, bool? with_tag = False) -> Tensor"));
   m.def(TORCH_SELECTIVE_SCHEMA(
-      "axdimm::create_tensor.from_file(str tensor_type_name, str weights_file_path, ScalarType scalar_type,"
+      "pnm::create_tensor.from_file(str tensor_type_name, str weights_file_path, ScalarType scalar_type,"
       "Tensor tables_rows_num, int num_tables, int sparse_feature_size, int allocation_preference, bool? with_tag = False) -> Tensor"));
 }
 
-TORCH_LIBRARY_IMPL(axdimm, CPU, m) {
+TORCH_LIBRARY_IMPL(pnm, CPU, m) {
   m.impl(
-      TORCH_SELECTIVE_NAME("axdimm::create_tensor.from_weights"),
+      TORCH_SELECTIVE_NAME("pnm::create_tensor.from_weights"),
       TORCH_FN(create_tensor_from_weights));
   m.impl(
 
-      TORCH_SELECTIVE_NAME("axdimm::create_tensor.from_file"),
+      TORCH_SELECTIVE_NAME("pnm::create_tensor.from_file"),
       TORCH_FN(create_tensor_from_file));
 }
 
-} // namespace axdimm
+} // namespace pnm
 } // namespace native
 } // namespace at
diff --git a/aten/src/ATen/axdimm/is_axdimm_available.cpp b/aten/src/ATen/pnm/is_pnm_available.cpp
similarity index 62%
rename from aten/src/ATen/axdimm/is_axdimm_available.cpp
rename to aten/src/ATen/pnm/is_pnm_available.cpp
index 60e046b7..09cd6f41 100644
--- a/aten/src/ATen/axdimm/is_axdimm_available.cpp
+++ b/aten/src/ATen/pnm/is_pnm_available.cpp
@@ -1,14 +1,14 @@
 namespace at {
 namespace native {
 
-// Used to check if torch is linked with axdimm support from python
-// Call in python: torch.is_axdimm_available()
-// Function must be implemented even if torch linked without axdimm support,
+// Used to check if torch is linked with pnm support from python
+// Call in python: torch.is_pnm_available()
+// Function must be implemented even if torch linked without pnm support,
 // library won't link otherwise Schema is defined in
 // aten/src/ATen/native/native_functions.yaml Functions implementing schema must
 // be in at::native namespace Some extra logic can be implemented but atm is not
 // required
-bool is_axdimm_available() {
+bool is_pnm_available() {
 #ifdef USE_PNM
   return true;
 #else
diff --git a/c10/core/Backend.h b/c10/core/Backend.h
index d4601637..516813ec 100644
--- a/c10/core/Backend.h
+++ b/c10/core/Backend.h
@@ -56,7 +56,7 @@ enum class Backend {
   Lazy,
   MTIA,
   PrivateUse1,
-  AXDIMM,
+  PNM,
   NumOptions
 };
 
@@ -117,8 +117,8 @@ static inline Backend dispatchKeyToBackend(DispatchKey t) {
     return Backend::MTIA;
   } else if (t == DispatchKey::PrivateUse1) {
     return Backend::PrivateUse1;
-  } else if (t == DispatchKey::AXDIMM) {
-    return Backend::AXDIMM;
+  } else if (t == DispatchKey::PNM) {
+    return Backend::PNM;
   } else if (t == DispatchKey::Undefined) {
     return Backend::Undefined;
   } else {
@@ -184,8 +184,8 @@ static inline DispatchKey backendToDispatchKey(Backend b) {
       return DispatchKey::MTIA;
     case Backend::PrivateUse1:
       return DispatchKey::PrivateUse1;
-    case Backend::AXDIMM:
-      return DispatchKey::AXDIMM;
+    case Backend::PNM:
+      return DispatchKey::PNM;
     default:
       throw std::runtime_error("Unknown backend");
   }
@@ -246,8 +246,8 @@ static inline DeviceType backendToDeviceType(Backend b) {
       return DeviceType::MTIA;
     case Backend::PrivateUse1:
       return DeviceType::PrivateUse1;
-    case Backend::AXDIMM:
-      return DeviceType::AXDIMM;
+    case Backend::PNM:
+      return DeviceType::PNM;
     case Backend::Undefined:
       TORCH_CHECK(false, "Undefined backend is not a valid device type");
     default:
@@ -314,8 +314,8 @@ static inline const char* toString(Backend b) {
       return "MTIA";
     case Backend::PrivateUse1:
       return "PrivateUseOne";
-    case Backend::AXDIMM:
-      return "AXDIMM";
+    case Backend::PNM:
+      return "PNM";
     default:
       return "UNKNOWN_BACKEND";
   }
diff --git a/c10/core/CPUAllocator.cpp b/c10/core/CPUAllocator.cpp
index 0374a870..dcb61b42 100644
--- a/c10/core/CPUAllocator.cpp
+++ b/c10/core/CPUAllocator.cpp
@@ -189,7 +189,7 @@ at::Allocator* GetDefaultCPUAllocator() {
 REGISTER_ALLOCATOR(DeviceType::CPU, &g_cpu_alloc);
 
 namespace {
-  static AllocatorRegisterer<DeviceType::AXDIMM> g_allocator_d_axdimm(&g_cpu_alloc);
+static AllocatorRegisterer<DeviceType::PNM> g_allocator_d_pnm(&g_cpu_alloc);
 }
 
 #endif /* C10_Mobile */
diff --git a/c10/core/Device.cpp b/c10/core/Device.cpp
index 7acf17aa..8de73dde 100644
--- a/c10/core/Device.cpp
+++ b/c10/core/Device.cpp
@@ -37,7 +37,7 @@ DeviceType parse_type(const std::string& device_string) {
           {"hpu", DeviceType::HPU},
           {"mtia", DeviceType::MTIA},
           {"privateuseone", DeviceType::PrivateUse1},
-          {"axdimm", DeviceType::AXDIMM}
+          {"pnm", DeviceType::PNM}
       }};
   auto device = std::find_if(
       types.begin(),
diff --git a/c10/core/DeviceType.cpp b/c10/core/DeviceType.cpp
index 17abd7a9..1b9196fc 100644
--- a/c10/core/DeviceType.cpp
+++ b/c10/core/DeviceType.cpp
@@ -51,8 +51,8 @@ std::string DeviceTypeName(DeviceType d, bool lower_case) {
       return lower_case ? "mtia" : "MTIA";
     case DeviceType::PrivateUse1:
       return get_privateuse1_backend(/*lower_case=*/lower_case);
-    case DeviceType::AXDIMM:
-      return lower_case ? "axdimm" : "AXDIMM";
+    case DeviceType::PNM:
+      return lower_case ? "pnm" : "PNM";
     default:
       TORCH_CHECK(
           false,
@@ -97,7 +97,7 @@ bool isValidDeviceType(DeviceType d) {
     case DeviceType::IPU:
     case DeviceType::MTIA:
     case DeviceType::PrivateUse1:
-    case DeviceType::AXDIMM:
+    case DeviceType::PNM:
       return true;
     default:
       return false;
diff --git a/c10/core/DeviceType.h b/c10/core/DeviceType.h
index 7afbd4ec..862032cd 100644
--- a/c10/core/DeviceType.h
+++ b/c10/core/DeviceType.h
@@ -52,7 +52,7 @@ enum class DeviceType : int8_t {
   IPU = 18, // Graphcore IPU
   MTIA = 19, // Meta training and inference devices
   PrivateUse1 = 20, // PrivateUse1 device
-  AXDIMM = 21, // AXDIMM
+  PNM = 21, // PNM
   // NB: If you add more devices:
   //  - Change the implementations of DeviceTypeName and isValidDeviceType
   //    in DeviceType.cpp
@@ -77,7 +77,7 @@ constexpr DeviceType kLazy = DeviceType::Lazy;
 constexpr DeviceType kIPU = DeviceType::IPU;
 constexpr DeviceType kMTIA = DeviceType::MTIA;
 constexpr DeviceType kPrivateUse1 = DeviceType::PrivateUse1;
-constexpr DeviceType kAXDIMM = DeviceType::AXDIMM;
+constexpr DeviceType kPNM = DeviceType::PNM;
 
 // define explicit int constant
 constexpr int COMPILE_TIME_MAX_DEVICE_TYPES =
diff --git a/c10/core/DispatchKey.cpp b/c10/core/DispatchKey.cpp
index 3ce8b1ba..869a9d0f 100644
--- a/c10/core/DispatchKey.cpp
+++ b/c10/core/DispatchKey.cpp
@@ -81,8 +81,8 @@ const char* toString(DispatchKey t) {
       return "HPU";
     case DispatchKey::MTIA:
       return "MTIA";
-    case DispatchKey::AXDIMM:
-      return "AXDIMM";
+    case DispatchKey::PNM:
+      return "PNM";
 
     case DispatchKey::Quantized:
       return "Quantized";
@@ -308,7 +308,7 @@ c10::DispatchKey parseDispatchKey(const std::string& k) {
       {"XPU", c10::DispatchKey::XPU},
       {"IPU", c10::DispatchKey::IPU},
       {"HPU", c10::DispatchKey::HPU},
-      {"AXDIMM", c10::DispatchKey::AXDIMM},
+      {"PNM", c10::DispatchKey::PNM},
       {"Lazy", c10::DispatchKey::Lazy},
       {"MTIA", c10::DispatchKey::MTIA},
       {"NestedTensor", c10::DispatchKey::NestedTensor},
diff --git a/c10/core/DispatchKey.h b/c10/core/DispatchKey.h
index 37e42abd..7f2c2c6f 100644
--- a/c10/core/DispatchKey.h
+++ b/c10/core/DispatchKey.h
@@ -184,7 +184,7 @@ enum class DispatchKey : uint16_t {
   ORT,
 
   Vulkan, // TODO: put this in BackendComponents
-  AXDIMM,
+  PNM,
   Metal, // TODO: put this in BackendComponents
 
   // See [Note: Per-Backend Functionality Dispatch Keys]
diff --git a/c10/core/DispatchKeySet.h b/c10/core/DispatchKeySet.h
index 9d06a862..005cbf77 100644
--- a/c10/core/DispatchKeySet.h
+++ b/c10/core/DispatchKeySet.h
@@ -684,7 +684,8 @@ constexpr DispatchKeySet autogradother_backends =
         {DispatchKey::FPGA,
          DispatchKey::ORT,
          DispatchKey::Vulkan,
-         DispatchKey::AXDIMM, // Adding this will generate default kernels required for tensor operations
+         DispatchKey::PNM, // Adding this will generate default kernels required
+                           // for tensor operations
          DispatchKey::Metal,
          DispatchKey::SparseCsrCPU,
          DispatchKey::SparseCsrCUDA,
diff --git a/c10/core/TensorImpl.h b/c10/core/TensorImpl.h
index 6d5a9370..1225d777 100644
--- a/c10/core/TensorImpl.h
+++ b/c10/core/TensorImpl.h
@@ -1177,9 +1177,9 @@ struct C10_API TensorImpl : public c10::intrusive_ptr_target {
     return device_opt_.has_value() && device_opt_->type() == kVulkan;
   }
 
-  bool is_axdimm() const {
-    static constexpr auto axdimm_ks = DispatchKeySet(DispatchKey::AXDIMM);
-    return key_set_.has_all(axdimm_ks);
+  bool is_pnm() const {
+    static constexpr auto pnm_ks = DispatchKeySet(DispatchKey::PNM);
+    return key_set_.has_all(pnm_ks);
   }
 
   bool is_metal() const {
diff --git a/c10/core/TensorOptions.h b/c10/core/TensorOptions.h
index 6518378e..98f4be6c 100644
--- a/c10/core/TensorOptions.h
+++ b/c10/core/TensorOptions.h
@@ -657,8 +657,8 @@ inline DispatchKey computeDispatchKey(
               "This is a grandfathered Caffe2 device type ",
               device_.type(),
               ", it shouldn't ever convert to a DispatchKey.  File a bug describing what you were doing if you think this is in error.");
-        case DeviceType::AXDIMM:
-          return DispatchKey::AXDIMM;
+        case DeviceType::PNM:
+          return DispatchKey::PNM;
         default:
           TORCH_CHECK_NOT_IMPLEMENTED(
               false,
@@ -674,8 +674,8 @@ inline DispatchKey computeDispatchKey(
   }
         C10_FORALL_BACKEND_DEVICE_TYPES(DO_CASE, unused)
 #undef DO_CASE
-        case DeviceType::AXDIMM:
-          return DispatchKey::AXDIMM;
+        case DeviceType::PNM:
+          return DispatchKey::PNM;
         default:
           TORCH_CHECK_NOT_IMPLEMENTED(
               false,
@@ -752,8 +752,8 @@ inline DeviceType dispatchKeyToDeviceType(DispatchKey dispatch_key) {
     case DispatchKey::ORT:
       return DeviceType::ORT;
 
-    case DispatchKey::AXDIMM:
-      return DeviceType::AXDIMM;
+    case DispatchKey::PNM:
+      return DeviceType::PNM;
     default:
       TORCH_CHECK(
           false,
diff --git a/caffe2/CMakeLists.txt b/caffe2/CMakeLists.txt
index 52db61aa..40c37153 100644
--- a/caffe2/CMakeLists.txt
+++ b/caffe2/CMakeLists.txt
@@ -78,7 +78,7 @@ if(INTERN_BUILD_ATEN_OPS)
   add_dependencies(aten_op_header_gen __aten_op_header_gen)
 
   # Add source, includes, and libs to lists
-  list(APPEND Caffe2_AXDIMM_SRCS ${ATen_AXDIMM_SRCS})
+  list(APPEND Caffe2_PNM_SRCS ${ATen_PNM_SRCS})
   list(APPEND Caffe2_CPU_SRCS ${ATen_CPU_SRCS})
   list(APPEND Caffe2_GPU_SRCS ${ATen_CUDA_CPP_SRCS})
   list(APPEND Caffe2_GPU_SRCS_W_SORT_BY_KEY ${ATen_CUDA_SRCS_W_SORT_BY_KEY})
@@ -93,12 +93,12 @@ if(INTERN_BUILD_ATEN_OPS)
   list(APPEND Caffe2_HIP_TEST_SRCS ${ATen_HIP_TEST_SRCS})
   list(APPEND Caffe2_CPU_TEST_SRCS ${ATen_CORE_TEST_SRCS})
   list(APPEND Caffe2_VULKAN_TEST_SRCS ${ATen_VULKAN_TEST_SRCS})
-  list(APPEND Caffe2_AXDIMM_INCLUDE ${ATen_AXDIMM_INCLUDE})
+  list(APPEND Caffe2_PNM_INCLUDE ${ATen_PNM_INCLUDE})
   list(APPEND Caffe2_CPU_INCLUDE ${ATen_CPU_INCLUDE})
   list(APPEND Caffe2_GPU_INCLUDE ${ATen_CUDA_INCLUDE})
   list(APPEND Caffe2_HIP_INCLUDE ${ATen_HIP_INCLUDE})
   list(APPEND Caffe2_VULKAN_INCLUDE ${ATen_VULKAN_INCLUDE})
-  list(APPEND Caffe2_AXDIMM_DEPENDENCY_LIBS ${ATen_AXDIMM_DEPENDENCY_LIBS})
+  list(APPEND Caffe2_PNM_DEPENDENCY_LIBS ${ATen_PNM_DEPENDENCY_LIBS})
   list(APPEND Caffe2_DEPENDENCY_LIBS ${ATen_CPU_DEPENDENCY_LIBS})
   list(APPEND Caffe2_CUDA_DEPENDENCY_LIBS ${ATen_CUDA_DEPENDENCY_LIBS})
   list(APPEND Caffe2_HIP_DEPENDENCY_LIBS ${ATen_HIP_DEPENDENCY_LIBS})
@@ -171,7 +171,7 @@ endif()
 # Advanced: if we have allow list specified, we will do intersections for all
 # main lib srcs.
 if(CAFFE2_ALLOWLISTED_FILES)
-  caffe2_do_allowlist(Caffe2_AXDIMM_SRCS CAFFE2_ALLOWLISTED_FILES)
+  caffe2_do_allowlist(Caffe2_PNM_SRCS CAFFE2_ALLOWLISTED_FILES)
   caffe2_do_allowlist(Caffe2_CPU_SRCS CAFFE2_ALLOWLISTED_FILES)
   caffe2_do_allowlist(Caffe2_GPU_SRCS CAFFE2_ALLOWLISTED_FILES)
   caffe2_do_allowlist(Caffe2_GPU_SRCS_W_SORT_BY_KEY CAFFE2_ALLOWLISTED_FILES)
@@ -181,8 +181,8 @@ if(CAFFE2_ALLOWLISTED_FILES)
 endif()
 
 if(PRINT_CMAKE_DEBUG_INFO)
-  message(STATUS "AXDIMM sources: ")
-  foreach(tmp ${Caffe2_AXDIMM_SRCS})
+  message(STATUS "PNM sources: ")
+  foreach(tmp ${Caffe2_PNM_SRCS})
     message(STATUS "  " ${tmp})
   endforeach()
 
@@ -982,8 +982,8 @@ elseif(USE_CUDA)
         "$<$<COMPILE_LANGUAGE:CXX>:ATen/core/ATen_pch.h>")
   endif()
 elseif(USE_PNM)
-  add_library(torch_axdimm ${Caffe2_AXDIMM_SRCS})
-  set_property(TARGET torch_axdimm PROPERTY CXX_STANDARD 17)
+  add_library(torch_pnm ${Caffe2_PNM_SRCS})
+  set_property(TARGET torch_pnm PROPERTY CXX_STANDARD 17)
   set_property(TARGET torch_cpu PROPERTY CXX_STANDARD 17)
 endif()
 
@@ -1002,7 +1002,7 @@ if(NOT INTERN_BUILD_MOBILE)
   # See https://samthursfield.wordpress.com/2015/11/21/cmake-dependencies-between-targets-and-files-and-custom-commands/#custom-commands-in-different-directories
   add_dependencies(torch_cpu Caffe2_PROTO)
   if(USE_PNM)
-    add_dependencies(torch_axdimm Caffe2_PROTO)
+    add_dependencies(torch_pnm Caffe2_PROTO)
   endif()
 endif()
 
@@ -1258,7 +1258,7 @@ elseif(USE_CUDA)
     include_torch_lib_dir(torch_cuda)
   endif()
 elseif(USE_PNM)
-  include_torch_lib_dir(torch_axdimm)
+  include_torch_lib_dir(torch_pnm)
 endif()
 if(BUILD_PYTHON)
     include_torch_lib_dir(torch_python)
@@ -1286,7 +1286,7 @@ if(USE_DISTRIBUTED)
         target_compile_definitions(torch_cuda PUBLIC USE_NCCL_WITH_UCC)
       endif()
     else()
-      target_compile_definitions(torch_axdimm PUBLIC USE_C10D_NCCL)
+      target_compile_definitions(torch_pnm PUBLIC USE_C10D_NCCL)
     endif()
   endif()
   if(USE_MPI AND USE_C10D_MPI)
@@ -1314,17 +1314,17 @@ if(NOT INTERN_BUILD_MOBILE)
   caffe2_interface_library(caffe2_protos caffe2_protos_whole)
   target_link_libraries(torch_cpu PRIVATE caffe2_protos_whole)
   if(USE_PNM)
-    target_link_libraries(torch_axdimm PRIVATE caffe2_protos_whole)
+    target_link_libraries(torch_pnm PRIVATE caffe2_protos_whole)
   endif()
   if(${CAFFE2_LINK_LOCAL_PROTOBUF})
     target_link_libraries(torch_cpu INTERFACE protobuf::libprotobuf)
     if(USE_PNM)
-      target_link_libraries(torch_axdimm INTERFACE protobuf::libprotobuf)
+      target_link_libraries(torch_pnm INTERFACE protobuf::libprotobuf)
     endif()
   else()
     target_link_libraries(torch_cpu PUBLIC protobuf::libprotobuf)
     if(USE_PNM)
-      target_link_libraries(torch_axdimm PUBLIC protobuf::libprotobuf)
+      target_link_libraries(torch_pnm PUBLIC protobuf::libprotobuf)
     endif()
   endif()
 endif()
@@ -1367,7 +1367,7 @@ target_include_directories(torch_cpu PRIVATE ${Caffe2_CPU_INCLUDE})
 target_include_directories(torch_cpu SYSTEM PRIVATE "${Caffe2_DEPENDENCY_INCLUDE}")
 
 if (USE_PNM)
-  target_link_libraries(torch_axdimm PRIVATE ${Caffe2_AXDIMM_DEPENDENCY_LIBS})
+  target_link_libraries(torch_pnm PRIVATE ${Caffe2_PNM_DEPENDENCY_LIBS})
 endif ()
 
 target_compile_options(torch_cpu PRIVATE "-DCAFFE2_BUILD_MAIN_LIB")
@@ -1475,7 +1475,7 @@ if(USE_CUDA)
 elseif(USE_ROCM)
   caffe2_interface_library(torch_hip torch_hip_library)
 elseif(USE_PNM)
-  caffe2_interface_library(torch_axdimm torch_axdimm_library)
+  caffe2_interface_library(torch_pnm torch_pnm_library)
 endif()
 
 caffe2_interface_library(torch torch_library)
@@ -1487,7 +1487,7 @@ if(USE_CUDA)
 elseif(USE_ROCM)
   install(TARGETS torch_hip torch_hip_library EXPORT Caffe2Targets DESTINATION "${TORCH_INSTALL_LIB_DIR}")
 elseif(USE_PNM)
-  install(TARGETS torch_axdimm torch_axdimm_library EXPORT Caffe2Targets DESTINATION "${TORCH_INSTALL_LIB_DIR}")
+  install(TARGETS torch_pnm torch_pnm_library EXPORT Caffe2Targets DESTINATION "${TORCH_INSTALL_LIB_DIR}")
 endif()
 install(TARGETS torch torch_library EXPORT Caffe2Targets DESTINATION "${TORCH_INSTALL_LIB_DIR}")
 
@@ -1498,7 +1498,7 @@ if(USE_CUDA)
 elseif(USE_ROCM)
   target_link_libraries(torch PUBLIC torch_hip_library)
 elseif(USE_PNM)
-  target_link_libraries(torch PUBLIC torch_axdimm_library)
+  target_link_libraries(torch PUBLIC torch_pnm_library)
 endif()
 
 if(PRINT_CMAKE_DEBUG_INFO)
@@ -1982,38 +1982,38 @@ if(BUILD_PYTHON)
   endif()
 
   if(USE_PNM)
-    add_library(caffe2_pybind11_state_axdimm MODULE ${Caffe2_AXDIMM_PYTHON_SRCS})
-    set_property(TARGET caffe2_pybind11_state_axdimm PROPERTY CXX_STANDARD 17)
+    add_library(caffe2_pybind11_state_pnm MODULE ${Caffe2_PNM_PYTHON_SRCS})
+    set_property(TARGET caffe2_pybind11_state_pnm PROPERTY CXX_STANDARD 17)
 
     if(USE_NUMPY)
-      target_compile_options(caffe2_pybind11_state_axdimm PRIVATE "-DUSE_NUMPY")
-      target_link_libraries(caffe2_pybind11_state_axdimm PRIVATE numpy::numpy)
+      target_compile_options(caffe2_pybind11_state_pnm PRIVATE "-DUSE_NUMPY")
+      target_link_libraries(caffe2_pybind11_state_pnm PRIVATE numpy::numpy)
     endif()
     if(NOT MSVC)
-      target_compile_options(caffe2_pybind11_state_axdimm PRIVATE "-fvisibility=hidden")
+      target_compile_options(caffe2_pybind11_state_pnm PRIVATE "-fvisibility=hidden")
     endif()
-    set_target_properties(caffe2_pybind11_state_axdimm PROPERTIES PREFIX "")
-    set_target_properties(caffe2_pybind11_state_axdimm PROPERTIES SUFFIX ${PY_EXT_SUFFIX})
-    set_target_properties(caffe2_pybind11_state_axdimm PROPERTIES LINK_FLAGS "${_caffe2_pybind11_state_linker_flags}")
-    target_include_directories(caffe2_pybind11_state_axdimm PRIVATE $<INSTALL_INTERFACE:include>)
-    target_include_directories(caffe2_pybind11_state_axdimm PRIVATE ${Caffe2_CPU_INCLUDE} ${Caffe2_AXDIMM_INCLUDE})
-    target_link_libraries(caffe2_pybind11_state_axdimm PRIVATE torch_library python::python pybind::pybind11)
-    target_link_libraries(caffe2_pybind11_state_axdimm PRIVATE PNM::AxdimmAI)
+    set_target_properties(caffe2_pybind11_state_pnm PROPERTIES PREFIX "")
+    set_target_properties(caffe2_pybind11_state_pnm PROPERTIES SUFFIX ${PY_EXT_SUFFIX})
+    set_target_properties(caffe2_pybind11_state_pnm PROPERTIES LINK_FLAGS "${_caffe2_pybind11_state_linker_flags}")
+    target_include_directories(caffe2_pybind11_state_pnm PRIVATE $<INSTALL_INTERFACE:include>)
+    target_include_directories(caffe2_pybind11_state_pnm PRIVATE ${Caffe2_CPU_INCLUDE} ${Caffe2_PNM_INCLUDE})
+    target_link_libraries(caffe2_pybind11_state_pnm PRIVATE torch_library python::python pybind::pybind11)
+    target_link_libraries(caffe2_pybind11_state_pnm PRIVATE PNM::AxdimmAI)
 
     if(USE_MKLDNN)
-        target_link_libraries(caffe2_pybind11_state_axdimm PRIVATE caffe2::mkldnn)
+        target_link_libraries(caffe2_pybind11_state_pnm PRIVATE caffe2::mkldnn)
     endif()
 
     if(WIN32)
-      target_link_libraries(caffe2_pybind11_state_axdimm ${PYTHON_LIBRARIES})
+      target_link_libraries(caffe2_pybind11_state_pnm ${PYTHON_LIBRARIES})
     endif(WIN32)
 
-    # Install with same rpath as non-axdimm caffe2_pybind11_state
+    # Install with same rpath as non-pnm caffe2_pybind11_state
     set_target_properties(
-        caffe2_pybind11_state_axdimm PROPERTIES LIBRARY_OUTPUT_DIRECTORY
+        caffe2_pybind11_state_pnm PROPERTIES LIBRARY_OUTPUT_DIRECTORY
         ${CMAKE_BINARY_DIR}/caffe2/python)
-    install(TARGETS caffe2_pybind11_state_axdimm DESTINATION "${PYTHON_LIB_REL_PATH}/caffe2/python")
-    set_target_properties(caffe2_pybind11_state_axdimm PROPERTIES INSTALL_RPATH "${caffe2_pybind11_rpath}")
+    install(TARGETS caffe2_pybind11_state_pnm DESTINATION "${PYTHON_LIB_REL_PATH}/caffe2/python")
+    set_target_properties(caffe2_pybind11_state_pnm PROPERTIES INSTALL_RPATH "${caffe2_pybind11_rpath}")
   endif()
 
   if(MSVC AND CMAKE_GENERATOR MATCHES "Visual Studio")
diff --git a/caffe2/core/context_axdimm.h b/caffe2/core/context_pnm.h
similarity index 71%
rename from caffe2/core/context_axdimm.h
rename to caffe2/core/context_pnm.h
index a7838fbb..b82b4731 100644
--- a/caffe2/core/context_axdimm.h
+++ b/caffe2/core/context_pnm.h
@@ -1,5 +1,5 @@
-#ifndef CAFFE2_CORE_CONTEXT_AXDIMM_H_
-#define CAFFE2_CORE_CONTEXT_AXDIMM_H_
+#ifndef CAFFE2_CORE_CONTEXT_PNM_H_
+#define CAFFE2_CORE_CONTEXT_PNM_H_
 
 #include "caffe2/core/common.h"
 #include "caffe2/core/context.h"
@@ -16,16 +16,15 @@
 
 namespace caffe2 {
 
-class C10_EXPORT AXDIMMContext final : public BaseContext {
+class C10_EXPORT PNMContext final : public BaseContext {
  public:
-  // The default axdimm context constructor.
-  explicit AXDIMMContext(DeviceIndex device_id = -1) : device_id_(device_id){};
-  explicit AXDIMMContext(const DeviceOption& option)
+  // The default pnm context constructor.
+  explicit PNMContext(DeviceIndex device_id = -1) : device_id_(device_id){};
+  explicit PNMContext(const DeviceOption& option)
       : device_id_(option.has_device_id() ? option.device_id() : 0){};
-  explicit AXDIMMContext(Device device)
-      : AXDIMMContext(DeviceToOption(device)) {}
+  explicit PNMContext(Device device) : PNMContext(DeviceToOption(device)) {}
 
-  ~AXDIMMContext() override {
+  ~PNMContext() override {
     FinishDeviceComputation();
   }
 
@@ -36,12 +35,12 @@ class C10_EXPORT AXDIMMContext final : public BaseContext {
   using BaseContext::SwitchToDevice;
 
   inline void WaitEvent(const Event& ev) override {
-    ev.Wait(AXDIMM, this);
+    ev.Wait(PNM, this);
   }
 
   inline void Record(Event* ev, const char* err_msg = nullptr) const override {
     CAFFE_ENFORCE(ev, "Event must not be null.");
-    ev->Record(AXDIMM, this, err_msg);
+    ev->Record(PNM, this, err_msg);
   }
 
   // Note on current use cases:
@@ -59,15 +58,15 @@ class C10_EXPORT AXDIMMContext final : public BaseContext {
   }
 
   void CopyBytesSameDevice(size_t nbytes, const void* src, void* dst) override {
-    CopyBytes<AXDIMMContext, AXDIMMContext>(nbytes, src, dst);
+    CopyBytes<PNMContext, PNMContext>(nbytes, src, dst);
   }
 
   void CopyBytesToCPU(size_t nbytes, const void* src, void* dst) override {
-    CopyBytes<AXDIMMContext, CPUContext>(nbytes, src, dst);
+    CopyBytes<PNMContext, CPUContext>(nbytes, src, dst);
   }
 
   void CopyBytesFromCPU(size_t nbytes, const void* src, void* dst) override {
-    CopyBytes<CPUContext, AXDIMMContext>(nbytes, src, dst);
+    CopyBytes<CPUContext, PNMContext>(nbytes, src, dst);
   }
 
   template <typename T, class SrcContext, class DstContext>
@@ -79,11 +78,11 @@ class C10_EXPORT AXDIMMContext final : public BaseContext {
   template <class SrcContext, class DstContext>
   inline void
   CopyItems(const TypeMeta meta, size_t n, const void* src, void* dst) {
-    CAFFE_ENFORCE(!meta.copy(), "AXDIMMContext requires fundamental types.");
+    CAFFE_ENFORCE(!meta.copy(), "PNMContext requires fundamental types.");
     CopyBytes<SrcContext, DstContext>(n * meta.itemsize(), src, dst);
   }
 
-  // By default AXDIMM operators don't support async scheduling.
+  // By default PNM operators don't support async scheduling.
   // TODO: figure out and implement.
   static bool HasAsyncPartDefault() {
     return false;
@@ -102,15 +101,15 @@ class C10_EXPORT AXDIMMContext final : public BaseContext {
   }
 
   at::Device device() const override {
-    return at::Device(AXDIMM, device_id_);
+    return at::Device(PNM, device_id_);
   }
 
   DeviceType device_type() const override {
-    return AXDIMM;
+    return PNM;
   }
 
   static constexpr DeviceType GetDeviceType() {
-    return AXDIMM;
+    return PNM;
   }
 
  protected:
@@ -119,4 +118,4 @@ class C10_EXPORT AXDIMMContext final : public BaseContext {
 
 } // namespace caffe2
 
-#endif // CAFFE2_CORE_CONTEXT_AXDIMM_H_
+#endif // CAFFE2_CORE_CONTEXT_PNM_H_
diff --git a/caffe2/core/event_axdimm.cc b/caffe2/core/event_pnm.cc
similarity index 57%
rename from caffe2/core/event_axdimm.cc
rename to caffe2/core/event_pnm.cc
index 8724f811..f426730a 100644
--- a/caffe2/core/event_axdimm.cc
+++ b/caffe2/core/event_pnm.cc
@@ -1,4 +1,4 @@
-#include "caffe2/core/context_axdimm.h"
+#include "caffe2/core/context_pnm.h"
 #include "caffe2/core/event_cpu.h"
 #include "caffe2/core/operator.h"
 
@@ -7,13 +7,13 @@
 
 namespace caffe2 {
 
-struct AxdimmEventWrapper {
-  explicit AxdimmEventWrapper(const DeviceOption& option)
+struct PnmEventWrapper {
+  explicit PnmEventWrapper(const DeviceOption& option)
       : status_(EventStatus::EVENT_INITIALIZED) {
     CAFFE_ENFORCE(
-        option.device_type(), PROTO_AXDIMM, "Expected AXDIMM device type");
+        option.device_type(), PROTO_PNM, "Expected PNM device type");
   }
-  ~AxdimmEventWrapper() {}
+  ~PnmEventWrapper() {}
 
   std::mutex mutex_;
   std::condition_variable cv_completed_;
@@ -26,15 +26,15 @@ namespace {
 const std::string kNoError = "No error";
 }
 
-void EventCreateAXDIMM(const DeviceOption& option, Event* event) {
-  event->event_ = std::make_shared<AxdimmEventWrapper>(option);
+void EventCreatePNM(const DeviceOption& option, Event* event) {
+  event->event_ = std::make_shared<PnmEventWrapper>(option);
 }
 
-void EventRecordAXDIMM(
+void EventRecordPNM(
     Event* event,
     const void* /* unused */,
     const char* err_msg) {
-  auto* wrapper = static_cast<AxdimmEventWrapper*>(event->event_.get());
+  auto* wrapper = static_cast<PnmEventWrapper*>(event->event_.get());
   std::unique_lock<std::mutex> lock(wrapper->mutex_);
 
   // Possible state changes:
@@ -59,8 +59,8 @@ void EventRecordAXDIMM(
   }
 }
 
-void EventFinishAXDIMM(const Event* event) {
-  auto* wrapper = static_cast<AxdimmEventWrapper*>(event->event_.get());
+void EventFinishPNM(const Event* event) {
+  auto* wrapper = static_cast<PnmEventWrapper*>(event->event_.get());
   std::unique_lock<std::mutex> lock(wrapper->mutex_);
   while (wrapper->status_ != EventStatus::EVENT_SUCCESS &&
          wrapper->status_ != EventStatus::EVENT_FAILED) {
@@ -68,28 +68,28 @@ void EventFinishAXDIMM(const Event* event) {
   }
 }
 
-// Both waiter and event are AXDIMM.
-void EventWaitAXDIMMAXDIMM(const Event* event, void* /* context */) {
-  EventFinishAXDIMM(event);
+// Both waiter and event are PNM.
+void EventWaitPNMPNM(const Event* event, void* /* context */) {
+  EventFinishPNM(event);
 }
 
-// Waiter is CPU, event is AXDIMM.
-void EventWaitCPUAXDIMM(const Event* event, void* context) {
-  EventFinishAXDIMM(event);
+// Waiter is CPU, event is PNM.
+void EventWaitCPUPNM(const Event* event, void* context) {
+  EventFinishPNM(event);
 }
 
-// Waiter is AXDIMM, event is CPU
-void EventWaitAXDIMMCPU(const Event* event, void* context) {
+// Waiter is PNM, event is CPU
+void EventWaitPNMCPU(const Event* event, void* context) {
   event->Finish(); // calls EventFinishCPU
 }
 
-EventStatus EventQueryAXDIMM(const Event* event) {
-  auto* wrapper = static_cast<AxdimmEventWrapper*>(event->event_.get());
+EventStatus EventQueryPNM(const Event* event) {
+  auto* wrapper = static_cast<PnmEventWrapper*>(event->event_.get());
   return static_cast<EventStatus>(wrapper->status_.load());
 }
 
-const std::string& EventErrorMessageAXDIMM(const Event* event) {
-  auto* wrapper = static_cast<AxdimmEventWrapper*>(event->event_.get());
+const std::string& EventErrorMessagePNM(const Event* event) {
+  auto* wrapper = static_cast<PnmEventWrapper*>(event->event_.get());
   if (wrapper->status_ == EventStatus::EVENT_FAILED) {
     // Failed is a terminal state, not synchronizing,
     // err_msg_ should not be changed anymore
@@ -99,8 +99,8 @@ const std::string& EventErrorMessageAXDIMM(const Event* event) {
   }
 }
 
-void EventSetFinishedAXDIMM(const Event* event, const char* err_msg) {
-  auto* wrapper = static_cast<AxdimmEventWrapper*>(event->event_.get());
+void EventSetFinishedPNM(const Event* event, const char* err_msg) {
+  auto* wrapper = static_cast<PnmEventWrapper*>(event->event_.get());
   std::unique_lock<std::mutex> lock(wrapper->mutex_);
 
   if (wrapper->status_ == EventStatus::EVENT_FAILED) {
@@ -130,8 +130,8 @@ void EventSetFinishedAXDIMM(const Event* event, const char* err_msg) {
   wrapper->cv_completed_.notify_all();
 }
 
-void EventSetCallbackAXDIMM(Event* event, EventCallbackFunction callback) {
-  auto* wrapper = static_cast<AxdimmEventWrapper*>(event->event_.get());
+void EventSetCallbackPNM(Event* event, EventCallbackFunction callback) {
+  auto* wrapper = static_cast<PnmEventWrapper*>(event->event_.get());
   std::unique_lock<std::mutex> lock(wrapper->mutex_);
 
   wrapper->callbacks_.push_back(callback);
@@ -141,26 +141,26 @@ void EventSetCallbackAXDIMM(Event* event, EventCallbackFunction callback) {
   }
 }
 
-void EventResetAXDIMM(Event* event) {
-  auto* wrapper = static_cast<AxdimmEventWrapper*>(event->event_.get());
+void EventResetPNM(Event* event) {
+  auto* wrapper = static_cast<PnmEventWrapper*>(event->event_.get());
   std::unique_lock<std::mutex> lock(wrapper->mutex_);
   wrapper->status_ = EventStatus::EVENT_INITIALIZED;
   wrapper->err_msg_ = "";
   wrapper->callbacks_.clear();
 }
 
-REGISTER_EVENT_CREATE_FUNCTION(AXDIMM, EventCreateAXDIMM);
-REGISTER_EVENT_RECORD_FUNCTION(AXDIMM, EventRecordAXDIMM);
-REGISTER_EVENT_WAIT_FUNCTION(AXDIMM, AXDIMM, EventWaitAXDIMMAXDIMM);
-REGISTER_EVENT_WAIT_FUNCTION(AXDIMM, CPU, EventWaitAXDIMMCPU);
-REGISTER_EVENT_WAIT_FUNCTION(CPU, AXDIMM, EventWaitCPUAXDIMM);
-REGISTER_EVENT_FINISH_FUNCTION(AXDIMM, EventFinishAXDIMM);
+REGISTER_EVENT_CREATE_FUNCTION(PNM, EventCreatePNM);
+REGISTER_EVENT_RECORD_FUNCTION(PNM, EventRecordPNM);
+REGISTER_EVENT_WAIT_FUNCTION(PNM, PNM, EventWaitPNMPNM);
+REGISTER_EVENT_WAIT_FUNCTION(PNM, CPU, EventWaitPNMCPU);
+REGISTER_EVENT_WAIT_FUNCTION(CPU, PNM, EventWaitCPUPNM);
+REGISTER_EVENT_FINISH_FUNCTION(PNM, EventFinishPNM);
 
-REGISTER_EVENT_QUERY_FUNCTION(AXDIMM, EventQueryAXDIMM);
-REGISTER_EVENT_ERROR_MESSAGE_FUNCTION(AXDIMM, EventErrorMessageAXDIMM);
-REGISTER_EVENT_SET_FINISHED_FUNCTION(AXDIMM, EventSetFinishedAXDIMM);
-REGISTER_EVENT_RESET_FUNCTION(AXDIMM, EventResetAXDIMM);
+REGISTER_EVENT_QUERY_FUNCTION(PNM, EventQueryPNM);
+REGISTER_EVENT_ERROR_MESSAGE_FUNCTION(PNM, EventErrorMessagePNM);
+REGISTER_EVENT_SET_FINISHED_FUNCTION(PNM, EventSetFinishedPNM);
+REGISTER_EVENT_RESET_FUNCTION(PNM, EventResetPNM);
 
-REGISTER_EVENT_SET_CALLBACK_FUNCTION(AXDIMM, EventSetCallbackAXDIMM);
+REGISTER_EVENT_SET_CALLBACK_FUNCTION(PNM, EventSetCallbackPNM);
 
 } // namespace caffe2
diff --git a/caffe2/core/operator.cc b/caffe2/core/operator.cc
index 57736ad8..2a0a0924 100644
--- a/caffe2/core/operator.cc
+++ b/caffe2/core/operator.cc
@@ -409,11 +409,11 @@ C10_DEFINE_REGISTRY(
 CAFFE_REGISTER_DEVICE_TYPE(HIP, HIPOperatorRegistry);
 
 C10_DEFINE_REGISTRY(
-    AXDIMMOperatorRegistry,
+    PNMOperatorRegistry,
     OperatorBase,
     const OperatorDef&,
     Workspace*);
-CAFFE_REGISTER_DEVICE_TYPE(AXDIMM, AXDIMMOperatorRegistry);
+CAFFE_REGISTER_DEVICE_TYPE(PNM, PNMOperatorRegistry);
 
 C10_DEFINE_REGISTRY(
     GradientRegistry,
diff --git a/caffe2/core/operator.h b/caffe2/core/operator.h
index dc4f403a..6eba3f79 100644
--- a/caffe2/core/operator.h
+++ b/caffe2/core/operator.h
@@ -1425,24 +1425,24 @@ C10_DECLARE_REGISTRY(
       name, CUDNN, __VA_ARGS__) // Make CUDNN an alias of MIOPEN for HIP ops
 
 C10_DECLARE_REGISTRY(
-    AXDIMMOperatorRegistry,
+    PNMOperatorRegistry,
     OperatorBase,
     const OperatorDef&,
     Workspace*);
-#define REGISTER_AXDIMM_OPERATOR_CREATOR(key, ...) \
-  C10_REGISTER_CREATOR(AXDIMMOperatorRegistry, key, __VA_ARGS__)
-#define REGISTER_AXDIMM_OPERATOR(name, ...)                               \
+#define REGISTER_PNM_OPERATOR_CREATOR(key, ...) \
+  C10_REGISTER_CREATOR(PNMOperatorRegistry, key, __VA_ARGS__)
+#define REGISTER_PNM_OPERATOR(name, ...)                               \
   IMPORT_IF_NOT_MSVC void CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_##name(); \
-  static void CAFFE2_UNUSED CAFFE_ANONYMOUS_VARIABLE_AXDIMM##name() {     \
+  static void CAFFE2_UNUSED CAFFE_ANONYMOUS_VARIABLE_PNM##name() {     \
     CAFFE2_PLEASE_ADD_OPERATOR_SCHEMA_FOR_##name();                       \
   }                                                                       \
-  C10_REGISTER_CLASS(AXDIMMOperatorRegistry, name, __VA_ARGS__)
-#define REGISTER_AXDIMM_OPERATOR_STR(str_name, ...) \
-  C10_REGISTER_TYPED_CLASS(AXDIMMOperatorRegistry, str_name, __VA_ARGS__)
+  C10_REGISTER_CLASS(PNMOperatorRegistry, name, __VA_ARGS__)
+#define REGISTER_PNM_OPERATOR_STR(str_name, ...) \
+  C10_REGISTER_TYPED_CLASS(PNMOperatorRegistry, str_name, __VA_ARGS__)
 
-#define REGISTER_AXDIMM_OPERATOR_WITH_ENGINE(name, engine, ...) \
+#define REGISTER_PNM_OPERATOR_WITH_ENGINE(name, engine, ...) \
   C10_REGISTER_CLASS(                                           \
-      AXDIMMOperatorRegistry, name##_ENGINE_##engine, __VA_ARGS__)
+      PNMOperatorRegistry, name##_ENGINE_##engine, __VA_ARGS__)
 
 // StaticLinkingProtector is a helper class that ensures that the Caffe2
 // library is linked correctly with whole archives (in the case of static
diff --git a/caffe2/operators/CMakeLists.txt b/caffe2/operators/CMakeLists.txt
index ac13ad46..65d8aaf6 100644
--- a/caffe2/operators/CMakeLists.txt
+++ b/caffe2/operators/CMakeLists.txt
@@ -46,15 +46,15 @@ file(GLOB tmp_cudnn *_cudnn.cc)
 exclude(tmp "${tmp}" ${tmp_cudnn})
 set(Caffe2_CPU_SRCS ${Caffe2_CPU_SRCS} ${tmp})
 
-# ---[ AXDIMM files.
-file(GLOB axdimm_tmp *_axdimm.cc)
-set(Caffe2_AXDIMM_SRCS ${Caffe2_AXDIMM_SRCS} ${axdimm_tmp})
+# ---[ PNM files.
+file(GLOB pnm_tmp *_pnm.cc)
+set(Caffe2_PNM_SRCS ${Caffe2_PNM_SRCS} ${pnm_tmp})
 
 set(Caffe2_CPU_SRCS ${Caffe2_CPU_SRCS} ${tmp})
-# exclude test files, axdimm files and gpu files
+# exclude test files, pnm files and gpu files
 file(GLOB tmp *_test.cc)
 exclude(Caffe2_CPU_SRCS "${Caffe2_CPU_SRCS}" ${tmp})
-exclude(Caffe2_CPU_SRCS "${Caffe2_CPU_SRCS}" ${axdimm_tmp})
+exclude(Caffe2_CPU_SRCS "${Caffe2_CPU_SRCS}" ${pnm_tmp})
 exclude(Caffe2_CPU_SRCS "${Caffe2_CPU_SRCS}" ${Caffe2_GPU_SRCS} ${Caffe2_HIP_SRCS})
 
 # ---[ GPU test files
@@ -85,7 +85,7 @@ set(Caffe2_CPU_SRCS ${Caffe2_CPU_SRCS} PARENT_SCOPE)
 set(Caffe2_GPU_SRCS ${Caffe2_GPU_SRCS} PARENT_SCOPE)
 set(Caffe2_GPU_SRCS_W_SORT_BY_KEY ${Caffe2_GPU_SRCS_W_SORT_BY_KEY} PARENT_SCOPE)
 set(Caffe2_HIP_SRCS ${Caffe2_HIP_SRCS} PARENT_SCOPE)
-set(Caffe2_AXDIMM_SRCS ${Caffe2_AXDIMM_SRCS} PARENT_SCOPE)
+set(Caffe2_PNM_SRCS ${Caffe2_PNM_SRCS} PARENT_SCOPE)
 set(Caffe2_CPU_TEST_SRCS ${Caffe2_CPU_TEST_SRCS} PARENT_SCOPE)
 set(Caffe2_GPU_TEST_SRCS ${Caffe2_GPU_TEST_SRCS} PARENT_SCOPE)
 set(Caffe2_HIP_TEST_SRCS ${Caffe2_HIP_TEST_SRCS} PARENT_SCOPE)
diff --git a/caffe2/operators/lengths_reducer_ops.h b/caffe2/operators/lengths_reducer_ops.h
index 28739d4a..536b15cc 100644
--- a/caffe2/operators/lengths_reducer_ops.h
+++ b/caffe2/operators/lengths_reducer_ops.h
@@ -2,7 +2,7 @@
 
 #include <c10/util/irange.h>
 #include "caffe2/core/context.h"
-#include "caffe2/core/context_axdimm.h"
+#include "caffe2/core/context_pnm.h"
 #include "caffe2/core/operator.h"
 #include "caffe2/perfkernels/embedding_lookup.h"
 #ifdef USE_FBGEMM
diff --git a/caffe2/operators/lengths_reducer_ops_axdimm.cc b/caffe2/operators/lengths_reducer_ops_pnm.cc
similarity index 93%
rename from caffe2/operators/lengths_reducer_ops_axdimm.cc
rename to caffe2/operators/lengths_reducer_ops_pnm.cc
index 07b79a44..6abb7852 100644
--- a/caffe2/operators/lengths_reducer_ops_axdimm.cc
+++ b/caffe2/operators/lengths_reducer_ops_pnm.cc
@@ -22,7 +22,7 @@
 namespace caffe2 {
 
 // A templated class that implements SparseLengths[Sum,WeightedSum,Mean] for
-// AXDIMM.
+// PNM.
 template <
     typename T, // output type
     class InputTypes, // supported input types, such as TensorTypes<float>
@@ -32,17 +32,17 @@ template <
     // USE_WEIGHT = true and USE_POSITIONAL_WEIGHT = true
     // -> SparseLengthsPositionalWeightedSum
     >
-class AXDIMMSparseLengthsReductionOp : public Operator<AXDIMMContext> {
+class PNMSparseLengthsReductionOp : public Operator<PNMContext> {
  public:
-  USE_OPERATOR_FUNCTIONS(AXDIMMContext);
+  USE_OPERATOR_FUNCTIONS(PNMContext);
   template <class... Args>
-  explicit AXDIMMSparseLengthsReductionOp(Args&&... args)
-      : Operator<AXDIMMContext>(std::forward<Args>(args)...) {
+  explicit PNMSparseLengthsReductionOp(Args&&... args)
+      : Operator<PNMContext>(std::forward<Args>(args)...) {
     static_assert(
         !(USE_WEIGHT & USE_MEAN), "Cannot both specify weight and mean.");
   }
 
-  ~AXDIMMSparseLengthsReductionOp() {}
+  ~PNMSparseLengthsReductionOp() {}
 
   // Currently, we support float and at::Half inputs for input data type, and
   // int32_t and int64_t for the index type.
@@ -101,7 +101,7 @@ class AXDIMMSparseLengthsReductionOp : public Operator<AXDIMMContext> {
     (void)N;
     (void)D;
     // FIXME: support generic execution w/o SLS ops blocking.
-    CAFFE_THROW("AXDIMM SLS is supported only with blocking.");
+    CAFFE_THROW("PNM SLS is supported only with blocking.");
     return true;
   }
 
@@ -116,7 +116,7 @@ class AXDIMMSparseLengthsReductionOp : public Operator<AXDIMMContext> {
 };
 
 // A templated class that implements SparseLengths[Sum,WeightedSum,Mean] for
-// AXDIMM.
+// PNM.
 template <
     typename T, // output type
     class InputTypes, // supported input types, such as TensorTypes<float>
@@ -126,12 +126,12 @@ template <
     // USE_WEIGHT = true and USE_POSITIONAL_WEIGHT = true
     // -> SparseLengthsPositionalWeightedSum
     >
-class AXDIMMSparseLengthsReductionOpVec : public Operator<AXDIMMContext> {
+class PNMSparseLengthsReductionOpVec : public Operator<PNMContext> {
  public:
-  USE_OPERATOR_FUNCTIONS(AXDIMMContext);
+  USE_OPERATOR_FUNCTIONS(PNMContext);
   template <class... Args>
-  explicit AXDIMMSparseLengthsReductionOpVec(Args&&... args)
-      : Operator<AXDIMMContext>(std::forward<Args>(args)...) {
+  explicit PNMSparseLengthsReductionOpVec(Args&&... args)
+      : Operator<PNMContext>(std::forward<Args>(args)...) {
     static_assert(
         !(USE_WEIGHT & USE_MEAN), "Cannot both specify weight and mean.");
     // Setup input pointers for tables/indices/lengths. The input comes in
@@ -162,7 +162,7 @@ class AXDIMMSparseLengthsReductionOpVec : public Operator<AXDIMMContext> {
     }
   }
 
-  ~AXDIMMSparseLengthsReductionOpVec() {
+  ~PNMSparseLengthsReductionOpVec() {
     free(indices_blocked_);
     free(lengths_blocked_);
     indices_blocked_ = nullptr;
@@ -390,7 +390,7 @@ class AXDIMMSparseLengthsReductionOpVec : public Operator<AXDIMMContext> {
   uint64_t lengths_total_size_in_bytes_ =
       0; // Size of currently allocated blocked lengths buffer
   SlsDevice device_ =
-      SlsDevice::make(); // SLS device. TODO: move into AXDIMMContext
+      SlsDevice::make(); // SLS device. TODO: move into PNMContext
 
   pnm::ContextHandler pnm_ctx_ = pnm::make_context(pnm::ContextType::AXDIMM);
   pnm::Runner runner_{pnm_ctx_};
@@ -402,7 +402,7 @@ class AXDIMMSparseLengthsReductionOpVec : public Operator<AXDIMMContext> {
 
 using SparseLengthsSumOp =
     // NOLINTNEXTLINE(modernize-use-bool-literals)
-    AXDIMMSparseLengthsReductionOp<
+    PNMSparseLengthsReductionOp<
         float,
         TensorTypes<float, at::Half>,
         0,
@@ -410,13 +410,13 @@ using SparseLengthsSumOp =
         0>;
 using SparseLengthsSumOpVec =
     // NOLINTNEXTLINE(modernize-use-bool-literals)
-    AXDIMMSparseLengthsReductionOpVec<
+    PNMSparseLengthsReductionOpVec<
         float,
         TensorTypes<float, at::Half>,
         0,
         0,
         0>;
 
-REGISTER_AXDIMM_OPERATOR(SparseLengthsSum, SparseLengthsSumOp);
-REGISTER_AXDIMM_OPERATOR(SparseLengthsSumVec, SparseLengthsSumOpVec);
+REGISTER_PNM_OPERATOR(SparseLengthsSum, SparseLengthsSumOp);
+REGISTER_PNM_OPERATOR(SparseLengthsSumVec, SparseLengthsSumOpVec);
 } // namespace caffe2
diff --git a/caffe2/operators/lengths_reducer_ops_sec_axdimm.cc b/caffe2/operators/lengths_reducer_ops_sec_pnm.cc
similarity index 88%
rename from caffe2/operators/lengths_reducer_ops_sec_axdimm.cc
rename to caffe2/operators/lengths_reducer_ops_sec_pnm.cc
index fe5eff07..73bc0d7e 100644
--- a/caffe2/operators/lengths_reducer_ops_sec_axdimm.cc
+++ b/caffe2/operators/lengths_reducer_ops_sec_pnm.cc
@@ -2,13 +2,13 @@
 
 #include "caffe2/operators/no_default_engine_op.h"
 
-#include "lengths_reducer_ops_sec_axdimm.h"
+#include "lengths_reducer_ops_sec_pnm.h"
 
 namespace caffe2 {
 //-------------------FLOAT OPERATOR---------------------------------
-REGISTER_AXDIMM_OPERATOR(
+REGISTER_PNM_OPERATOR(
     SecureSparseLengthsSumVec,
-    AXDIMMSecureSparseLengthsReductionOpVec<
+    PNMSecureSparseLengthsReductionOpVec<
         float,
         TensorTypes<float, at::Half>,
         ::sls::secure::RunnerType::FLOAT>);
@@ -17,9 +17,9 @@ REGISTER_AXDIMM_OPERATOR(
 REGISTER_CPU_OPERATOR(SecureSparseLengthsSumVec, NoDefaultEngineOp<CPUContext>);
 
 //-------------------UINT32_T OPERATOR---------------------------------
-REGISTER_AXDIMM_OPERATOR(
+REGISTER_PNM_OPERATOR(
     SecureSparseLengthsSumIntVec,
-    AXDIMMSecureSparseLengthsReductionOpVec<
+    PNMSecureSparseLengthsReductionOpVec<
         int32_t,
         TensorTypes<int32_t>,
         ::sls::secure::RunnerType::INT>);
@@ -34,7 +34,7 @@ REGISTER_CPU_OPERATOR(
   OPERATOR_SCHEMA(operator_name)                                                 \
       .NumInputs(2, INT_MAX)                                                     \
       .NumOutputs(1)                                                             \
-      .SetDoc(R"(Operator for Secure AXDIMM)")                                   \
+      .SetDoc(R"(Operator for Secure PNM)")                                   \
       .Arg("from_file", "bool: read embedded tables from file")                  \
       .Arg("path", "string: path of embedded tables")                            \
       .Arg("num_tables", "uint: number of embedded tables")                      \
diff --git a/caffe2/operators/lengths_reducer_ops_sec_axdimm.h b/caffe2/operators/lengths_reducer_ops_sec_pnm.h
similarity index 83%
rename from caffe2/operators/lengths_reducer_ops_sec_axdimm.h
rename to caffe2/operators/lengths_reducer_ops_sec_pnm.h
index 768d7f85..4325c0b5 100644
--- a/caffe2/operators/lengths_reducer_ops_sec_axdimm.h
+++ b/caffe2/operators/lengths_reducer_ops_sec_pnm.h
@@ -1,5 +1,5 @@
-#ifndef AXDIMM_PYTORCH_LENGTHS_REDUCER_OPS_SEC_AXDIMM_H
-#define AXDIMM_PYTORCH_LENGTHS_REDUCER_OPS_SEC_AXDIMM_H
+#ifndef PNM_PYTORCH_LENGTHS_REDUCER_OPS_SEC_PNM_H
+#define PNM_PYTORCH_LENGTHS_REDUCER_OPS_SEC_PNM_H
 
 #include "caffe2/core/context.h"
 #include "caffe2/core/logging.h"
@@ -7,16 +7,16 @@
 #include "caffe2/operators/lengths_reducer_ops.h"
 #include "caffe2/operators/segment_reduction_op.h"
 
-#include <pnmlib/secure/sls_runner_factory.h>
 #include <pnmlib/secure/base_device.h>
 #include <pnmlib/secure/base_runner.h>
+#include <pnmlib/secure/sls_runner_factory.h>
 #include <pnmlib/secure/untrusted_sls_params.h>
 
 #include <pnmlib/ai/sls.h>
 
 #include <pnmlib/common/128bit_math.h>
 
-#include <ATen/native/axdimm/AxdimmTypeHelpers.h>
+#include <ATen/native/pnm/PNMTypeHelpers.h>
 
 #include <fcntl.h>
 #include <sys/mman.h>
@@ -24,22 +24,22 @@
 namespace caffe2 {
 
 // A templated class that implements SparseLengths[Sum,WeightedSum,Mean] for
-// AXDIMM.
+// PNM.
 template <
     typename T, // output type
     typename InputTypes, // supported input types, such as TensorTypes<float>
     sls::secure::RunnerType runner_type>
-class AXDIMMSecureSparseLengthsReductionOpVec : public Operator<AXDIMMContext> {
+class PNMSecureSparseLengthsReductionOpVec : public Operator<PNMContext> {
  public:
-  USE_OPERATOR_FUNCTIONS(AXDIMMContext);
+  USE_OPERATOR_FUNCTIONS(PNMContext);
   template <class... Args>
-  explicit AXDIMMSecureSparseLengthsReductionOpVec(Args&&... args)
-      : Operator<AXDIMMContext>(std::forward<Args>(args)...) {
-    if constexpr (::at::native::axdimm::SecureTypeTraits<T>::APPLY_SCALE) {
+  explicit PNMSecureSparseLengthsReductionOpVec(Args&&... args)
+      : Operator<PNMContext>(std::forward<Args>(args)...) {
+    if constexpr (::at::native::pnm::SecureTypeTraits<T>::APPLY_SCALE) {
       LOG(WARNING) << "Secure operator works only with integer types. "
                       "The floating values will be converted to integer "
                       "by expression I = static_cast<I>(F * "
-                   << ::at::native::axdimm::SecureTypeTraits<T>::SCALE_FACTOR
+                   << ::at::native::pnm::SecureTypeTraits<T>::SCALE_FACTOR
                    << " )";
     }
     with_tag_ = this->template GetSingleArgument<bool>("with_tag", false);
@@ -142,14 +142,14 @@ class AXDIMMSecureSparseLengthsReductionOpVec : public Operator<AXDIMMContext> {
 
     auto output_int_v = pnm::view_cast<secure_core_value_type>(output_view);
 
-    if constexpr (::at::native::axdimm::SecureTypeTraits<T>::APPLY_SCALE) {
+    if constexpr (::at::native::pnm::SecureTypeTraits<T>::APPLY_SCALE) {
       std::transform(
           output_int_v.begin(),
           output_int_v.end(),
           output_view.begin(),
           [this](const auto v) {
             return static_cast<T>(v) /
-                ::at::native::axdimm::SecureTypeTraits<T>::SCALE_FACTOR;
+                ::at::native::pnm::SecureTypeTraits<T>::SCALE_FACTOR;
           }); // Restore floating point values
     }
 
@@ -158,7 +158,7 @@ class AXDIMMSecureSparseLengthsReductionOpVec : public Operator<AXDIMMContext> {
 
  private:
   using secure_core_value_type =
-      typename ::at::native::axdimm::SecureTypeTraits<T>::secure_engine_value_t;
+      typename ::at::native::pnm::SecureTypeTraits<T>::secure_engine_value_t;
 
   template <typename...>
   static constexpr std::false_type always_false{};
@@ -172,19 +172,17 @@ class AXDIMMSecureSparseLengthsReductionOpVec : public Operator<AXDIMMContext> {
       tables_size_bytes +=
           (tables_size_ / sparse_feature_size_) * sizeof(pnm::uint128_t);
     }
-    LOG(INFO) << "Operator AXDIMMSecureSparseLengthsReductionOpVec: "
+    LOG(INFO) << "Operator PNMSecureSparseLengthsReductionOpVec: "
               << " Tables size in bytes: " << tables_size_bytes;
 
     const auto memory_preference = this->template GetSingleArgument<int>(
         "mem_preference", AXDIMM_ALLOC_AUTO);
 
-    sls::secure::DeviceArguments args(
-        sls::secure::UntrustedDeviceParams{
-            .rows = rows,
-            .sparse_feature_size = sparse_feature_size,
-            .with_tag = with_tag_,
-            .preference =
-                static_cast<axd_user_preferences>(memory_preference)});
+    sls::secure::DeviceArguments args(sls::secure::UntrustedDeviceParams{
+        .rows = rows,
+        .sparse_feature_size = sparse_feature_size,
+        .with_tag = with_tag_,
+        .preference = static_cast<axd_user_preferences>(memory_preference)});
     runner_->init(&args);
 
     runner_->load_tables(data.begin(), rows, sparse_feature_size, with_tag_);
@@ -215,11 +213,8 @@ class AXDIMMSecureSparseLengthsReductionOpVec : public Operator<AXDIMMContext> {
       sls::secure::make_runner(runner_type);
 };
 
-template <
-    typename T,
-    typename InputTypes,
-    sls::secure::RunnerType runner_type>
-void AXDIMMSecureSparseLengthsReductionOpVec<T, InputTypes, runner_type>::
+template <typename T, typename InputTypes, sls::secure::RunnerType runner_type>
+void PNMSecureSparseLengthsReductionOpVec<T, InputTypes, runner_type>::
     init_from_file() {
   block_size_ = this->template GetSingleArgument<int>("num_tables", 0);
   CAFFE_ENFORCE_NE(
@@ -251,13 +246,13 @@ void AXDIMMSecureSparseLengthsReductionOpVec<T, InputTypes, runner_type>::
   auto data_v = pnm::make_view(
       static_cast<const T*>(data), static_cast<const T*>(data) + tables_size_);
 
-  if constexpr (::at::native::axdimm::SecureTypeTraits<T>::APPLY_SCALE) {
+  if constexpr (::at::native::pnm::SecureTypeTraits<T>::APPLY_SCALE) {
     std::vector<secure_core_value_type> qdata(tables_size_);
     std::transform(
         data_v.begin(), data_v.end(), qdata.begin(), [](const auto v) {
           return static_cast<secure_core_value_type>(
               v *
-              ::at::native::axdimm::SecureTypeTraits<
+              ::at::native::pnm::SecureTypeTraits<
                   T>::SCALE_FACTOR); // Transform floating
                                      // point values to integer
         });
@@ -275,11 +270,8 @@ void AXDIMMSecureSparseLengthsReductionOpVec<T, InputTypes, runner_type>::
   close(fd);
 }
 
-template <
-    typename T,
-    typename InputTypes,
-    sls::secure::RunnerType runner_type>
-void AXDIMMSecureSparseLengthsReductionOpVec<T, InputTypes, runner_type>::
+template <typename T, typename InputTypes, sls::secure::RunnerType runner_type>
+void PNMSecureSparseLengthsReductionOpVec<T, InputTypes, runner_type>::
     init_from_input() {
   // Setup input pointers for tables/indices/lengths. The input comes in
   // following format:
@@ -300,9 +292,9 @@ void AXDIMMSecureSparseLengthsReductionOpVec<T, InputTypes, runner_type>::
         Input(i).template data<T>() + rows_[i] * sparse_feature_size_,
         std::back_inserter(qdata),
         [](const auto v) {
-          if constexpr (::at::native::axdimm::SecureTypeTraits<T>::APPLY_SCALE)
+          if constexpr (::at::native::pnm::SecureTypeTraits<T>::APPLY_SCALE)
             return static_cast<secure_core_value_type>(
-                v * ::at::native::axdimm::SecureTypeTraits<T>::SCALE_FACTOR);
+                v * ::at::native::pnm::SecureTypeTraits<T>::SCALE_FACTOR);
           else
             return v;
         });
@@ -318,4 +310,4 @@ void AXDIMMSecureSparseLengthsReductionOpVec<T, InputTypes, runner_type>::
 }
 } // namespace caffe2
 
-#endif // AXDIMM_PYTORCH_LENGTHS_REDUCER_OPS_SEC_AXDIMM_H
+#endif // PNM_PYTORCH_LENGTHS_REDUCER_OPS_SEC_PNM_H
diff --git a/caffe2/operators/operator_fallback_axdimm.h b/caffe2/operators/operator_fallback_pnm.h
similarity index 70%
rename from caffe2/operators/operator_fallback_axdimm.h
rename to caffe2/operators/operator_fallback_pnm.h
index c0d86c8a..a355ca78 100644
--- a/caffe2/operators/operator_fallback_axdimm.h
+++ b/caffe2/operators/operator_fallback_pnm.h
@@ -1,19 +1,19 @@
-#ifndef CAFFE2_OPERATORS_OPERATOR_AXDIMM_FALLBACK_H_
-#define CAFFE2_OPERATORS_OPERATOR_AXDIMM_FALLBACK_H_
+#ifndef CAFFE2_OPERATORS_OPERATOR_PNM_FALLBACK_H_
+#define CAFFE2_OPERATORS_OPERATOR_PNM_FALLBACK_H_
 
 #include "caffe2/core/common.h"
 #include "caffe2/core/context.h"
-#include "caffe2/core/context_axdimm.h"
+#include "caffe2/core/context_pnm.h"
 #include "caffe2/core/operator.h"
 #include "caffe2/proto/caffe2_pb.h"
 
 namespace caffe2 {
 
 /**
- * @brief A templated class to allow one to wrap a CPU operator as a AXDIMM
+ * @brief A templated class to allow one to wrap a CPU operator as a PNM
  * operator.
  *
- * This class can be used when one does not have the AXDIMM implementation ready
+ * This class can be used when one does not have the PNM implementation ready
  * yet for an operator. Essentially, what this op does is to automatically
  * deal with data copy for you. Plausibly, this causes a lot of overhead and
  * is not optimal, so you should use this operator mostly for quick prototyping
@@ -23,11 +23,11 @@ namespace caffe2 {
  *
  * Example usage: if you have a class MyMagicOp that is CPU based, and you use
  * the registration code
- *     REGISTER_AXDIMM_OPERATOR(MyMagic, MyMagicOp);
- * to register the CPU side, you can create its corresponding AXDIMM operator
+ *     REGISTER_PNM_OPERATOR(MyMagic, MyMagicOp);
+ * to register the CPU side, you can create its corresponding PNM operator
  * (with performance hits of course) via
- *     REGISTER_AXDIMM_OPERATOR(MyMagic,
- *                              AXDIMMFallbackOp);
+ *     REGISTER_PNM_OPERATOR(MyMagic,
+ *                              PNMFallbackOp);
  * Note that you will need to make sure that the operators actually share the
  * same name.
  *
@@ -35,16 +35,16 @@ namespace caffe2 {
  * can use the SkipOutputCopy template argument to do that. For example, if
  * MyMagic produces two outputs and the first output is always going to live on
  * the CPU, you can do
- *     REGISTER_AXDIMM_OPERATOR(MyMagic,
- *                              AXDIMMFallbackOpEx<SkipIndices<0>>);
+ *     REGISTER_PNM_OPERATOR(MyMagic,
+ *                              PNMFallbackOpEx<SkipIndices<0>>);
  */
 template <typename SkipOutputCopy>
-class AXDIMMFallbackOpEx final : public Operator<AXDIMMContext> {
+class PNMFallbackOpEx final : public Operator<PNMContext> {
  public:
-  USE_OPERATOR_FUNCTIONS(AXDIMMContext);
-  explicit AXDIMMFallbackOpEx(const OperatorDef& def, Workspace* ws)
-      : Operator<AXDIMMContext>(def, ws) {
-    CAFFE_ENFORCE_EQ(def.device_option().device_type(), PROTO_AXDIMM);
+  USE_OPERATOR_FUNCTIONS(PNMContext);
+  explicit PNMFallbackOpEx(const OperatorDef& def, Workspace* ws)
+      : Operator<PNMContext>(def, ws) {
+    CAFFE_ENFORCE_EQ(def.device_option().device_type(), PROTO_PNM);
     OperatorDef base_def_(def);
     // base_def_ runs on CPU, so we will set its device option to CPU.
     base_def_.clear_device_option();
@@ -63,11 +63,11 @@ class AXDIMMFallbackOpEx final : public Operator<AXDIMMContext> {
 
   bool RunOnDevice() override {
     for (int i = 0; i < InputSize(); ++i) {
-      if (this->InputIsTensorType(i, AXDIMM)) {
+      if (this->InputIsTensorType(i, PNM)) {
         // use sync copy
         BlobGetMutableTensor(local_input_blobs_[i], CPU)->CopyFrom(Input(i));
       } else {
-        VLOG(1) << "Input " << i << " is not TensorAXDIMM. Skipping copy.";
+        VLOG(1) << "Input " << i << " is not TensorPNM. Skipping copy.";
         // Note(jiayq): This removes a const but conceptually
         // local_input_blobs will only be used as const blob input for the
         // base op so we are still fine.
@@ -78,7 +78,7 @@ class AXDIMMFallbackOpEx final : public Operator<AXDIMMContext> {
     }
 
     if (!base_op_->Run()) {
-      LOG(ERROR) << "Base op run failed in AXDIMMFallbackOp. Def: "
+      LOG(ERROR) << "Base op run failed in PNMFallbackOp. Def: "
                  << ProtoDebugString(this->debug_def());
       return false;
     }
@@ -89,7 +89,7 @@ class AXDIMMFallbackOpEx final : public Operator<AXDIMMContext> {
       }
       CAFFE_ENFORCE(
           BlobIsTensorType(*local_output_blobs_[i], CPU),
-          "AXDIMM fallback op currently does not support non-TensorCPU "
+          "PNM fallback op currently does not support non-TensorCPU "
           "output type who needs copying.");
       Output(i)->CopyFrom(local_output_blobs_[i]->template Get<TensorCPU>());
     }
@@ -103,8 +103,8 @@ class AXDIMMFallbackOpEx final : public Operator<AXDIMMContext> {
   unique_ptr<OperatorBase> base_op_;
 };
 
-using AXDIMMFallbackOp = AXDIMMFallbackOpEx<SkipIndices<>>;
+using PNMFallbackOp = PNMFallbackOpEx<SkipIndices<>>;
 
 } // namespace caffe2
 
-#endif // CAFFE2_OPERATORS_OPERATOR_AXDIMM_FALLBACK_H_
+#endif // CAFFE2_OPERATORS_OPERATOR_PNM_FALLBACK_H_
diff --git a/caffe2/proto/caffe2.proto b/caffe2/proto/caffe2.proto
index c1d56457..beb92b06 100644
--- a/caffe2/proto/caffe2.proto
+++ b/caffe2/proto/caffe2.proto
@@ -221,7 +221,7 @@ enum DeviceTypeProto {
   PROTO_ORT = 8; // ONNX Runtime
   PROTO_XLA = 9; // XLA / TPU
   PROTO_MPS = 10; // MPS
-  PROTO_AXDIMM = 11; // AXDIMM
+  PROTO_PNM = 11; // PNM
   // Change the following number if you add more devices in the code.
   PROTO_COMPILE_TIME_MAX_DEVICE_TYPES = 12;
 }
diff --git a/caffe2/proto/caffe2_pb.h b/caffe2/proto/caffe2_pb.h
index 74afd726..6f084eb3 100644
--- a/caffe2/proto/caffe2_pb.h
+++ b/caffe2/proto/caffe2_pb.h
@@ -13,7 +13,7 @@ constexpr DeviceType OPENCL = DeviceType::OPENCL;
 constexpr DeviceType MKLDNN = DeviceType::MKLDNN;
 constexpr DeviceType IDEEP = DeviceType::IDEEP;
 constexpr DeviceType HIP = DeviceType::HIP;
-constexpr DeviceType AXDIMM = DeviceType::AXDIMM;
+constexpr DeviceType PNM = DeviceType::PNM;
 constexpr DeviceType COMPILE_TIME_MAX_DEVICE_TYPES =
     DeviceType::COMPILE_TIME_MAX_DEVICE_TYPES;
 
@@ -33,8 +33,8 @@ inline TORCH_API DeviceType ProtoToType(const caffe2::DeviceTypeProto p) {
       return DeviceType::IDEEP;
     case caffe2::PROTO_HIP:
       return DeviceType::HIP;
-    case caffe2::PROTO_AXDIMM:
-      return DeviceType::AXDIMM;
+    case caffe2::PROTO_PNM:
+      return DeviceType::PNM;
     case caffe2::PROTO_COMPILE_TIME_MAX_DEVICE_TYPES:
       return DeviceType::COMPILE_TIME_MAX_DEVICE_TYPES;
     default:
@@ -67,8 +67,8 @@ inline TORCH_API DeviceTypeProto TypeToProto(const DeviceType& t) {
       return caffe2::PROTO_IDEEP;
     case DeviceType::HIP:
       return caffe2::PROTO_HIP;
-    case DeviceType::AXDIMM:
-      return caffe2::PROTO_AXDIMM;
+    case DeviceType::PNM:
+      return caffe2::PROTO_PNM;
     case DeviceType::COMPILE_TIME_MAX_DEVICE_TYPES:
       return caffe2::PROTO_COMPILE_TIME_MAX_DEVICE_TYPES;
     default:
@@ -100,7 +100,7 @@ inline TORCH_API caffe2::DeviceOption DeviceToOption(const at::Device& device) {
     case DeviceType::OPENCL:
     case DeviceType::MKLDNN:
     case DeviceType::IDEEP:
-    case DeviceType::AXDIMM:
+    case DeviceType::PNM:
     case DeviceType::COMPILE_TIME_MAX_DEVICE_TYPES:
       break;
     default:
@@ -125,7 +125,7 @@ inline TORCH_API at::Device OptionToDevice(const caffe2::DeviceOption& option) {
       break;
     case caffe2::PROTO_CUDA:
     case caffe2::PROTO_HIP:
-    case caffe2::PROTO_AXDIMM:
+    case caffe2::PROTO_PNM:
       id = static_cast<c10::DeviceIndex>(option.device_id());
       break;
   }
diff --git a/caffe2/python/CMakeLists.txt b/caffe2/python/CMakeLists.txt
index 8c393cee..9a929b1e 100644
--- a/caffe2/python/CMakeLists.txt
+++ b/caffe2/python/CMakeLists.txt
@@ -27,18 +27,18 @@ set(Caffe2_HIP_PYTHON_SRCS
     "/pybind_state_hip.cc"
 )
 
-# ---[ AXDIMM files
-set(Caffe2_AXDIMM_PYTHON_SRCS
+# ---[ PNM files
+set(Caffe2_PNM_PYTHON_SRCS
     ${Caffe2_CPU_PYTHON_SRCS}
-    "/pybind_state_axdimm.cc"
+    "/pybind_state_pnm.cc"
 )
 
 prepend(Caffe2_CPU_PYTHON_SRCS ${CMAKE_CURRENT_SOURCE_DIR} ${Caffe2_CPU_PYTHON_SRCS})
-prepend(Caffe2_AXDIMM_PYTHON_SRCS ${CMAKE_CURRENT_SOURCE_DIR} ${Caffe2_AXDIMM_PYTHON_SRCS})
+prepend(Caffe2_PNM_PYTHON_SRCS ${CMAKE_CURRENT_SOURCE_DIR} ${Caffe2_PNM_PYTHON_SRCS})
 prepend(Caffe2_GPU_PYTHON_SRCS ${CMAKE_CURRENT_SOURCE_DIR} ${Caffe2_GPU_PYTHON_SRCS})
 prepend(Caffe2_HIP_PYTHON_SRCS ${CMAKE_CURRENT_SOURCE_DIR} ${Caffe2_HIP_PYTHON_SRCS})
 
 set(Caffe2_CPU_PYTHON_SRCS ${Caffe2_CPU_PYTHON_SRCS} PARENT_SCOPE)
-set(Caffe2_AXDIMM_PYTHON_SRCS ${Caffe2_AXDIMM_PYTHON_SRCS} PARENT_SCOPE)
+set(Caffe2_PNM_PYTHON_SRCS ${Caffe2_PNM_PYTHON_SRCS} PARENT_SCOPE)
 set(Caffe2_GPU_PYTHON_SRCS ${Caffe2_GPU_PYTHON_SRCS} PARENT_SCOPE)
 set(Caffe2_HIP_PYTHON_SRCS ${Caffe2_HIP_PYTHON_SRCS} PARENT_SCOPE)
diff --git a/caffe2/python/__init__.py b/caffe2/python/__init__.py
index ec7fdf20..aa143fe9 100644
--- a/caffe2/python/__init__.py
+++ b/caffe2/python/__init__.py
@@ -18,7 +18,7 @@ caffe2_pb2.OPENGL = caffe2_pb2.PROTO_OPENGL
 caffe2_pb2.OPENCL = caffe2_pb2.PROTO_OPENCL
 caffe2_pb2.IDEEP = caffe2_pb2.PROTO_IDEEP
 caffe2_pb2.HIP = caffe2_pb2.PROTO_HIP
-caffe2_pb2.AXDIMM = caffe2_pb2.PROTO_AXDIMM
+caffe2_pb2.PNM = caffe2_pb2.PROTO_PNM
 caffe2_pb2.COMPILE_TIME_MAX_DEVICE_TYPES = caffe2_pb2.PROTO_COMPILE_TIME_MAX_DEVICE_TYPES
 
 if sys.platform == "win32":
diff --git a/caffe2/python/_import_c_extension.py b/caffe2/python/_import_c_extension.py
index 478b3afe..ccb57c0a 100644
--- a/caffe2/python/_import_c_extension.py
+++ b/caffe2/python/_import_c_extension.py
@@ -9,7 +9,7 @@ from caffe2.python import extension_loader
 # attempt to load the cpu version. The cpu backend is the minimum required, so
 # if that still fails, we will exit loud.
 with extension_loader.DlopenGuard():
-    has_axdimm_support = False
+    has_pnm_support = False
     has_hip_support = False
     has_cuda_support = False
     has_gpu_support = False
@@ -35,11 +35,11 @@ with extension_loader.DlopenGuard():
                 'and AMD hip module:{}.'
                 'Will run in CPU only mode.'.format(gpu_e, hip_e))
             try:
-                from caffe2.python.caffe2_pybind11_state_axdimm import *  # noqa
-                has_axdimm_support = True
-                logging.info('This caffe2 python run has AXDIMM support!')
-            except ImportError as axdimm_e:
-                logging.warning('Failed to import AXDIMM module: {}'.format(axdimm_e))
+                from caffe2.python.caffe2_pybind11_state_pnm import *  # noqa
+                has_pnm_support = True
+                logging.info('This caffe2 python run has PNM support!')
+            except ImportError as pnm_e:
+                logging.warning('Failed to import PNM module: {}'.format(pnm_e))
                 try:
                     from caffe2.python.caffe2_pybind11_state import *  # noqa
                 except ImportError as cpu_e:
diff --git a/caffe2/python/_import_c_extension.pyi b/caffe2/python/_import_c_extension.pyi
index 5d6efb0c..c2d71560 100644
--- a/caffe2/python/_import_c_extension.pyi
+++ b/caffe2/python/_import_c_extension.pyi
@@ -221,7 +221,7 @@ def num_hip_devices() -> int: ...
 def get_hip_version() -> int: ...
 def get_miopen_version() -> int: ...
 
-has_axdimm_support: bool
+has_pnm_support: bool
 has_hip_support: bool
 has_cuda_support: bool
 has_gpu_support: bool
diff --git a/caffe2/python/pybind_state_axdimm.cc b/caffe2/python/pybind_state_pnm.cc
similarity index 81%
rename from caffe2/python/pybind_state_axdimm.cc
rename to caffe2/python/pybind_state_pnm.cc
index 210822b1..3c722f99 100644
--- a/caffe2/python/pybind_state_axdimm.cc
+++ b/caffe2/python/pybind_state_pnm.cc
@@ -10,8 +10,8 @@
 #include <pybind11/pybind11.h>
 #include <pybind11/stl.h>
 
-#include "caffe2/core/context_axdimm.h"
-#include "caffe2/operators/operator_fallback_axdimm.h"
+#include "caffe2/core/context_pnm.h"
+#include "caffe2/operators/operator_fallback_pnm.h"
 #include "caffe2/python/pybind_state_registry.h"
 
 #include <pnmlib/ai/sls.h>
@@ -32,19 +32,19 @@ static pnm::memory::EmbeddedTablesHandler tables;
 namespace caffe2 {
 namespace python {
 
-REGISTER_AXDIMM_OPERATOR(Python, AXDIMMFallbackOp);
-REGISTER_AXDIMM_OPERATOR(PythonGradient, AXDIMMFallbackOp);
+REGISTER_PNM_OPERATOR(Python, PNMFallbackOp);
+REGISTER_PNM_OPERATOR(PythonGradient, PNMFallbackOp);
 
-REGISTER_AXDIMM_OPERATOR(PythonDLPack, AXDIMMFallbackOp);
-REGISTER_AXDIMM_OPERATOR(PythonDLPackGradient, AXDIMMFallbackOp);
+REGISTER_PNM_OPERATOR(PythonDLPack, PNMFallbackOp);
+REGISTER_PNM_OPERATOR(PythonDLPackGradient, PNMFallbackOp);
 
-REGISTER_BLOB_FEEDER(AXDIMM, TensorFeeder<AXDIMMContext>);
+REGISTER_BLOB_FEEDER(PNM, TensorFeeder<PNMContext>);
 
 namespace py = pybind11;
 
-void addAXDIMMGlobalMethods(py::module& m) {
+void addPNMGlobalMethods(py::module& m) {
   m.def(
-      "axdimm_starter",
+      "pnm_starter",
       [](const std::string& weight_file,
          const std::vector<uint32_t>& table_entry,
          uint32_t row_size_in_bytes,
@@ -90,18 +90,18 @@ void addAXDIMMGlobalMethods(py::module& m) {
         }
       });
 
-  m.def("axdimm_closer", []() {
+  m.def("pnm_closer", []() {
     tables.reset();
     pnm_ctx.reset();
     return 0;
   });
 }
 
-PYBIND11_MODULE(caffe2_pybind11_state_axdimm, m) {
-  m.doc() = "pybind11 stateful interface to Caffe2 workspaces - AXDIMM edition";
+PYBIND11_MODULE(caffe2_pybind11_state_pnm, m) {
+  m.doc() = "pybind11 stateful interface to Caffe2 workspaces - PNM edition";
 
   addGlobalMethods(m);
-  addAXDIMMGlobalMethods(m);
+  addPNMGlobalMethods(m);
   addObjectMethods(m);
   for (const auto& addition : PybindAdditionRegistry()->Keys()) {
     PybindAdditionRegistry()->Create(addition, m);
diff --git a/caffe2/python/workspace.py b/caffe2/python/workspace.py
index 4bd6ea35..99262eb5 100644
--- a/caffe2/python/workspace.py
+++ b/caffe2/python/workspace.py
@@ -49,7 +49,7 @@ has_fbgemm = C.has_fbgemm
 has_cuda_support = C.has_cuda_support
 has_hip_support = C.has_hip_support
 has_gpu_support = C.has_gpu_support
-has_axdimm_support = C.has_axdimm_support
+has_pnm_support = C.has_pnm_support
 if has_cuda_support:
     GpuDeviceType = caffe2_pb2.CUDA
     NumCudaDevices = C.num_cuda_devices
@@ -94,14 +94,14 @@ if not has_gpu_support:
     # pyre-fixme[9]: incompatible type assignment
     GetGPUMemoryInfo = lambda: None # noqa
 
-if has_axdimm_support:
-    AXDIMMDeviceType = caffe2_pb2.AXDIMM
-    AxdimmStarter = C.axdimm_starter
-    AxdimmCloser = C.axdimm_closer
+if has_pnm_support:
+    PNMDeviceType = caffe2_pb2.PNM
+    PnmStarter = C.pnm_starter
+    PnmCloser = C.pnm_closer
 
-if not has_axdimm_support:
-    AxdimmStarter = lambda: 0 # noqa
-    AxdimmCloser = lambda: 0 # noqa
+if not has_pnm_support:
+    PnmStarter = lambda: 0 # noqa
+    PnmCloser = lambda: 0 # noqa
 
 IsNUMAEnabled = C.is_numa_enabled
 GetNumNUMANodes = C.get_num_numa_nodes
diff --git a/caffe2/utils/proto_utils.cc b/caffe2/utils/proto_utils.cc
index b3a95eb9..f0d0ec2a 100644
--- a/caffe2/utils/proto_utils.cc
+++ b/caffe2/utils/proto_utils.cc
@@ -80,11 +80,11 @@ C10_EXPORT bool IsGPUDeviceType(int device_type) {
   return gpu_types.count(device_type);
 }
 
-C10_EXPORT bool IsAXDIMMDeviceType(int device_type) {
-  static const std::unordered_set<int> axdimm_types{
-      PROTO_AXDIMM,
+C10_EXPORT bool IsPNMDeviceType(int device_type) {
+  static const std::unordered_set<int> pnm_types{
+      PROTO_PNM,
   };
-  return axdimm_types.count(device_type);
+  return pnm_types.count(device_type);
 }
 
 C10_EXPORT bool ReadStringFromFile(const char* filename, string* str) {
diff --git a/caffe2/utils/proto_utils.h b/caffe2/utils/proto_utils.h
index 6f5c44ae..570768a7 100644
--- a/caffe2/utils/proto_utils.h
+++ b/caffe2/utils/proto_utils.h
@@ -42,7 +42,7 @@ TORCH_API bool IsSameDevice(const DeviceOption& lhs, const DeviceOption& rhs);
 
 TORCH_API bool IsCPUDeviceType(int device_type);
 TORCH_API bool IsGPUDeviceType(int device_type);
-TORCH_API bool IsAXDIMMDeviceType(int device_type);
+TORCH_API bool IsPNMDeviceType(int device_type);
 
 // Common interfaces that reads file contents into a string.
 TORCH_API bool ReadStringFromFile(const char* filename, string* str);
diff --git a/cmake/Codegen.cmake b/cmake/Codegen.cmake
index c7d6d40a..b12982a2 100644
--- a/cmake/Codegen.cmake
+++ b/cmake/Codegen.cmake
@@ -236,10 +236,10 @@ if(INTERN_BUILD_ATEN_OPS)
   add_custom_target(ATEN_CUDA_FILES_GEN_TARGET DEPENDS
       ${cuda_generated_headers} ${cuda_generated_sources})
   add_library(ATEN_CPU_FILES_GEN_LIB INTERFACE)
-  add_library(ATEN_AXDIMM_FILES_GEN_LIB INTERFACE)
+  add_library(ATEN_PNM_FILES_GEN_LIB INTERFACE)
   add_library(ATEN_CUDA_FILES_GEN_LIB INTERFACE)
   add_dependencies(ATEN_CPU_FILES_GEN_LIB ATEN_CPU_FILES_GEN_TARGET)
-  add_dependencies(ATEN_AXDIMM_FILES_GEN_LIB ATEN_CPU_FILES_GEN_TARGET)
+  add_dependencies(ATEN_PNM_FILES_GEN_LIB ATEN_CPU_FILES_GEN_TARGET)
   add_dependencies(ATEN_CUDA_FILES_GEN_LIB ATEN_CUDA_FILES_GEN_TARGET)
 
   if(USE_PER_OPERATOR_HEADERS)
diff --git a/cmake/Dependencies.cmake b/cmake/Dependencies.cmake
index 5bf12498..a1e8b5b8 100644
--- a/cmake/Dependencies.cmake
+++ b/cmake/Dependencies.cmake
@@ -1822,18 +1822,20 @@ set(BUILD_SHARED_LIBS OFF CACHE BOOL "Build shared libs" FORCE)
 add_subdirectory(${PROJECT_SOURCE_DIR}/third_party/fmt)
 
 # This defined after fmt processing to resolve fmt::fmt package
-# which is is required by axdimm libraries.
-# This package export is not used to link against fmt library by Axdimm libraries here
-# since Axdimm libraries are already built at this point and used solely
+# which is is required by pnm libraries.
+# This package export is not used to link against fmt library by Pnm libraries here
+# since Pnm libraries are already built at this point and used solely
 # to define one, to stop cmake complaining.
-# Axdimm cmake files are required only to export axdimm library packages
+# Pnm cmake files are required only to export pnm library packages
 if(USE_PNM)
   list(APPEND CMAKE_PREFIX_PATH ${PNM_INSTALL_DIR})
   find_package(PNMLib REQUIRED)
+
+  # [TODO:] Rename to PNM* after axdimm_driver rebranding.
   set(PNM_LIBS PNM::AxdimmSecure PNM::AxdimmAI)
 
   list(APPEND Caffe2_DEPENDENCY_LIBS ${PNM_LIBS})
-  list(APPEND Caffe2_AXDIMM_DEPENDENCY_LIBS ${PNM_LIBS})
+  list(APPEND Caffe2_PNM_DEPENDENCY_LIBS ${PNM_LIBS})
 endif()
 
 # Disable compiler feature checks for `fmt`.
diff --git a/setup.py b/setup.py
index 922e188c..c0aaa976 100644
--- a/setup.py
+++ b/setup.py
@@ -612,7 +612,7 @@ class build_ext(setuptools.command.build_ext.build_ext):
         # We only make this copy for Caffe2's pybind extensions
         caffe2_pybind_exts = [
             'caffe2.python.caffe2_pybind11_state',
-            'caffe2.python.caffe2_pybind11_state_axdimm',
+            'caffe2.python.caffe2_pybind11_state_pnm',
             'caffe2.python.caffe2_pybind11_state_gpu',
             'caffe2.python.caffe2_pybind11_state_hip',
         ]
@@ -976,7 +976,7 @@ def configure_extension_build():
         if cmake_cache_vars['USE_PNM']:
             extensions.append(
                 Extension(
-                    name=str('caffe2.python.caffe2_pybind11_state_axdimm'),
+                    name=str('caffe2.python.caffe2_pybind11_state_pnm'),
                     sources=[]),
             )
         if cmake_cache_vars['USE_ROCM']:
diff --git a/torch/csrc/autograd/python_variable.cpp b/torch/csrc/autograd/python_variable.cpp
index d29a2eeb..6550b55e 100644
--- a/torch/csrc/autograd/python_variable.cpp
+++ b/torch/csrc/autograd/python_variable.cpp
@@ -1265,14 +1265,14 @@ PyObject* THPVariable_is_vulkan(THPVariable* self, void* unused) {
   END_HANDLE_TH_ERRORS
 }
 
-PyObject* THPVariable_is_axdimm(THPVariable* self, void* unused)
+PyObject* THPVariable_is_pnm(THPVariable* self, void* unused)
 {
   HANDLE_TH_ERRORS
   if (check_has_torch_function((PyObject *)self)) {
-    return handle_torch_function_getter(self, "is_axdimm");
+    return handle_torch_function_getter(self, "is_pnm");
   }
   auto& self_ = THPVariable_Unpack(self);
-  return torch::autograd::utils::wrap(self_.is_axdimm());
+  return torch::autograd::utils::wrap(self_.is_pnm());
   END_HANDLE_TH_ERRORS
 }
 
@@ -1458,7 +1458,7 @@ static struct PyGetSetDef THPVariable_properties[] = {
     {"is_mps", (getter)THPVariable_is_mps, nullptr, nullptr, nullptr},
     {"is_ort", (getter)THPVariable_is_ort, nullptr, nullptr, nullptr},
     {"is_vulkan", (getter)THPVariable_is_vulkan, nullptr, nullptr, nullptr},
-    {"is_axdimm", (getter)THPVariable_is_axdimm, nullptr, nullptr, nullptr},
+    {"is_pnm", (getter)THPVariable_is_pnm, nullptr, nullptr, nullptr},
     {"is_complex", (getter)THPVariable_is_complex, nullptr, nullptr, nullptr},
     {"is_quantized",
      (getter)THPVariable_is_quantized,
diff --git a/torch/csrc/jit/frontend/sugared_value.cpp b/torch/csrc/jit/frontend/sugared_value.cpp
index c566453e..d2a03230 100644
--- a/torch/csrc/jit/frontend/sugared_value.cpp
+++ b/torch/csrc/jit/frontend/sugared_value.cpp
@@ -121,7 +121,7 @@ std::shared_ptr<SugaredValue> SimpleValue::attr(
            {"is_mps", "prim"},
            {"is_quantized", "prim"},
            {"is_vulkan", "prim"},
-           {"is_axdimm", "prim"},
+           {"is_pnm", "prim"},
            {"is_ipu", "prim"},
            {"is_meta", "prim"},
            {"is_leaf", "aten"},
diff --git a/torch/csrc/jit/runtime/register_prim_ops.cpp b/torch/csrc/jit/runtime/register_prim_ops.cpp
index 54224589..75a14e53 100644
--- a/torch/csrc/jit/runtime/register_prim_ops.cpp
+++ b/torch/csrc/jit/runtime/register_prim_ops.cpp
@@ -2372,11 +2372,11 @@ static const std::vector<OperatorGeneratorArgs> opGenArgs1{
         },
         aliasAnalysisFromSchema()),
     OperatorGeneratorArgs(
-        TORCH_SELECTIVE_SCHEMA("prim::is_axdimm(Tensor a) -> bool"),
+        TORCH_SELECTIVE_SCHEMA("prim::is_pnm(Tensor a) -> bool"),
         [](Stack& stack) {
           at::Tensor a;
           pop(stack, a);
-          push(stack, a.is_axdimm());
+          push(stack, a.is_pnm());
         },
         aliasAnalysisFromSchema()),
     OperatorGeneratorArgs(
diff --git a/torch/csrc/utils/tensor_types.cpp b/torch/csrc/utils/tensor_types.cpp
index e36b250a..c2f0531d 100644
--- a/torch/csrc/utils/tensor_types.cpp
+++ b/torch/csrc/utils/tensor_types.cpp
@@ -49,8 +49,8 @@ static const char* backend_to_string(const at::Backend& backend) {
       return "torch.xla";
     case at::Backend::Meta:
       return "torch.meta";
-    case at::Backend::AXDIMM:
-        return "torch.axdimm";
+    case at::Backend::PNM:
+      return "torch.pnm";
     default:
       AT_ERROR("Unimplemented backend ", backend);
   }
diff --git a/torch/nn/modules/__init__.py b/torch/nn/modules/__init__.py
index 87eb6c8f..d282908e 100644
--- a/torch/nn/modules/__init__.py
+++ b/torch/nn/modules/__init__.py
@@ -23,7 +23,7 @@ from .normalization import LocalResponseNorm, CrossMapLRN2d, LayerNorm, GroupNor
 from .dropout import Dropout, Dropout1d, Dropout2d, Dropout3d, AlphaDropout, FeatureAlphaDropout
 from .padding import ReflectionPad1d, ReflectionPad2d, ReflectionPad3d, ReplicationPad1d, ReplicationPad2d, \
     ReplicationPad3d, ZeroPad2d, ConstantPad1d, ConstantPad2d, ConstantPad3d
-from .sparse import Embedding, EmbeddingBag, EmbeddingBagAxdimm
+from .sparse import Embedding, EmbeddingBag, EmbeddingBagPnm
 from .rnn import RNNBase, RNN, LSTM, GRU, \
     RNNCellBase, RNNCell, LSTMCell, GRUCell
 from .pixelshuffle import PixelShuffle, PixelUnshuffle
@@ -51,7 +51,7 @@ __all__ = [
     'InstanceNorm2d', 'InstanceNorm3d', 'LayerNorm', 'GroupNorm', 'SyncBatchNorm',
     'Dropout', 'Dropout1d', 'Dropout2d', 'Dropout3d', 'AlphaDropout', 'FeatureAlphaDropout',
     'ReflectionPad1d', 'ReflectionPad2d', 'ReflectionPad3d', 'ReplicationPad2d', 'ReplicationPad1d', 'ReplicationPad3d',
-    'CrossMapLRN2d', 'Embedding', 'EmbeddingBag', 'EmbeddingBagAxdimm', 'RNNBase', 'RNN', 'LSTM', 'GRU', 'RNNCellBase', 'RNNCell',
+    'CrossMapLRN2d', 'Embedding', 'EmbeddingBag', 'EmbeddingBagPnm', 'RNNBase', 'RNN', 'LSTM', 'GRU', 'RNNCellBase', 'RNNCell',
     'LSTMCell', 'GRUCell', 'PixelShuffle', 'PixelUnshuffle', 'Upsample', 'UpsamplingNearest2d', 'UpsamplingBilinear2d',
     'PairwiseDistance', 'AdaptiveMaxPool1d', 'AdaptiveMaxPool2d', 'AdaptiveMaxPool3d', 'AdaptiveAvgPool1d',
     'AdaptiveAvgPool2d', 'AdaptiveAvgPool3d', 'TripletMarginLoss', 'ZeroPad2d', 'ConstantPad1d', 'ConstantPad2d',
diff --git a/torch/nn/modules/sparse.py b/torch/nn/modules/sparse.py
index f8398c41..72631283 100644
--- a/torch/nn/modules/sparse.py
+++ b/torch/nn/modules/sparse.py
@@ -223,16 +223,16 @@ class Embedding(Module):
         return embedding
 
 
-class EmbeddingBagAxdimm(Module):
+class EmbeddingBagPnm(Module):
     weight: Tensor
     op_id: int
     def __init__(self, weight):
-        super(EmbeddingBagAxdimm, self).__init__()
+        super(EmbeddingBagPnm, self).__init__()
         self.weight = weight
         self.op_context = None
 
     def forward(self, indices: Tensor, offsets: Tensor) -> Tensor:
-        return torch.ops.aten.embedding_bag_forward_only_axdimm(self.weight, indices, offsets)
+        return torch.ops.aten.embedding_bag_forward_only_pnm(self.weight, indices, offsets)
 
 
 class EmbeddingBag(Module):
diff --git a/torchgen/model.py b/torchgen/model.py
index b8e337ab..44764604 100644
--- a/torchgen/model.py
+++ b/torchgen/model.py
@@ -72,7 +72,7 @@ class DispatchKey(Enum):
     FPGA = auto()
     ORT = auto()
     Vulkan = auto()
-    AXDIMM = auto()
+    PNM = auto()
     Metal = auto()
     MKLDNN = auto()
     OpenGL = auto()
-- 
2.34.1

